@article{alexa-internet:2018:keyword-research-competitor,
  title = {Keyword {{Research}}, {{Competitor Analysis}}, \& {{Website Ranking}} | {{Alexa}}},
  author = {Alexa Internet},
  date = {2018-01-27},
  url = {https://www.alexa.com},
  keywords = {*CITATION}
}

@book{anderson:2013:architecture-cognition,
  title = {The {{Architecture}} of {{Cognition}}},
  author = {Anderson, John R.},
  date = {2013-11-19},
  edition = {0},
  publisher = {{Psychology Press}},
  url = {https://www.taylorfrancis.com/books/9781317759539},
  urldate = {2023-06-07},
  isbn = {978-1-317-75953-9},
  langid = {english},
  keywords = {*CITATION,Ergonomie,Temps adaptation}
}

@thesis{baledent:2022:complexite-annotation-manuelle,
  title = {De la complexité de l'annotation manuelle : méthodologie, biais et recommandations},
  author = {Baledent, Anaelle},
  date = {2023-12-01},
  institution = {{Normandie Université}},
  url = {https://theses.hal.science/tel-04011353},
  abstract = {Les corpus de référence annotés constituent des éléments primordiaux de nombreuses tâches du Traitement Automatique des Langues. Leur construction fait l'objet d’une attention particulière, notamment lors de campagnes d’annotation manuelle. Ces dernières impliquent de multiples aspects, déjà étudiés dans la littérature mais souvent de manière séparée. Nous présentons une synthèse des problèmes rencontrés lors des différentes étapes d'une campagne, attirant l’attention des gestionnaires sur des points de vigilance, afin qu'ils fassent preuve de prudence durant leur campagne.Cette thèse donne une première définition des biais d’annotation, qui sont des phénomènes perturbateurs et variés pouvant avoir une incidence sur les annotations. Nous proposons une méthode et des moyens d'observation pour détecter et analyser la présence de biais d’annotation. Deux campagnes d’annotation, menées spécialement dans le but d'étudier des biais particuliers, servent d'illustration et nous ont permis de constater l'influence tangible de certains paramètres sur l’annotation. Dans cette optique, nous avons aussi introduit la notion de consensualité, qui permet en particulier de situer un annotateur par rapport à un groupe. Nous montrons un premier lien entre les annotateurs les moins consensuels et les moins performants.},
  langid = {french},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\PK64N4R8\\Baledent - 2022 - De la complexité de l'annotation manuelle  méthod.pdf}
}

@unpublished{bocklisch-etal:2017:rasa-open-source,
  title = {Rasa: {{Open Source Language Understanding}} and {{Dialogue Management}}},
  shorttitle = {Rasa},
  author = {Bocklisch, Tom and Faulkner, Joey and Pawlowski, Nick and Nichol, Alan},
  date = {2017-12-15},
  eprint = {1712.05181},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1712.05181},
  urldate = {2020-10-23},
  abstract = {We introduce a pair of tools, Rasa NLU and Rasa Core, which are open source python libraries for building conversational software. Their purpose is to make machine-learning based dialogue management and language understanding accessible to non-specialist software developers. In terms of design philosophy, we aim for ease of use, and bootstrapping from minimal (or no) initial training data. Both packages are extensively documented and ship with a comprehensive suite of tests. The code is available at https://github.com/RasaHQ/},
  langid = {english},
  keywords = {*CITATION,Artificial Intelligence,Computation and Language,Computer Science - Machine Learning,Rasa},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\4ME935TW\\Bocklisch et al. - 2017 - Rasa Open Source Language Understanding and Dialo.pdf}
}

@unpublished{bojanowski-etal:2016:enriching-word-vectors,
  title = {Enriching {{Word Vectors}} with {{Subword Information}}},
  author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  date = {2016},
  eprint = {1607.04606},
  eprinttype = {arxiv},
  keywords = {*CITATION,⛔ No DOI found,Computation and Language,Machine learning},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\BZMD9R5Y\\Bojanowski et al. - 2016 - Enriching Word Vectors with Subword Information.pdf}
}

@article{brysbaert:2019:how-many-words,
  title = {How Many Words Do We Read per Minute? {{A}} Review and Meta-Analysis of Reading Rate},
  shorttitle = {How Many Words Do We Read per Minute?},
  author = {Brysbaert, Marc},
  date = {2019-12},
  journaltitle = {Journal of Memory and Language},
  volume = {109},
  pages = {104047},
  issn = {0749596X},
  doi = {10.1016/j.jml.2019.104047},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X19300786},
  urldate = {2023-06-27},
  langid = {english},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\6HQS5M2Y\\Brysbaert - 2019 - How many words do we read per minute A review and.pdf}
}

@article{costello:2019:gartner-top-technologies,
  title = {Gartner {{Top Technologies}} and {{Trends Driving}} the {{Digital Workplace}}},
  author = {Costello, Katie},
  date = {2019-03-18},
  journaltitle = {Gartner, Inc},
  url = {//www.gartner.com/smarterwithgartner/top-10-technologies-driving-the-digital-workplace/},
  urldate = {2020-10-23},
  abstract = {How artificial intelligence, smart workspaces and talent markets will boost employee digital dexterity in future digital workplaces.},
  langid = {american},
  keywords = {*CITATION}
}

@inproceedings{dagan-etal:2005:pascal-recognising-textual,
  title = {The {{PASCAL Recognising Textual Entailment Challenge}}},
  booktitle = {Machine {{Learning Challenges}}. {{Evaluating Predictive Uncertainty}}, {{Visual Object Classification}}, and {{Recognising Tectual Entailment}}},
  author = {Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  date = {2005-01},
  volume = {3944},
  pages = {177--190},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11736790_9},
  url = {http://link.springer.com/10.1007/11736790_9},
  abstract = {This paper describes the Second PASCAL Recognising Textual Entailment Challenge (RTE-2).1 We describe the RTE2 dataset and overview the submissions for the challenge. One of the main goals for this year’s dataset was to provide more “realistic” text-hypothesis examples, based mostly on outputs of actual systems. The 23 submissions for the challenge present diverse approaches and research directions, and the best results achieved this year are considerably higher than last year’s state of the art.},
  isbn = {978-3-540-33427-9},
  langid = {english},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\NXZHY47L\\Dagan et al. - 2006 - The PASCAL Recognising Textual Entailment Challeng.pdf}
}

@article{davidson-ravi:2005:agglomerative-hierarchical-clustering,
  title = {Agglomerative {{Hierarchical Clustering}} with {{Constraints}}: {{Theoretical}} and {{Empirical Results}}},
  shorttitle = {Agglomerative {{Hierarchical Clustering}} with {{Constraints}}},
  author = {Davidson, Ian and Ravi, S. S.},
  editor = {Jorge, Alípio Mário and Torgo, Luís and Brazdil, Pavel and Camacho, Rui and Gama, João},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {collaborator},
  date = {2005},
  journaltitle = {Knowledge Discovery in Databases: PKDD 2005},
  volume = {3721},
  pages = {59--70},
  url = {http://link.springer.com/10.1007/11564126_11},
  urldate = {2020-10-22},
  abstract = {We explore the use of instance and cluster-level constraints with agglomerative hierarchical clustering. Though previous work has illustrated the benefits of using constraints for non-hierarchical clustering, their application to hierarchical clustering is not straight-forward for two primary reasons. First, some constraint combinations make the feasibility problem (Does there exist a single feasible solution?) NP-complete. Second, some constraint combinations when used with traditional agglomerative algorithms can cause the dendrogram to stop prematurely in a dead-end solution even though there exist other feasible solutions with a significantly smaller number of clusters. When constraints lead to efficiently solvable feasibility problems and standard agglomerative algorithms do not give rise to dead-end solutions, we empirically illustrate the benefits of using constraints to improve cluster purity and average distortion. Furthermore, we introduce the new γ constraint and use it in conjunction with the triangle inequality to considerably improve the efficiency of agglomerative clustering.},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Clustering,Constrained clustering,Hierarchcal clustering},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\QEHQH3QT\\Davidson et Ravi - 2005 - Agglomerative Hierarchical Clustering with Constra.pdf}
}

@article{diamond-etal:1990:analysis-binary-data,
  title = {Analysis of {{Binary Data}}. 2nd {{Edn}}.},
  author = {Diamond, Ian and Cox, D. R. and Snell, E. J.},
  date = {1990},
  journaltitle = {Applied Statistics},
  volume = {39},
  number = {2},
  eprint = {10.2307/2347766},
  eprinttype = {jstor},
  pages = {260},
  issn = {00359254},
  doi = {10.2307/2347766},
  url = {https://www.jstor.org/stable/10.2307/2347766?origin=crossref},
  urldate = {2023-07-06},
  keywords = {*CITATION,R²}
}

@book{edwards:1992:likelihood,
  title = {Likelihood},
  author = {Edwards, Anthony William Fairbank},
  date = {1992},
  edition = {Expanded ed},
  publisher = {{Johns Hopkins Univ. Press}},
  location = {{Baltimore}},
  isbn = {978-0-8018-4445-4 978-0-8018-4443-0},
  langid = {english},
  pagetotal = {275},
  keywords = {*CITATION,Log vraissemblance,Metric}
}

@article{elkosantini-gien:2009:integration-human-behavioural,
  title = {Integration of Human Behavioural Aspects in a Dynamic Model for a Manufacturing System},
  author = {Elkosantini, S. and Gien, D.},
  date = {2009-05-15},
  journaltitle = {International Journal of Production Research},
  volume = {47},
  number = {10},
  pages = {2601--2623},
  issn = {0020-7543, 1366-588X},
  doi = {10.1080/00207540701663490},
  url = {https://www.tandfonline.com/doi/full/10.1080/00207540701663490},
  urldate = {2023-06-07},
  langid = {english},
  keywords = {*CITATION,Ergonomie,Fatigue des opérateurs},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\BVES3475\\Elkosantini et Gien - 2009 - Integration of human behavioural aspects in a dyna.pdf}
}

@article{gancarski-wemmert:2007:collaborative-multistep-monolevel,
  title = {Collaborative Multi-Step Mono-Level Multi-Strategy Classification},
  author = {Gançarski, Pierre and Wemmert, Cédric},
  date = {2007-08-30},
  journaltitle = {Multimed Tools Appl},
  volume = {35},
  number = {1},
  pages = {1--27},
  issn = {1380-7501},
  doi = {10.1007/s11042-007-0115-x},
  url = {https://univoak.eu/islandora/object/islandora:96302},
  abstract = {This article deals with the description of a new way to learn from multiple and heterogeneous data sets, and with the integration of this method in a multi-agent hybrid learning system. This system integrates different kinds of unsupervised classification methods and gives a set of clusterings as the result and a unifying result, representing all the other one. In this new approach, the method occurrences compare their results and automatically refine them to try to make them converge towards a unique clustering that unifies all the results. Thus, the data are not really merged but the results from their classification are compared and refined according to the results from all the other data sets. This enables to produce a set of classification hierarchies which classes are very similar, although these hierarchies were extracted from different data sets. Then it is easy to build a unifying result from all of them.},
  langid = {english},
  keywords = {*CITATION,Clustering,Collaborative clustering,Constrained clustering,INTERACTIVE\_CLUSTERING},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\CFXDP786\\Gançarski and Wemmert - 2007 - Collaborative multi-step mono-level multi-strategy.pdf}
}

@book{girden:1992:anova,
  title = {{{ANOVA}}},
  author = {Girden, Ellen},
  date = {1992},
  publisher = {{SAGE Publications, Inc.}},
  location = {{2455 Teller Road,~Thousand Oaks~California~91320~United States of America}},
  url = {https://methods.sagepub.com/book/anova},
  urldate = {2023-07-06},
  isbn = {978-0-8039-4257-8 978-1-4129-8341-9},
  keywords = {*CITATION}
}

@article{givoni-frey:2009:semisupervised-affinity-propagation,
  title = {Semi-{{Supervised Aﬃnity Propagation}} with {{Instance-Level Constraints}}},
  author = {Givoni, Inmar E and Frey, Brendan J},
  date = {2009},
  abstract = {Recently, affinity propagation (AP) was introduced as an unsupervised learning algorithm for exemplar based clustering. Here we extend the AP model to account for semisupervised clustering. AP, which is formulated as inference in a factor-graph, can be naturally extended to account for ‘instancelevel’ constraints: pairs of data points that cannot belong to the same cluster (cannotlink), or must belong to the same cluster (must-link). We present a semi-supervised AP algorithm (SSAP) that can use instancelevel constraints to guide the clustering. We demonstrate the applicability of SSAP to interactive image segmentation by using SSAP to cluster superpixels while taking into account user instructions regarding which superpixels belong to the same object. We demonstrate SSAP can achieve better performance compared to other semi-supervised methods.},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Affinity propagation,Clustering,Constrained clustering},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\SMP6WJN6\\Givoni et Frey - 2009 - Semi-Supervised Aﬃnity Propagation with Instance-L.pdf}
}

@article{goasduff:2019:chatbots-will-appeal,
  title = {Chatbots {{Will Appeal}} to {{Modern Workers}}},
  author = {Goasduff, Laurence},
  date = {2019-07-31},
  journaltitle = {Gartner, Inc},
  url = {//www.gartner.com/smarterwithgartner/chatbots-will-appeal-to-modern-workers/},
  urldate = {2020-10-23},
  abstract = {The proliferation of chatbots in the modern workplace calls for IT leaders to create a conversational platform strategy that ensures an effective solution for employees, customers and key partners.},
  langid = {american},
  keywords = {*CITATION}
}

@incollection{hart-staveland:1988:development-nasatlx-task,
  title = {Development of {{NASA-TLX}} ({{Task Load Index}}): {{Results}} of {{Empirical}} and {{Theoretical Research}}},
  booktitle = {Human {{Mental Workload}}},
  author = {Hart, Sandra G. and Staveland, Lowell E.},
  editor = {Hancock, Peter A. and Meshkati, Najmedin},
  date = {1988},
  series = {Advances in {{Psychology}}},
  volume = {52},
  pages = {139--183},
  publisher = {{North-Holland}},
  url = {https://www.sciencedirect.com/science/article/pii/S0166411508623869},
  abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.},
  keywords = {*CITATION,Charge mentale}
}

@article{honnibal-montani:2017:spacy-natural-language,
  title = {{{spaCy}} 2 : {{Natural}} Language Understanding with {{Bloom}} Embeddings, Convolutional Neural Networks and Incremental Parsing},
  author = {Honnibal, Matthew and Montani, Ines},
  date = {2017},
  keywords = {*CITATION,Spacy}
}

@article{hoyt-etal:2016:ibm-watson-analytics,
  title = {{{IBM Watson Analytics}}: {{Automating Visualization}}, {{Descriptive}}, and {{Predictive Statistics}}},
  author = {Hoyt, Robert Eugene and Snider, Dallas and Thompson, Carla and Mantravadi, Sarita},
  date = {2016-10-11},
  journaltitle = {JMIR Public Health Surveill},
  volume = {2},
  number = {2},
  issn = {2369-2960},
  doi = {10.2196/publichealth.5810},
  url = {https://doi.org/10.2196/publichealth.5810},
  abstract = {Background: We live in an era of explosive data generation that will continue to grow and involve all industries. One of the results of this explosion is the need for newer and more efficient data analytics procedures. Traditionally, data analytics required a substantial background in statistics and computer science. In 2015, International Business Machines Corporation (IBM) released the IBM Watson Analytics (IBMWA) software that delivered advanced statistical procedures based on the Statistical Package for the Social Sciences (SPSS). The latest entry of Watson Analytics into the field of analytical software products provides users with enhanced functions that are not available in many existing programs. For example, Watson Analytics automatically analyzes datasets, examines data quality, and determines the optimal statistical approach. Users can request exploratory, predictive, and visual analytics. Using natural language processing (NLP), users are able to submit additional questions for analyses in a quick response format. This analytical package is available free to academic institutions (faculty and students) that plan to use the tools for noncommercial purposes. Objective: To report the features of IBMWA and discuss how this software subjectively and objectively compares to other data mining programs. Methods: The salient features of the IBMWA program were examined and compared with other common analytical platforms, using validated health datasets. Results: Using a validated dataset, IBMWA delivered similar predictions compared with several commercial and open source data mining software applications. The visual analytics generated by IBMWA were similar to results from programs such as Microsoft Excel and Tableau Software. In addition, assistance with data preprocessing and data exploration was an inherent component of the IBMWA application. Sensitivity and specificity were not included in the IBMWA predictive analytics results, nor were odds ratios, confidence intervals, or a confusion matrix. Conclusions: IBMWA is a new alternative for data analytics software that automates descriptive, predictive, and visual analytics. This program is very user-friendly but requires data preprocessing, statistical conceptual understanding, and domain expertise.},
  keywords = {*CITATION,data analysis,data mining,IBM Watson,machine learning,NLP,statistical data analysis}
}

@article{jones-etal:2015:demographic-occupational-predictors,
  title = {Demographic and Occupational Predictors of Stress and Fatigue in {{French}} Intensive-Care Registered Nurses and Nurses' Aides: {{A}} Cross-Sectional Study},
  shorttitle = {Demographic and Occupational Predictors of Stress and Fatigue in {{French}} Intensive-Care Registered Nurses and Nurses' Aides},
  author = {Jones, Gabrielle and Hocine, Mounia and Salomon, Jérôme and Dab, William and Temime, Laura},
  date = {2015-01},
  journaltitle = {International Journal of Nursing Studies},
  volume = {52},
  number = {1},
  pages = {250--259},
  issn = {00207489},
  doi = {10.1016/j.ijnurstu.2014.07.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0020748914002016},
  urldate = {2023-06-07},
  langid = {english},
  keywords = {*CITATION,Ergonomie,Fatigue des opérateurs}
}

@book{kahneman:2011:thinking-fast-slow,
  title = {Thinking, Fast and Slow.},
  author = {Kahneman, Daniel},
  date = {2011},
  series = {Thinking, Fast and Slow.},
  publisher = {{Farrar, Straus and Giroux}},
  location = {{New York,  NY,  US}},
  abstract = {In the highly anticipated Thinking, Fast and Slow, Kahneman takes us on a groundbreaking tour of the mind and explains the two systems that drive the way we think. System 1 is fast, intuitive, and emotional; System 2 is slower, more deliberative, and more logical. Kahneman exposes the extraordinary capabilities—and also the faults and biases—of fast thinking, and reveals the pervasive influence of intuitive impressions on our thoughts and behavior. The impact of loss aversion and overconfidence on corporate strategies, the difficulties of predicting what will make us happy in the future, the challenges of properly framing risks at work and at home, the profound effect of cognitive biases on everything from playing the stock market to planning the next vacation—each of these can be understood only by knowing how the two systems shape our judgments and decisions. Engaging the reader in a lively conversation about how we think, Kahneman reveals where we can and cannot trust our intuitions and how we can tap into the benefits of slow thinking. He offers practical and enlightening insights into how choices are made in both our business and our personal lives—and how we can use different techniques to guard against the mental glitches that often get us into trouble. Thinking, Fast and Slow will transform the way you think about thinking. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {0-374-27563-7 (Hardcover); 1-4299-6935-0 (PDF); 978-0-374-27563-1 (Hardcover); 978-1-4299-6935-2 (PDF)},
  pagetotal = {499},
  keywords = {*CITATION,*Cognitive Processes,*Mind,*Thinking,Choice Behavior,Decision Making,Intuition,Judgment}
}

@article{kamvar-etal:2003:spectral-learning,
  title = {Spectral {{Learning}}},
  author = {Kamvar, Sepandar D and Klein, Dan and Manning, Christopher D},
  date = {2003},
  journaltitle = {Proceedings of the international joint conference on artificial intelligence},
  pages = {561--566},
  abstract = {We present a simple, easily implemented spectral learning algorithm that applies equally whether we have no supervisory information, pairwise link constraints, or labeled examples. In the unsupervised case, it performs consistently with other spectral clustering algorithms. In the supervised case, our approach achieves high accuracy on the categorization of thousands of documents given only a few dozen labeled training documents for the 20 Newsgroups data set. Furthermore, its classification accuracy increases with the addition of unlabeled documents, demonstrating effective use of unlabeled data.},
  langid = {english},
  keywords = {*CITATION,⛔ No DOI found,Clustering,Constrained clustering,Spectral clustering},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\GX9HEA6W\\Kamvar et al. - 2003 - Spectral Learning.pdf}
}

@article{khan-etal:2012:multiple-parameter-based,
  title = {Multiple {{Parameter Based Clustering}} ({{MPC}}): {{Prospective Analysis}} for {{Effective Clustering}} in {{Wireless Sensor Network}} ({{WSN}}) {{Using K-Means Algorithm}}},
  shorttitle = {Multiple {{Parameter Based Clustering}} ({{MPC}})},
  author = {Khan, Md. Asif and Tamim, Israfil and Ahmed, Emdad and Awal, M. Abdul},
  date = {2012},
  journaltitle = {WSN},
  volume = {04},
  number = {01},
  pages = {18--24},
  issn = {1945-3078, 1945-3086},
  doi = {10.4236/wsn.2012.41003},
  url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/wsn.2012.41003},
  urldate = {2023-01-16},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Clustering,Constrained clustering,K-Means},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\LQ5DZJVB\\Khan et al. - 2012 - Multiple Parameter Based Clustering (MPC) Prospec.pdf}
}

@incollection{kirch:2008:pearson-correlation-coefficient,
  title = {Pearson’s {{Correlation Coefficient}}},
  booktitle = {Encyclopedia of {{Public Health}}},
  editor = {Kirch, Wilhelm},
  date = {2008},
  pages = {1090--1091},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  url = {https://link.springer.com/10.1007/978-1-4020-5614-7_2569},
  urldate = {2023-07-06},
  isbn = {978-1-4020-5613-0 978-1-4020-5614-7},
  langid = {english},
  keywords = {*CITATION,Correlation,Metric}
}

@article{lampert-etal:2018:constrained-distance-based,
  title = {Constrained Distance Based Clustering for Time-Series: A Comparative and Experimental Study},
  shorttitle = {Constrained Distance Based Clustering for Time-Series},
  author = {Lampert, Thomas and Dao, Thi-Bich-Hanh and Lafabregue, Baptiste and Serrette, Nicolas and Forestier, Germain and Crémilleux, Bruno and Vrain, Christel and Gançarski, Pierre},
  date = {2018-11},
  journaltitle = {Data Min Knowl Disc},
  volume = {32},
  number = {6},
  pages = {1663--1707},
  issn = {1384-5810, 1573-756X},
  doi = {10/gfbpj8},
  url = {http://link.springer.com/10.1007/s10618-018-0573-y},
  urldate = {2020-06-02},
  abstract = {Constrained clustering is becoming an increasingly popular approach in data mining. It offers a balance between the complexity of producing a formal definition of thematic classes—required by supervised methods—and unsupervised approaches, which ignore expert knowledge and intuition. Nevertheless, the application of constrained clustering to time-series analysis is relatively unknown. This is partly due to the unsuitability of the Euclidean distance metric, which is typically used in data mining, to time-series data. This article addresses this divide by presenting an exhaustive review of constrained clustering algorithms and by modifying publicly available implementations to use a more appropriate distance measure—dynamic time warping. It presents a comparative study, in which their performance is evaluated when applied to time-series. It is found that k-means based algorithms become computationally expensive and unstable under these modifications. Spectral approaches are easily applied and offer state-of-the-art performance, whereas declarative approaches are also easily applied and guarantee constraint satisfaction. An analysis of the results raises several influencing factors to an algorithm’s performance when constraints are introduced.},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Comparaison,Constrained clustering,Dynamic time warping,INTERACTIVE\_CLUSTERING,Partition clustering,Semi-supervised,Time-series},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\UMVKY7ZH\\Lampert et al. - 2018 - Constrained distance based clustering for time-ser.pdf}
}

@inproceedings{lampert-etal:2019:constrained-distance-based,
  title = {Constrained {{Distance}} Based {{K-Means Clustering}} for {{Satellite Image Time-Series}}},
  booktitle = {{{IGARSS}} 2019 - 2019 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}}},
  author = {Lampert, Thomas and Lafabregue, Baptiste and Gancarski, Pierre},
  date = {2019-07},
  pages = {2419--2422},
  publisher = {{IEEE}},
  location = {{Yokohama, Japan}},
  doi = {10/ggx3tj},
  url = {https://ieeexplore.ieee.org/document/8900147/},
  urldate = {2020-06-02},
  abstract = {The advent of high-resolution instruments for time-series sampling poses added complexity for the formal definition of thematic classes in the remote sensing domain—required by supervised methods—while unsupervised methods ignore expert knowledge and intuition. Constrained clustering is becoming an increasingly popular approach in data mining because it offers a solution to these problems, however, its application in remote sensing is relatively unknown. This article addresses this divide by adapting publicly available k-Means constrained clustering implementations to use the dynamic time warping (DTW) dissimilarity measure, which is thought to be more appropriate for time-series analysis. Adding constraints to the clustering problem increases accuracy when compared to unconstrained clustering. The output of such algorithms are homogeneous in spatially defined regions.},
  eventtitle = {{{IGARSS}} 2019 - 2019 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}}},
  isbn = {978-1-5386-9154-0},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Clustering,Constrained clustering,INTERACTIVE\_CLUSTERING,K-Means},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\KWERLC9W\\Lampert et al. - 2019 - PRÉSENTATION.pdf;C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\UNDG3ZHC\\Lampert et al. - 2019 - Constrained Distance based K-Means Clustering for .pdf}
}

@inproceedings{li-etal:2009:constrained-clustering-spectral,
  title = {Constrained Clustering via Spectral Regularization},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Li, Zhenguo and Liu, Jianzhuang and Tang, Xiaoou},
  date = {2009-06},
  pages = {421--428},
  publisher = {{IEEE}},
  location = {{Miami, FL}},
  doi = {10/dsh439},
  url = {https://ieeexplore.ieee.org/document/5206852/},
  urldate = {2020-07-29},
  abstract = {We propose a novel framework for constrained spectral clustering with pairwise constraints which specify whether two objects belong to the same cluster or not. Unlike previous methods that modify the similarity matrix with pairwise constraints, we adapt the spectral embedding towards an ideal embedding as consistent with the pairwise constraints as possible. Our formulation leads to a small semidefinite program whose complexity is independent of the number of objects in the data set and the number of pairwise constraints, making it scalable to large-scale problems. The proposed approach is applicable directly to multi-class problems, handles both must-link and cannotlink constraints, and can effectively propagate pairwise constraints. Extensive experiments on real image data and UCI data have demonstrated the efficacy of our algorithm.},
  eventtitle = {2009 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPR Workshops}})},
  isbn = {978-1-4244-3992-8},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Constrained clustering,INTERACTIVE\_CLUSTERING,Spectral clustering},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\DUKRVM3F\\Li et al. - 2009 - Constrained clustering via spectral regularization.pdf}
}

@article{macqueen:1967:methods-classification-analysis,
  title = {Some Methods for Classification and Analysis of Multivariate Observations.},
  author = {MacQueen, J},
  date = {1967},
  journaltitle = {Proceedings of the fifth Berkeley symposium on mathematical statistics and probability},
  volume = {1},
  number = {14},
  pages = {281--297},
  langid = {english},
  keywords = {*CITATION,⛔ No DOI found,Clustering,K-Means},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\NUMFXV2C\\MacQueen - 1967 - Some methods for classification and analysis of mu.pdf}
}

@book{manning-schutze:2000:foundations-statistical-natural,
  title = {Foundations of Statistical Natural Language Processing},
  author = {Manning, Christopher D. and Schütze, Hinrich},
  date = {2000},
  edition = {2e éd. avec des corrections},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass}},
  langid = {english},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\WINIYV9I\\Manning et Schütze - 2000 - Foundations of statistical natural language proces.pdf}
}

@article{miller-charles:1991:contextual-correlates-semantic,
  title = {Contextual Correlates of Semantic Similarity},
  author = {Miller, George A. and Charles, Walter G.},
  date = {1991},
  journaltitle = {Language and Cognitive Processes},
  volume = {6},
  number = {1},
  pages = {1--28},
  doi = {10.1080/01690969108406936},
  url = {https://doi.org/10.1080/01690969108406936},
  keywords = {*CITATION}
}

@article{murtagh-contreras:2012:algorithms-hierarchical-clustering,
  title = {Algorithms for Hierarchical Clustering: {{An}} Overview},
  author = {Murtagh, Fionn and Contreras, Pedro},
  date = {2012},
  journaltitle = {Wiley Interdisc. Rew.: Data Mining and Knowledge Discovery},
  volume = {2},
  pages = {86--97},
  doi = {10.1002/widm.53},
  abstract = {We survey agglomerative hierarchical clustering algorithms and discuss efficient implementations that are available in R and other software environments. We look at hierarchical self-organizing maps, and mixture models. We review grid-based clustering, focusing on hierarchical density-based approaches. Finally, we describe a recently developed very efficient (linear time) hierarchical clustering algorithm, which can also be viewed as a hierarchical grid-based algorithm. © 2011 Wiley Periodicals, Inc.},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Clustering,Hierarchcal clustering}
}

@article{nelder-wedderburn:1972:generalized-linear-models,
  title = {Generalized {{Linear Models}}},
  author = {Nelder, J. A. and Wedderburn, R. W. M.},
  date = {1972},
  journaltitle = {Journal of the Royal Statistical Society. Series A (General)},
  volume = {135},
  number = {3},
  eprint = {10.2307/2344614},
  eprinttype = {jstor},
  pages = {370},
  issn = {00359238},
  doi = {10.2307/2344614},
  url = {https://www.jstor.org/stable/10.2307/2344614?origin=crossref},
  urldate = {2023-07-06},
  keywords = {*CITATION,GLM}
}

@incollection{ng-etal:2002:spectral-clustering-analysis,
  title = {On {{Spectral Clustering}}: {{Analysis}} and an Algorithm},
  shorttitle = {On {{Spectral Clustering}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 14},
  author = {Ng, Andrew Y. and Jordan, Michael I. and Weiss, Yair},
  editor = {Dietterich, T. G. and Becker, S. and Ghahramani, Z.},
  date = {2002},
  pages = {849--856},
  publisher = {{MIT Press}},
  url = {http://papers.nips.cc/paper/2092-on-spectral-clustering-analysis-and-an-algorithm.pdf},
  urldate = {2020-10-22},
  abstract = {Despite many empirical successes of spectral clustering methodsalgorithms that cluster points using eigenvectors of matrices derived from the data- there are several unresolved issues. First, there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.},
  keywords = {*CITATION,Clustering,Spectral clustering},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\DTJJCJL4\\Ng et al. - 2002 - On Spectral Clustering Analysis and an algorithm.pdf}
}

@book{nivre:2006:inductive-dependency-parsing,
  title = {Inductive {{Dependency Parsing}}},
  author = {Nivre, Joakim},
  editorb = {Ide, Nancy and Véronis, Jean},
  editorbtype = {redactor},
  date = {2006},
  series = {Text, {{Speech}} and {{Language Technology}}},
  volume = {34},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  url = {http://link.springer.com/10.1007/1-4020-4889-0},
  urldate = {2023-07-06},
  isbn = {978-1-4020-4888-3 978-1-4020-4889-0},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\YZEE8JPF\\Nivre - 2006 - Inductive Dependency Parsing.pdf}
}

@inproceedings{nothman-etal:2018:stop-word-lists,
  title = {Stop {{Word Lists}} in {{Free Open-source Software Packages}}},
  booktitle = {Proceedings of {{Workshop}} for {{NLP Open Source Software}} ({{NLP-OSS}})},
  author = {Nothman, Joel and Qin, Hanmin and Yurchak, Roman},
  date = {2018},
  pages = {7--12},
  publisher = {{Association for Computational Linguistics}},
  location = {{Melbourne, Australia}},
  doi = {10.18653/v1/W18-2502},
  url = {http://aclweb.org/anthology/W18-2502},
  urldate = {2023-07-06},
  eventtitle = {Proceedings of {{Workshop}} for {{NLP Open Source Software}} ({{NLP-OSS}})},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Preprocessing,Stopwords},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\VGBMUBTE\\Nothman et al. - 2018 - Stop Word Lists in Free Open-source Software Packa.pdf}
}

@article{pedregosa-etal:2011:scikitlearn-machine-learning,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  date = {2011},
  journaltitle = {Journal of Machine Learning Research},
  volume = {12},
  pages = {2825--2830},
  keywords = {*CITATION,Sklearn}
}

@inproceedings{pradhan-etal:2007:semeval2007-task-17,
  title = {{{SemEval-2007}} Task 17: {{English}} Lexical Sample, {{SRL}} and All Words},
  shorttitle = {{{SemEval-2007}} Task 17},
  booktitle = {Proceedings of the 4th {{International Workshop}} on {{Semantic Evaluations}} - {{SemEval}} '07},
  author = {Pradhan, Sameer S. and Loper, Edward and Dligach, Dmitriy and Palmer, Martha},
  date = {2007},
  pages = {87--92},
  publisher = {{Association for Computational Linguistics}},
  location = {{Prague, Czech Republic}},
  doi = {10.3115/1621474.1621490},
  url = {http://portal.acm.org/citation.cfm?doid=1621474.1621490},
  urldate = {2023-06-27},
  abstract = {This paper describes our experience in preparing the data and evaluating the results for three subtasks of SemEval-2007 Task-17 – Lexical Sample, Semantic Role Labeling (SRL) and All-Words respectively. We tabulate and analyze the results of participating systems.},
  eventtitle = {The 4th {{International Workshop}}},
  langid = {english},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\WXHN2Z2U\\Pradhan et al. - 2007 - SemEval-2007 task 17 English lexical sample, SRL .pdf}
}

@book{purves-brannon:2013:principles-cognitive-neuroscience,
  title = {Principles of Cognitive Neuroscience},
  editor = {Purves, Dale and Brannon, Elizabeth M.},
  date = {2013},
  edition = {2. ed},
  publisher = {{Sinauer}},
  location = {{Sunderland, Mass}},
  isbn = {978-0-87893-573-4},
  langid = {english},
  pagetotal = {601},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\XKKHDBM8\\Purves et Brannon - 2013 - Principles of cognitive neuroscience.pdf}
}

@report{r-core-team:2017:language-environment-statistical,
  title = {R: {{A}} Language and Environment for Statistical   Computing},
  author = {R Core Team},
  date = {2017},
  institution = {{R Foundation for Statistical Computing}},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  langid = {english},
  keywords = {*CITATION}
}

@article{rosenberg-hirschberg:2007:vmeasure-conditional-entropybased,
  title = {V-{{Measure}}: {{A Conditional Entropy-Based External Cluster Evaluation Measure}}},
  author = {Rosenberg, Andrew and Hirschberg, Julia},
  date = {2007},
  abstract = {We present V-measure, an external entropybased cluster evaluation measure. Vmeasure provides an elegant solution to many problems that affect previously defined cluster evaluation measures including 1) dependence on clustering algorithm or data set, 2) the “problem of matching”, where the clustering of only a portion of data points are evaluated and 3) accurate evaluation and combination of two desirable aspects of clustering, homogeneity and completeness. We compare V-measure to a number of popular cluster evaluation measures and demonstrate that it satisfies several desirable properties of clustering solutions, using simulated clustering results. Finally, we use V-measure to evaluate two clustering tasks: document clustering and pitch accent type clustering.},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\HK8LKIDM\\Rosenberg et Hirschberg - V-Measure A Conditional Entropy-Based External Cl.pdf}
}

@article{ruiz-etal:2010:densitybased-semisupervised-clustering,
  title = {Density-Based Semi-Supervised Clustering},
  author = {Ruiz, Carlos and Spiliopoulou, Myra and Menasalvas, Ernestina},
  date = {2010-11},
  journaltitle = {Data Min Knowl Disc},
  volume = {21},
  number = {3},
  pages = {345--370},
  issn = {1384-5810, 1573-756X},
  doi = {10.1007/s10618-009-0157-y},
  url = {http://link.springer.com/10.1007/s10618-009-0157-y},
  urldate = {2023-01-12},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Clustering,Constrained clustering,DBScan},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\T78I7SNJ\\Ruiz et al. - 2010 - Density-based semi-supervised clustering.pdf}
}

@inproceedings{schild-etal:2021:conception-iterative-semisupervisee,
  title = {Conception itérative et semi-supervisée d'assistants conversationnels par regroupement interactif des questions},
  author = {Schild, Erwan and Durantin, Gautier and Lamirel, Jean-Charles and Miconi, Florian},
  date = {2021-01-25},
  volume = {RNTI E-37},
  publisher = {{Edition RNTI}},
  url = {https://hal.inria.fr/hal-03133007},
  urldate = {2021-06-14},
  abstract = {La création d’un jeu de données pour l’entrainement d’un chatbot repose sur un a priori de connaissance du domaine. En conséquence, cette étape est le plus souvent manuelle, fastidieuse et soumise aux biais. Pour garantir l’efficacité et l’objectivité de l’annotation, nous proposons une méthodologie d’apprentissage actif par annotation de contraintes. Il s’agit d’une approche itérative, reposant sur un algorithme de clustering pour segmenter les données et tirant parti de la connaissance de l’annotateur pour guider le regroupement des questions en une structure d’intentions. Dans cet article, nous étudions les paramètres optimaux de modélisation pour réaliser une segmentation exploitable en un minimum d’annotations, et montrons que cette approche permet d’aboutir à une structure cohérente pour l’entrainement d’un assistant conversationnel.},
  eventtitle = {EGC 2021 - 21èmes Journées Francophones Extraction et Gestion des Connaissances},
  langid = {french},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,*PUBLICATION,INTERACTIVE\_CLUSTERING},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\T7NYJRY8\\Schild et al. - 2021 - Conception itérative et semi-supervisée d'assistan.pdf}
}

@inproceedings{schild-etal:2021:concevoir-assistant-conversationnel,
  title = {Concevoir un assistant conversationnel de manière itérative et semi-supervisée avec le clustering interactif},
  shorttitle = {Concevoir un assistant conversationnel avec le clustering interactif},
  booktitle = {TextMine 2021 (TM'2021) - En conjonction avec EGC 2021},
  author = {Schild, Erwan and Durantin, Gautier and Lamirel, Jean-Charles},
  date = {2021-01-26},
  pages = {11--14},
  publisher = {{Pascal Cuxac, Vincent Lemaire, Cédric Lopez}},
  url = {https://hal.inria.fr/hal-03133060},
  abstract = {La création d’un jeu de données nécessaire à la conception d’un assistant conversationnel résulte le plus souvent d’une étape manuelle et fastidieuse qui manque de techniques destinées à l’assister. Pour accélérer cette étape d’annotation, nous proposons une méthode de clustering interactif : il s’agit d’une approche itérative inspirée de l’apprentissage actif, reposant sur un algorithme de clustering et tirant parti d’une annotation de contraintes pour guider le regroupement des questions en une structure d’intentions. Dans cet article, nous exposons la méthodologie à mettre en oeuvre pour concevoir un assistant conversationnel opérationnel à l’aide du clustering interactif.},
  eventtitle = {Atelier - Fouille de Textes - Text Mine 2021 - En conjonction avec EGC 2021},
  langid = {french},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,*PUBLICATION,⛔ No DOI found,INTERACTIVE\_CLUSTERING},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\3GD3XG3E\\Schild et al. - 2021 - Concevoir un assistant conversationnel de manière .pdf;C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\IHVRXA2V\\Schild et al - 2021 - PRESENTATION.pdf}
}

@software{schild-etal:2022:cognitivefactory-interactiveclusteringgui,
  title = {Cognitivefactory/Interactive-Clustering-Gui},
  shorttitle = {Cognitivefactory/Interactive-Clustering-Gui},
  author = {SCHILD, Erwan and TTremble and Clementine-Msk},
  date = {2022-09-01},
  url = {https://zenodo.org/record/4775270},
  urldate = {2023-02-13},
  abstract = {Release {$<$}code{$>$}0.4.0{$<$}/code{$>$} of {$<$}code{$>$}cognitivefactory/interactive-clustering-gui{$<$}/code{$>$} package. {$<$}em{$>$}GitHub repository{$<$}/em{$>$} : https://github.com/cognitivefactory/interactive-clustering-gui/tree/0.4.0 {$<$}em{$>$}Main documentation{$<$}/em{$>$} : https://cognitivefactory.github.io/interactive-clustering-gui/ {$<$}em{$>$}Pypi distribution{$<$}/em{$>$} : https://pypi.org/project/cognitivefactory-interactive-clustering-gui/0.4.0/},
  organization = {{Zenodo}},
  version = {0.4.0},
  keywords = {*CITATION}
}

@article{schild-etal:2022:iterative-semisupervised-design,
  title = {Iterative and {{Semi-Supervised Design}} of {{Chatbots Using Interactive Clustering}}},
  shorttitle = {Iterative and {{Semi-Supervised Design}} of {{Chatbots Using Interactive Clustering}}},
  author = {Schild, Erwan and Durantin, Gautier and Lamirel, Jean-Charles and Miconi, Florian},
  date = {2022-04-01},
  journaltitle = {International Journal of Data Warehousing and Mining (IJDWM)},
  volume = {18},
  number = {2},
  pages = {1--19},
  issn = {1548-3924},
  doi = {10.4018/IJDWM.298007},
  url = {https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJDWM.298007},
  abstract = {Chatbots represent a promising tool to automate the processing of requests in a business context. However, despite major progress in natural language processing technologies, constructing a dataset deemed relevant by business experts is a manual, iterative and error-prone process. To assist these experts during modelling and labelling, the authors propose an active learning methodology coined Interactive Clustering. It relies on interactions between computer-guided segmentation of data in intents, and response-driven human annotations imposing constraints on clusters to improve relevance.This article applies Interactive Clustering on a realistic dataset, and measures the optimal settings required for relevant segmentation in a minimal number of annotations. The usability of the method is discussed in terms of computation time, and the achieved compromise between business relevance and classification performance during training.In this context, Interactive Clustering appears as a suitable methodology combining human and computer initiatives to efficiently develop a useable chatbot.},
  langid = {english},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,*PUBLICATION,INTERACTIVE\_CLUSTERING},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\QPFCLFA7\\Schild et al. - 2022 - Iterative and Semi-Supervised Design of Chatbots U.pdf;C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\TW3MBXVX\\Schild et al. - 2022 - Iterative and Semi-Supervised Design of Chatbots U.pdf}
}

@software{schild:2021:cognitivefactory-interactiveclusteringcomparativestudy,
  title = {Cognitivefactory/Interactive-Clustering-Comparative-Study},
  author = {SCHILD, Erwan},
  date = {2022-11-05},
  url = {https://zenodo.org/record/5648255},
  urldate = {2023-02-13},
  abstract = {Release {$<$}code{$>$}0.1.0{$<$}/code{$>$} of {$<$}code{$>$}cognitivefactory/interactive-clustering-comparative-study{$<$}/code{$>$} repository. {$<$}em{$>$}GitHub repository{$<$}/em{$>$} : https://github.com/cognitivefactory/interactive-clustering-comparative-study/tree/0.1.0},
  organization = {{Zenodo}},
  version = {0.1.0},
  keywords = {*CITATION,clustering,comparative-study,constraints,interactive-clustering,natural-language-processing,python}
}

@software{schild:2022:cognitivefactory-interactiveclustering,
  title = {Cognitivefactory/Interactive-Clustering},
  shorttitle = {Cognitivefactory/Interactive-Clustering},
  author = {SCHILD, Erwan},
  date = {2022-08-22},
  url = {https://zenodo.org/record/4775251},
  urldate = {2023-02-13},
  abstract = {Release {$<$}code{$>$}0.5.2{$<$}/code{$>$} of {$<$}code{$>$}cognitivefactory/interactive-clustering{$<$}/code{$>$} package. {$<$}em{$>$}GitHub repository{$<$}/em{$>$} : https://github.com/cognitivefactory/interactive-clustering/tree/0.5.2 {$<$}em{$>$}Main documentation{$<$}/em{$>$} : https://cognitivefactory.github.io/interactive-clustering/ {$<$}em{$>$}Pypi distribution{$<$}/em{$>$} : https://pypi.org/project/cognitivefactory-interactive-clustering/0.5.2/},
  organization = {{Zenodo}},
  version = {0.5.2},
  keywords = {*CITATION}
}

@misc{schild:2022:french-trainset-chatbots,
  title = {French trainset for chatbots dealing with usual requests on bank cards},
  author = {SCHILD, Erwan},
  date = {2022-11-09},
  publisher = {{Zenodo}},
  url = {https://zenodo.org/record/4769949},
  urldate = {2023-02-13},
  abstract = {{$<$}strong{$>$}[EN] French training dataset for chatbots dealing with usual requests on bank cards.{$<$}/strong{$>$} {$<$}strong{$>$}Description{$<$}/strong{$>$}: This dataset represents examples of common customer requests relating to bank cards management. It can be used as a training set for a small chatbot intended to process these usual requests. {$<$}strong{$>$}Content{$<$}/strong{$>$}: The questions are asked in French. The dataset is divided into 10 intents of 100 questions each, for a total of 1 000 questions. {$<$}strong{$>$}Intents scope{$<$}/strong{$>$}: Intents are constructed in such a way that all questions arising from the same intention have the same response or action. The scope covered concerns: loss or theft of cards; the swallowed card; the card order; consultation of the bank balance; insurance provided by a card; card unlocking; virtual card management; management of bank overdraft; management of payment limits; management of contactless mode. {$<$}strong{$>$}Origin{$<$}/strong{$>$}: Intents scope is inspired by a chatbot currently in production, and the wording of the questions are inspired by the usual customers requests. {$<$}br{$>$} {$<$}strong{$>$}[FR] Jeu d'entraînement en français d'assistants conversationnels traitant des demandes courantes sur les cartes bancaires.{$<$}/strong{$>$} {$<$}strong{$>$}Description {$<$}/strong{$>$}: Cet ensemble de données représente des exemples de demandes usuelles des clients concernant la gestion des cartes bancaires. Il peut être utilisé comme jeu d'entraînement pour un assistant conversationnel destiné à traiter ces demandes courantes. {$<$}strong{$>$}Contenu {$<$}/strong{$>$}: Les questions sont formulées en français. L'ensemble de données est divisé en 10 intentions de 100 questions chacune, pour un total de 1 000 questions. {$<$}strong{$>$}Périmètre des intentions{$<$}/strong{$>$} : Les intentions sont construites de telle manière que toutes les questions issues d'une même intention ont la même réponse ou action. Le périmètre couvert concerne : la perte ou le vol de cartes ; la carte avalée ; la commande des cartes ; la consultation du solde bancaire ; l'assurance fournie par une carte ; le déverrouillage de la carte ; la gestion de cartes virtuelles ; la gestion du découvert bancaire ; la gestion des plafonds de paiement ; la gestion du mode sans contact. {$<$}strong{$>$}Origine {$<$}/strong{$>$}: Le périmètre des intentions est inspiré par un chatbot actuellement en production, et la formulation des questions est inspirée de demandes courantes de clients.},
  langid = {french},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,*PUBLICATION,Bank cards management,Chatbot,Natural Language Processing,Trainset},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\2YJEM4BD\\French_trainset_for_chatbots_dealing_with_usual_requests_on_bank_cards_v1.0.0.xlsx;C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\FGW9EV2H\\French_trainset_for_chatbots_dealing_with_usual_requests_on_bank_cards_v2.0.0_UNLABELED.xlsx;C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\KYG43CY9\\French_trainset_for_chatbots_dealing_with_usual_requests_on_bank_cards_v2.0.0.xlsx}
}

@software{schild:2023:cognitivefactory-featuresmaximizationmetric,
  title = {Cognitivefactory/Features-Maximization-Metric},
  shorttitle = {Cognitivefactory/Features-Maximization-Metric},
  author = {SCHILD, Erwan},
  date = {2023-02-16},
  url = {https://zenodo.org/record/7646382},
  urldate = {2023-02-16},
  abstract = {Release {$<$}code{$>$}0.1.1{$<$}/code{$>$} of {$<$}code{$>$}cognitivefactory/features-maximization-metric{$<$}/code{$>$} package. {$<$}em{$>$}GitHub repository{$<$}/em{$>$} : https://github.com/cognitivefactory/features-maximization-metric/tree/0.1.1 {$<$}em{$>$}Main documentation{$<$}/em{$>$} : https://cognitivefactory.github.io/features-maximization-metric/ {$<$}em{$>$}Pypi distribution{$<$}/em{$>$} : https://pypi.org/project/cognitivefactory-features-maximization-metric/0.1.1/},
  organization = {{Zenodo}},
  version = {0.1.1},
  keywords = {*CITATION}
}

@online{scialom-etal:2020:mlsum-multilingual-summarization,
  title = {{{MLSUM}}: {{The Multilingual Summarization Corpus}}},
  shorttitle = {{{MLSUM}}},
  author = {Scialom, Thomas and Dray, Paul-Alexis and Lamprier, Sylvain and Piwowarski, Benjamin and Staiano, Jacopo},
  date = {2020-04-30},
  eprint = {2004.14900},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2004.14900},
  urldate = {2023-06-07},
  abstract = {We present MLSUM, the first large-scale MultiLingual SUMmarization dataset. Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -- namely, French, German, Spanish, Russian, Turkish. Together with English newspapers from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community. We report cross-lingual comparative analyses based on state-of-the-art systems. These highlight existing biases which motivate the use of a multi-lingual dataset.},
  pubstate = {preprint},
  keywords = {*CITATION,*LU/IMPLÉMENTÉ,Computer Science - Computation and Language},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\3JYCXTTG\\mlsum_fr_train_subset_v1.0.0.schild.xlsx;C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\SJDKVTSQ\\Scialom et al. - 2020 - MLSUM The Multilingual Summarization Corpus.pdf;C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\VN46BQAB\\mlsum_fr_train_subset_v1.0.0.schild_UNLABELLED.xlsx;C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\8GN4N6TU\\2004.html}
}

@inproceedings{seabold-perktold:2010:statsmodels-econometric-statistical,
  title = {Statsmodels: {{Econometric}} and {{Statistical Modeling}} with {{Python}}},
  shorttitle = {Statsmodels},
  author = {Seabold, Skipper and Perktold, Josef},
  date = {2010},
  pages = {92--96},
  location = {{Austin, Texas}},
  doi = {10.25080/Majora-92bf1922-011},
  url = {https://conference.scipy.org/proceedings/scipy2010/seabold.html},
  urldate = {2023-07-07},
  eventtitle = {Python in {{Science Conference}}},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\N79637BD\\Seabold et Perktold - 2010 - Statsmodels Econometric and Statistical Modeling .pdf}
}

@article{settles:2010:active-learning-literature,
  title = {Active {{Learning Literature Survey}}},
  author = {Settles, Burr},
  date = {2010},
  pages = {67},
  abstract = {The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns. An active learner may pose queries, usually in the form of unlabeled data instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant or easily obtained, but labels are difficult, time-consuming, or expensive to obtain. This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for successful active learning, a summary of problem setting variants and practical issues, and a discussion of related topics in machine learning research are also presented.},
  langid = {english},
  keywords = {*CITATION,⛔ No DOI found,Active learning},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\SRWU4YSI\\Settles - 2010 - Active Learning Literature Survey.pdf}
}

@article{snow-etal:2008:cheap-fast-it,
  title = {Cheap and {{Fast}} - {{But}} Is It {{Good}}? {{Evaluating Non-Expert Annotations}} for {{Natural Language Tasks}}},
  author = {Snow, Rion and O'Connor, Brendan and Jurafsky, Daniel and Ng, Andrew},
  date = {2008-10},
  journaltitle = {Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing},
  pages = {254--263},
  abstract = {Human linguistic annotation is crucial for many natural language processing tasks but can be expensive and time-consuming. We explore the use of Amazon’s Mechanical Turk system, a significantly cheaper and faster method for collecting annotations from a broad base of paid non-expert contributors over the Web. We investigate five tasks: affect recognition, word similarity, recognizing textual entailment, event temporal ordering, and word sense disambiguation. For all five, we show high agreement between Mechanical Turk non-expert annotations and existing gold standard labels provided by expert labelers. For the task of affect recognition, we also show that using non-expert labels for training machine learning algorithms can be as effective as using gold standard annotations from experts. We propose a technique for bias correction that significantly improves annotation quality on two tasks. We conclude that many large labeling tasks can be effectively designed and carried out in this method at a fraction of the usual expense.},
  langid = {english},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\7UTBTBGX\\Snow et al. - 2008 - Cheap and Fast - But is it Good Evaluating Non-Ex.pdf}
}

@article{sparck-jones:1972:statistical-interpretation-term,
  title = {A Statistical Interpretation of Term Specificity and Its Application in Retrieval},
  author = {Sparck Jones, Karen},
  date = {1972-01},
  journaltitle = {Journal of Documentation},
  volume = {28},
  number = {1},
  pages = {11--21},
  issn = {0022-0418},
  doi = {10.1108/eb026526},
  url = {https://www.emerald.com/insight/content/doi/10.1108/eb026526/full/html},
  urldate = {2023-07-06},
  langid = {english},
  keywords = {*CITATION,TF-IDF,Vectorization}
}

@article{thorndike:1953:who-belongs-family,
  title = {Who Belongs in the Family?},
  author = {Thorndike, Robert L.},
  date = {1953-12},
  journaltitle = {Psychometrika},
  volume = {18},
  number = {4},
  pages = {267--276},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02289263},
  url = {http://link.springer.com/10.1007/BF02289263},
  urldate = {2023-07-06},
  langid = {english},
  keywords = {*CITATION,Elbow}
}

@article{tukey:1949:comparing-individual-means,
  title = {Comparing {{Individual Means}} in the {{Analysis}} of {{Variance}}},
  author = {Tukey, John W.},
  date = {1949-06},
  journaltitle = {Biometrics},
  volume = {5},
  number = {2},
  eprint = {3001913},
  eprinttype = {jstor},
  pages = {99},
  issn = {0006341X},
  doi = {10.2307/3001913},
  url = {https://www.jstor.org/stable/3001913?origin=crossref},
  urldate = {2023-07-06},
  keywords = {*CITATION}
}

@book{van-rossum-drake:2009:python-reference-manual,
  title = {Python 3 {{Reference Manual}}},
  author = {Van Rossum, Guido and Drake, Fred L.},
  date = {2009},
  edition = {CreateSpace},
  location = {{Scotts Valley, CA}},
  isbn = {1-4414-1269-7},
  keywords = {*CITATION}
}

@article{wagstaff-cardie:2000:clustering-instancelevel-constraints,
  title = {Clustering with {{Instance-level Constraints}}},
  author = {Wagstaff, Kiri and Cardie, Claire},
  date = {2000},
  journaltitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
  pages = {1103--1110},
  abstract = {Clustering algorithms conduct a search through the space of possible organizations of a data set. In this paper, we propose two types of instance-level clustering constraints – must-link and cannot-link constraints – and show how they can be incorporated into a clustering algorithm to aid that search. For three of the four data sets tested, our results indicate that the incorporation of surprisingly few such constraints can increase clustering accuracy while decreasing runtime. We also investigate the relative effects of each type of constraint and find that the type that contributes most to accuracy improvements depends on the behavior of the clustering algorithm without constraints.},
  langid = {english},
  keywords = {*CITATION,⛔ No DOI found,Clustering,Constrained clustering,Contraintes,INTERACTIVE\_CLUSTERING,Must-link and Cannot-Link},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\8WNCENKV\\Wagstaﬀ et Cardie - 2000 - Clustering with Instance-level Constraints.pdf}
}

@inproceedings{wagstaff-etal:2001:constrained-kmeans-clustering,
  title = {Constrained {{K-means}} Clustering with Background Knowledge},
  author = {Wagstaff, Kiri and Cardie, Claire and Rogers, Seth and Schrödl, Stefan},
  date = {2001-01},
  series = {Proceedings of 18th {{International Conference}} on {{Machine Learning}}},
  pages = {577--584},
  keywords = {*CITATION},
  file = {C\:\\Users\\SCHILDEW\\Documents\\Zotero\\storage\\TGGJZZWD\\Wagstaff et al. - 2001 - Constrained K-means clustering with background kno.pdf}
}

@article{xu-tian:2015:comprehensive-survey-clustering,
  title = {A {{Comprehensive Survey}} of {{Clustering Algorithms}}},
  author = {Xu, Dongkuan and Tian, Yingjie},
  date = {2015},
  journaltitle = {Annals of Data Science},
  volume = {2},
  pages = {165--193},
  abstract = {Data analysis is used as a common method in modern science research, which is across communication science, computer science and biology science. Clustering, as the basic composition of data analysis, plays a significant role. On one hand, many tools for cluster analysis have been created, along with the information increase and subject intersection. On the other hand, each clustering algorithm has its own strengths and weaknesses, due to the complexity of information. In this review paper, we begin at the definition of clustering, take the basic elements involved in the clustering process, such as the distance or similarity measurement and evaluation indicators, into consideration, and analyze the clustering algorithms from two perspectives, the traditional ones and the modern ones. All the discussed clustering algorithms will be compared in detail and comprehensively shown in Appendix Table 22.},
  keywords = {*CITATION,Clustering,Comparaison}
}
