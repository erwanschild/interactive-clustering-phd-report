<!DOCTYPE html>
<html><head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>Rapport Zotero</title>
		<link rel="stylesheet" type="text/css" href="data:text/css;base64,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">
		<link rel="stylesheet" type="text/css" media="screen,projection" href="data:text/css;base64,LyogR2VuZXJpYyBzdHlsZXMgKi8KYm9keSB7Cglmb250OiA2Mi41JSBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cgl3aWR0aDogNzgwcHg7CgltYXJnaW46IDAgYXV0bzsKfQoKaDIgewoJZm9udC1zaXplOiAxLjVlbTsKCWxpbmUtaGVpZ2h0OiAxLjVlbTsKCWZvbnQtZmFtaWx5OiBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cn0KCnAgewoJbGluZS1oZWlnaHQ6IDEuNWVtOwp9CgphOmxpbmssIGE6dmlzaXRlZCB7Cgljb2xvcjogIzkwMDsKfQoKYTpob3ZlciwgYTphY3RpdmUgewoJY29sb3I6ICM3Nzc7Cn0KCgp1bC5yZXBvcnQgewoJZm9udC1zaXplOiAxLjRlbTsKCXdpZHRoOiA2ODBweDsKCW1hcmdpbjogMCBhdXRvOwoJcGFkZGluZzogMjBweCAyMHB4Owp9CgovKiBNZXRhZGF0YSB0YWJsZSAqLwp0YWJsZSB7Cglib3JkZXI6IDFweCAjY2NjIHNvbGlkOwoJb3ZlcmZsb3c6IGF1dG87Cgl3aWR0aDogMTAwJTsKCW1hcmdpbjogLjFlbSBhdXRvIC43NWVtOwoJcGFkZGluZzogMC41ZW07Cn0K">
		<link rel="stylesheet" type="text/css" media="print" href="data:text/css;base64,Ym9keSB7Cglmb250OiAxMnB0ICJUaW1lcyBOZXcgUm9tYW4iLCBUaW1lcywgR2VvcmdpYSwgc2VyaWY7CgltYXJnaW46IDA7Cgl3aWR0aDogYXV0bzsKCWNvbG9yOiBibGFjazsKfQoKLyogUGFnZSBCcmVha3MgKHBhZ2UtYnJlYWstaW5zaWRlIG9ubHkgcmVjb2duaXplZCBieSBPcGVyYSkgKi8KaDEsIGgyLCBoMywgaDQsIGg1LCBoNiB7CglwYWdlLWJyZWFrLWFmdGVyOiBhdm9pZDsKCXBhZ2UtYnJlYWstaW5zaWRlOiBhdm9pZDsKfQoKdWwsIG9sLCBkbCB7CglwYWdlLWJyZWFrLWluc2lkZTogYXZvaWQ7Cgljb2xvci1hZGp1c3Q6IGV4YWN0Owp9CgpoMiB7Cglmb250LXNpemU6IDEuM2VtOwoJbGluZS1oZWlnaHQ6IDEuM2VtOwp9CgphIHsKCWNvbG9yOiAjMDAwOwoJdGV4dC1kZWNvcmF0aW9uOiBub25lOwp9Cg==">
	</head>
	<body>
		<ul class="report combineChildItems">
			<li id="item_SPKXXUKR" class="item journalArticle">
			<h2>A Comprehensive Survey of Clustering Algorithms</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dongkuan Xu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yingjie Tian</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>165-193</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Annals of Data Science</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2015</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: xu-tian:2015:comprehensive-survey-clustering</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Data analysis is used as a common method in modern science 
research, which is across communication science, computer science and 
biology science. Clustering, as the basic composition of data analysis, 
plays a significant role. On one hand, many tools for cluster analysis 
have been created, along with the information increase and subject 
intersection. On the other hand, each clustering algorithm has its own 
strengths and weaknesses, due to the complexity of information. In this 
review paper, we begin at the definition of clustering, take the basic 
elements involved in the clustering process, such as the distance or 
similarity measurement and evaluation indicators, into consideration, 
and analyze the clustering algorithms from two perspectives, the 
traditional ones and the modern ones. All the discussed clustering 
algorithms will be compared in detail and comprehensively shown in 
Appendix Table 22.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/10/2020 à 19:40:55</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:58</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>Comparaison</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_JB5YJDF6">Xu et Tian - 2015 - A Comprehensive Survey of Clustering Algorithms.pdf					</li>
				</ul>
			</li>


			<li id="item_C5DARTJI" class="item journalArticle">
			<h2>A Comprehensive Survey on Transfer Learning</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Fuzhen Zhuang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zhiyuan Qi</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Keyu Duan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dongbo Xi</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yongchun Zhu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hengshu Zhu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hui Xiong</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Qing He</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/9134370/">https://ieeexplore.ieee.org/document/9134370/</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>109</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>43-76</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Proceedings of the IEEE</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0018-9219, 1558-2256</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: zhuang-etal:2021:comprehensive-survey-transfer</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Proc. IEEE</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/JPROC.2020.3004555">10.1109/JPROC.2020.3004555</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 14:53:40</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Deep learning has been the answer to many machine learning 
problems during the past two decades. However, it comes with two 
significant constraints: dependency on extensive labeled data and 
training costs. Transfer learning in deep learning, known as Deep 
Transfer Learning (DTL), attempts to reduce such reliance and costs by 
reusing obtained knowledge from a source data/task in training on a 
target data/task. Most applied DTL techniques are network/model-based 
approaches. These methods reduce the dependency of deep learning models 
on extensive training data and drastically decrease training costs. 
Moreover, the training cost reduction makes DTL viable on edge devices 
with limited resources. Like any new advancement, DTL methods have their
 own limitations, and a successful transfer depends on specific 
adjustments and strategies for different scenarios. This paper reviews 
the concept, definition, and taxonomy of deep transfer learning and 
well-known methods. It investigates the DTL approaches by reviewing 
applied DTL techniques in the past five years and a couple of 
experimental analyses of DTLs to discover the best practice for using 
DTL in different scenarios. Moreover, the limitations of DTLs 
(catastrophic forgetting dilemma and overly biased pre-trained models) 
are discussed, along with possible solutions and research trends.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 14:53:40</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:58:54</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_PRYF889G">Zhuang et al. - 2021 - A Comprehensive Survey on Transfer Learning.pdf					</li>
				</ul>
			</li>


			<li id="item_MCMPMVC9" class="item journalArticle">
			<h2>A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Martin Ester</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hans-Peter Kriegel</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Xiaowei Xu</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1996</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: ester-etal:1996:densitybased-algorithm-discovering</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Clustering algorithm as reattractive for the task of class 
identification in spatial databases. Howevetrh, e applicationto large 
spatial databasesrises the followingrequirementfsor clustering 
algorithms: minimalrequirementsof domain knowledgteo determinethe input 
parameters,discoveryof clusters 
witharbitraryshapeandgoodefficiencyonlarge databases. 
Thewell-knowcnlusteringalgorithmsoffer nosolution to the combinatioonf 
theserequirementsI.n this paper, wepresent the newclustering 
algorithmDBSCAreNlying on a density-basednotionof clusters whichis 
designedto discoverclusters of arbitrary shape.DBSCrAeNquiresonly one 
input parameterandsupportsthe user in determiningan appropriatevaluefor 
it. Weperformeadn experimentaelvaluation of the effectiveness and 
efficiency of DBSCAusNing synthetic data and real data of the 
SEQUO2IA000benchmark.Theresults of our experimentsdemonstratethat (1) 
DBSCiAsNsignificantlymoreeffective in discoveringclusters of arbitrary 
shapethan the well-knowanlgorithmCLARANS,and that (2) DBSCAoNutperforms 
CLARANbyS factorof morethan100in termsof efficiency.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>12/01/2023 à 13:43:45</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>17/10/2023 à 15:57:34</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>DBScan</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_XA8UZCX5">Ester et al. - 1996 - A Density-Based Algorithm for Discovering Clusters.pdf					</li>
				</ul>
			</li>


			<li id="item_K3VJY7NV" class="item thesis">
			<h2>A Methodology for Using Professional Knowledge in Corpus</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Thèse</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Amber C. Stubbs</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2013</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: stubbs:2013:methodology-using-professional</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>14/06/2021 à 10:06:30</td>
					</tr>
					<tr>
					<th>Type</th>
						<td>Dissertation</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Université</th>
						<td>Brandeis University</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>It is a well-known problem that performing linguistic 
annotation over a corpus can be an expensive and time-consuming task. 
The problem of annotation becomes even more difficult to solve when the 
task is based around a domain-specific corpus or specification. For 
example, extracting diagnosis information from clinical notes must be 
done by someone with sufficient medical training, who can understand all
 of the medical jargon and determine if a diagnosis can be made. 
However, hiring medical professionals to perform syntactic or semantic 
annotations can be extremely expensive, and few domain-expert annotators
 will have the time to create such an annotation. 
This dissertation aims at finding a way to capture expert domain 
knowledge quickly and easily as annotations, and in a format where the 
information can then be used for more advanced natural language 
processing (NLP) tasks. To that end, this dissertation proposes the use 
of light annotation tasks: linguistically under-specified, task- and 
domain-specific annotation models that can quickly capture expert 
knowledge in a corpus as it relates to a research question. The corpora 
created from light annotation tasks can then be augmented with 
additional, denser annotations (such as part-of-speech tagging), or used
 directly with an NLP system. 
In addition to defining the light annotation task, this dissertation 
presents a set of principles that can be used to create annotation tasks
 for domain experts. These principles are based on examining other 
“light” annotations, as well as the existing standards and methodologies
 used in more traditional annotation research. Software designed for 
light annotation projects is also presented. 
Finally, in order to illustrate the utility of light annotations, a case
 study based around the medical research task of finding patients 
qualified to participate in a clinical study is presented. The medical 
settings that influence the case study&amp;#39;s design are discussed, 
and the light annotation task&amp;#39;s implementation is analyzed. The 
resulting corpus (called the Patient Evaluation Resource for Medical 
Information in Text (PERMIT) corpus) is then leveraged into a 
preliminary NLP system, which demonstrates the versatility of the light 
annotation methodology.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>14/06/2021 à 10:06:30</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>31/08/2023 à 11:18:48</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_T47FZS2F">Stubbs - 2013 - A Methodology for Using Professional Knowledge in .pdf					</li>
				</ul>
			</li>


			<li id="item_GU35E6S8" class="item journalArticle">
			<h2>A model for types and levels of human interaction with automation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>R. Parasuraman</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>T.B. Sheridan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>C.D. Wickens</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/844354/">http://ieeexplore.ieee.org/document/844354/</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>30</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>286-297</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>10834427</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2000-05</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: parasuraman-etal:2000:model-types-levels</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>IEEE Trans. Syst., Man, Cybern. A</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/3468.844354">10.1109/3468.844354</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>01/09/2023 à 16:51:13</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>01/09/2023 à 16:51:13</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:50:48</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_JNZR94XP">Parasuraman et al. - 2000 - A model for types and levels of human interaction .pdf					</li>
				</ul>
			</li>


			<li id="item_DKHGCGAE" class="item bookSection">
			<h2>A Novel Approach to Feature Selection Based on Quality Estimation Metrics</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Fabrice Guillet</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Bruno Pinaud</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Gilles Venturini</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jean-Charles Lamirel</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Pascal Cuxac</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kafil Hajlaoui</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-319-45763-5_7">http://link.springer.com/10.1007/978-3-319-45763-5_7</a></td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Studies in Computational Intelligence</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>665</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>121-140</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-45762-8 978-3-319-45763-5</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: lamirel-etal:2017:novel-approach-feature</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>23/11/2018 à 16:37:42</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Crossref</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Feature maximization (F-max) is an unbiased quality estimation
 metric of unsupervised classiﬁcation (clustering) that favours clusters
 with a maximal feature F-measure value. In this article we show that an
 adaptation of this metric within the framework of supervised 
classiﬁcation allows efﬁcient feature selection and feature contrasting 
to be performed. We experiment the method on different types of textual 
data. In this context, we demonstrate that this technique signiﬁcantly 
improves the performance of classiﬁcation methods as compared with the 
use of state-of-the art feature selection techniques, notably in the 
case of the classiﬁcation of unbalanced, highly multidimensional and 
noisy textual data gathered in similar classes.</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Advances in Knowledge Discovery and Management</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/11/2018 à 16:37:42</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>11/07/2023 à 15:23:53</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Filters</li>
					<li>Multidimensional data</li>
					<li>Evaluation metrics</li>
					<li>Features selection</li>
					<li>FMC</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_QHURTRCV">Lamirel et al. - 2017 - A Novel Approach to Feature Selection Based on Qua.pdf						<div class="note"><div><p><strong><span style="text-decoration: underline;">SUMMARY OF THE ARTICLE</span> :</strong></p>
<ul>
<li><strong>Goal</strong> : Feature selection
<ul>
<li>Evaluate classification with a clustering metrics</li>
<li>Problem : Multidimensional data, unbalanced classes, ...</li>
</ul>
</li>
<li><strong>Main idea</strong> :
<ul>
<li>Select "active features" for each class with a filter-based method</li>
<li>Compute a contrast factor for each feature and each class</li>
<li>Evaluate each class with the contrast</li>
</ul>
</li>
<li><strong>Definition</strong> :
<ul>
<li>The F-Measure is the harmonic mean of the Feature Recall and the Feature Predominance</li>
<li>A feature is "active" for a class if its F-Measure is greater than 
the average of F-Measure for all class and greater than the overall 
average of F-Measure</li>
<li>The Contrast is just the ratio between the F-Mesure and the overall average of F-Measure</li>
</ul>
</li>
<li><strong>Advantage</strong> :
<ul>
<li>Work on highly multidimensional data</li>
<li>Work on noisy data</li>
<li>Work on unbalanced classes</li>
<li>Flexible method adaptable on several classifiers</li>
<li>Low computation cost</li>
<li>Usable on main context : supervised, semi-supervised, ...</li>
</ul>
</li>
<li><strong>Results</strong> :
<ul>
<li>Basis : Bad performances without feature selection on unbalanced classes</li>
<li>With classical feature selection : Lower performances</li>
<li>With FMC : between +22% and +90% gain of performances</li>
</ul>
</li>
<li><strong>Example</strong> :
<ul>
<li>Classification problem between Men and Women</li>
<li>Feature : Hair size, Shoes size, Nose size</li>
<li>Feature selection : Nose size is irrelevant</li>
<li>Active Feature : Hair size is active for Women, Shoes size is active for Men</li>
<li>Apply contrast to focus on active features</li>
</ul>
</li>
</ul></div>
					</div>					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_4FGJ9FQE">Feature Selection for Machine Learning: Comparing a  Correlation-based Filter Approach to the Wrapper</li>
					<li id="item_G7B9BM7W">An Introduction to Variable and Feature Selection</li>
					<li id="item_GN6PCYHJ">The feature selection problem - Traditional methods and a new algorithm</li>
					<li id="item_J9H6ZK9K">Wrappers for feature subset selection</li>
					<li id="item_NYA6F76Z">Optimizing text classification through efficient feature selection based on quality metric</li>
					<li id="item_QMYU6ICQ">Consistency-based search in feature selection</li>
					<li id="item_SJ9JW8AA">Gene Selection for Cancer Classification using Support Vector Machines</li>
					<li id="item_UC7KPBAK">Data Mining: Practical Machine Learning Tools and Techniques</li>
					<li id="item_UDBF6YIP">Estimating attributes: Analysis and extensions of RELIEF</li>
					<li id="item_W38CZ8R2">Fast feature selection using partial correlation for multi-valued attributes</li>
					<li id="item_ZE9PPUK4">FEATURE SELECTION METHODS AND ALGORITHMS</li>
				</ul>
			</li>


			<li id="item_LSA4QKQK" class="item journalArticle">
			<h2>A Review of Deep Transfer Learning and Recent Advancements</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mohammadreza Iman</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hamid Reza Arabnia</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Khaled Rasheed</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.mdpi.com/2227-7080/11/2/40">https://www.mdpi.com/2227-7080/11/2/40</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>11</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>40</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Technologies</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2227-7080</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-03-14</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: iman-etal:2023:review-deep-transfer</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Technologies</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.3390/technologies11020040">10.3390/technologies11020040</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 14:55:20</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Deep learning has been the answer to many machine learning 
problems during the past two decades. However, it comes with two 
signiﬁcant constraints: dependency on extensive labeled data and 
training costs. Transfer learning in deep learning, known as Deep 
Transfer Learning (DTL), attempts to reduce such reliance and costs by 
reusing obtained knowledge from a source data/task in training on a 
target data/task. Most applied DTL techniques are network/model-based 
approaches. These methods reduce the dependency of deep learning models 
on extensive training data and drastically decrease training costs. 
Moreover, the training cost reduction makes DTL viable on edge devices 
with limited resources. Like any new advancement, DTL methods have their
 own limitations, and a successful transfer depends on speciﬁc 
adjustments and strategies for different scenarios. This paper reviews 
the concept, deﬁnition, and taxonomy of deep transfer learning and 
well-known methods. It investigates the DTL approaches by reviewing 
applied DTL techniques in the past ﬁve years and a couple of 
experimental analyses of DTLs to discover the best practice for using 
DTL in different scenarios. Moreover, the limitations of DTLs 
(catastrophic forgetting dilemma and overly biased pre-trained models) 
are discussed, along with possible solutions and research trends.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 14:55:20</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:59:20</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_IE6I9DG4">Iman et al. - 2023 - A Review of Deep Transfer Learning and Recent Adva.pdf					</li>
				</ul>
			</li>


			<li id="item_YTDZSVZ4" class="item journalArticle">
			<h2>A review: Data pre-processing and data augmentation techniques</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kiran Maharana</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Surajit Mondal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Bhushankumar Nemade</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://linkinghub.elsevier.com/retrieve/pii/S2666285X22000565">https://linkinghub.elsevier.com/retrieve/pii/S2666285X22000565</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>91-99</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Global Transitions Proceedings</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2666285X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: maharana-etal:2022:review-data-preprocessing</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Global Transitions Proceedings</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.gltp.2022.04.020">10.1016/j.gltp.2022.04.020</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 10:53:40</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This review paper provides an overview of data pre-processing 
in Machine learning, focusing on all types of problems while building 
the machine learning problems. It deals with two significant issues in 
the pre-processing process (i). issues with data and (ii). Steps to 
follow to do data analysis with its best approach. As raw data are 
vulnerable to noise, corruption, missing, and inconsistent data, it is 
necessary to perform pre-processing steps, which is done using 
classification, clustering, and association and many other 
pre-processing techniques available. Poor data can primarily affect the 
accuracy and lead to false prediction, so it is necessary to improve the
 dataset's quality. So, data pre-processing is the best way to deal with
 such problems. It makes the knowledge extraction from the data set much
 easier with cleaning, Integration, transformation, and reduction 
methods. The issue with Data missing and significant differences in the 
variety of data always exists as the information is collected through 
multiple sources and from a real-world application. So, the data 
augmentation approach generates data for machine learning models. To 
decrease the dependency on training data and to improve the performance 
of the machine learning model. This paper discusses flipping, rotating 
with slight degrees and others to augment the image data and shows how 
to perform data augmentation methods without distorting the original 
data.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>A review</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 10:53:40</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:00:41</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_9S4LRJFI">
<div><div data-schema-version="8"><p><strong>NOTES ERWAN</strong>:</p>
<ul>
<li>
Besoin de prétraiter les données
</li>
</ul>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_IE547ETH">Maharana et al. - 2022 - A review Data pre-processing and data augmentatio.pdf					</li>
				</ul>
			</li>


			<li id="item_PP2L2DG5" class="item journalArticle">
			<h2>A statistical interpretation of term specificity and its application in retrieval</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Karen Sparck Jones</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.emerald.com/insight/content/doi/10.1108/eb026526/full/html">https://www.emerald.com/insight/content/doi/10.1108/eb026526/full/html</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>28</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>11-21</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of Documentation</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0022-0418</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1972-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: sparck-jones:1972:statistical-interpretation-term</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Journal of Documentation</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1108/eb026526">10.1108/eb026526</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 15:19:05</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 15:19:05</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:48:51</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>TF-IDF</li>
					<li>Vectorization</li>
				</ul>
			</li>


			<li id="item_9QAMEW3R" class="item journalArticle">
			<h2>A Survey on Deep Learning for Named Entity Recognition</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jing Li</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Aixin Sun</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jianglei Han</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Chenliang Li</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/9039685/">https://ieeexplore.ieee.org/document/9039685/</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>34</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>50-70</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IEEE Transactions on Knowledge and Data Engineering</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1041-4347, 1558-2191, 2326-3865</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-01-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: li-etal:2022:survey-deep-learning</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>IEEE Trans. Knowl. Data Eng.</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/TKDE.2020.2981314">10.1109/TKDE.2020.2981314</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>18/09/2023 à 15:13:45</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Named entity recognition (NER) is the task to identify 
mentions of rigid designators from text belonging to predefined semantic
 types such as person, location, organization etc. NER always serves as 
the foundation for many natural language applications such as question 
answering, text summarization, and machine translation. Early NER 
systems got a huge success in achieving good performance with the cost 
of human engineering in designing domain-specific features and rules. In
 recent years, deep learning, empowered by continuous real-valued vector
 representations and semantic composition through nonlinear processing, 
has been employed in NER systems, yielding stat-of-the-art performance. 
In this paper, we provide a comprehensive review on existing deep 
learning techniques for NER. We first introduce NER resources, including
 tagged NER corpora and off-the-shelf NER tools. Then, we systematically
 categorize existing works based on a taxonomy along three axes: 
distributed representations for input, context encoder, and tag decoder.
 Next, we survey the most representative methods for recent applied 
techniques of deep learning in new NER problem settings and 
applications. Finally, we present readers with the challenges faced by 
NER systems and outline future directions in this area.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 15:13:45</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:01:22</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_KKWA3GMY">Li et al. - 2022 - A Survey on Deep Learning for Named Entity Recogni.pdf					</li>
				</ul>
			</li>


			<li id="item_5PMYGVXE" class="item journalArticle">
			<h2>A Survey on Dialogue Systems: Recent Advances and New Frontiers</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hongshen Chen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Xiaorui Liu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dawei Yin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jiliang Tang</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://dl.acm.org/doi/10.1145/3166054.3166058">https://dl.acm.org/doi/10.1145/3166054.3166058</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>19</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>25-35</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ACM SIGKDD Explorations Newsletter</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1931-0145, 1931-0153</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-11-21</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: chen-etal:2017:survey-dialogue-systems</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>SIGKDD Explor. Newsl.</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3166054.3166058">10.1145/3166054.3166058</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>26/07/2023 à 13:38:52</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Dialogue systems have attracted more and more attention. 
Recent advances on dialogue systems are overwhelmingly contributed by 
deep learning techniques, which have been employed to enhance a wide 
range of big data applications such as computer vision, natural language
 processing, and recommender systems. For dialogue systems, deep 
learning can leverage a massive amount of data to learn meaningful 
feature representations and response generation strategies, while 
requiring a minimum amount of hand-crafting. In this article, we give an
 overview to these recent advances on dialogue systems from various 
perspectives and discuss some possible research directions. In 
particular, we generally divide existing dialogue systems into 
task-oriented and nontask- oriented models, then detail how deep 
learning techniques help them with representative algorithms and finally
 discuss some appealing research directions that can bring the dialogue 
system research into a new frontier</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>A Survey on Dialogue Systems</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/07/2023 à 13:38:52</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:21:15</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*ALIRE/AIMPLÉMENTER</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_KPXQPKSJ">
<div><div data-schema-version="8"><p>NOTES DE LECTURE</p>
<ul>
<li>
<strong>task-oriented</strong>: #TODO
</li>
<li>
<strong>chat-oriented</strong>: #TODO
</li>
</ul>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_S2RHDJ72">Chen et al. - 2017 - A Survey on Dialogue Systems Recent Advances and .pdf					</li>
				</ul>
			</li>


			<li id="item_PL99QISY" class="item journalArticle">
			<h2>A survey on Image Data Augmentation for Deep Learning</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Connor Shorten</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Taghi M. Khoshgoftaar</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0">https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>6</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>60</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of Big Data</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2196-1115</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: shorten-khoshgoftaar:2019:survey-image-data</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>J Big Data</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1186/s40537-019-0197-0">10.1186/s40537-019-0197-0</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 10:59:22</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Deep convolutional neural networks have performed remarkably 
well on many Computer Vision tasks. However, these networks are heavily 
reliant on big data to avoid overfitting. Overfitting refers to the 
phenomenon when a network learns a function with very high variance such
 as to perfectly model the training data. Unfortunately, many 
application domains do not have access to big data, such as medical 
image analysis. This survey focuses on Data Augmentation, a data-space 
solution to the problem of limited data. Data Augmentation encompasses a
 suite of techniques that enhance the size and quality of training 
datasets such that better Deep Learning models can be built using them. 
The image augmentation algorithms discussed in this survey include 
geometric transformations, color space augmentations, kernel filters, 
mixing images, random erasing, feature space augmentation, adversarial 
training, generative adversarial networks, neural style transfer, and 
meta-learning. The application of augmentation methods based on GANs are
 heavily covered in this survey. In addition to augmentation techniques,
 this paper will briefly discuss other characteristics of Data 
Augmentation such as test-time augmentation, resolution impact, final 
dataset size, and curriculum learning. This survey will present existing
 methods for Data Augmentation, promising developments, and meta-level 
decisions for implementing Data Augmentation. Readers will understand 
how Data Augmentation can improve the performance of their models and 
expand limited datasets to take advantage of the capabilities of big 
data.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 10:59:22</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:10:23</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_FL796M3N">Shorten et Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf					</li>
				</ul>
			</li>


			<li id="item_XSDJQVK9" class="item journalArticle">
			<h2>Active Learning Literature Survey</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Burr Settles</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>67</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2010</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: settles:2010:active-learning-literature</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>The key idea behind active learning is that a machine learning
 algorithm can achieve greater accuracy with fewer training labels if it
 is allowed to choose the data from which it learns. An active learner 
may pose queries, usually in the form of unlabeled data instances to be 
labeled by an oracle (e.g., a human annotator).
Active learning is well-motivated in many modern machine learning 
problems, where unlabeled data may be abundant or easily obtained, but 
labels are difficult, time-consuming, or expensive to obtain. This 
report provides a general introduction to active learning and a survey 
of the literature. This includes a discussion of the scenarios in which 
queries can be formulated, and an overview of the query strategy 
frameworks proposed in the literature to date. An analysis of the 
empirical and theoretical evidence for successful active learning, a 
summary of problem setting variants and practical issues, and a 
discussion of related topics in machine learning research are also 
presented.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/10/2020 à 19:18:34</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:53</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Active learning</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_SRWU4YSI">Settles - 2010 - Active Learning Literature Survey.pdf					</li>
				</ul>
			</li>


			<li id="item_6QQQVYXV" class="item bookSection">
			<h2>Adding linguistic annotation.</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Geoffrey Leech</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>M. Wynne</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ahds.ac.uk/creating/guides/linguistic-corpora/chapter2.htm">http://ahds.ac.uk/creating/guides/linguistic-corpora/chapter2.htm</a></td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>Oxbow Books</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Oxford</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>AHDS: Literature, Languages, and Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>17–29</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-84217-205-6</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2004</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: leech:2004:adding-linguistic-annotation</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>English</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Developing linguistic corpora : a guide to good practice</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>05/09/2023 à 14:57:29</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>05/09/2023 à 17:03:38</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_6775IFEW">Developing linguistic corpora: a guide to good practice</li>
				</ul>
			</li>


			<li id="item_9CSKDJYE" class="item computerProgram">
			<h2>Agent virtuel SNCF</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>SNCF</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://bot.assistant.sncf/index.html">https://bot.assistant.sncf/index.html</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: sncf:2018:agent-virtuel-sncf</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>09/10/2023 à 18:55:10</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 18:56:46</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_FDSNSJBK" class="item journalArticle">
			<h2>Agglomerative Hierarchical Clustering with Constraints: Theoretical and Empirical Results</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>David Hutchison</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Takeo Kanade</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Josef Kittler</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Jon M. Kleinberg</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Friedemann Mattern</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>John C. Mitchell</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Moni Naor</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Oscar Nierstrasz</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>C. Pandu Rangan</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Bernhard Steffen</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Madhu Sudan</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Demetri Terzopoulos</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Dough Tygar</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Moshe Y. Vardi</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Gerhard Weikum</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Alípio Mário Jorge</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Luís Torgo</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Pavel Brazdil</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Rui Camacho</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>João Gama</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ian Davidson</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>S. S. Ravi</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/11564126_11">http://link.springer.com/10.1007/11564126_11</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>3721</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>59-70</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Knowledge Discovery in Databases: PKDD 2005</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2005</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: davidson-ravi:2005:agglomerative-hierarchical-clustering</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>22/10/2020 à 19:02:07</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We explore the use of instance and cluster-level constraints 
with agglomerative hierarchical clustering. Though previous work has 
illustrated the beneﬁts of using constraints for non-hierarchical 
clustering, their application to hierarchical clustering is not 
straight-forward for two primary reasons. First, some constraint 
combinations make the feasibility problem (Does there exist a single 
feasible solution?) NP-complete. Second, some constraint combinations 
when used with traditional agglomerative algorithms can cause the 
dendrogram to stop prematurely in a dead-end solution even though there 
exist other feasible solutions with a signiﬁcantly smaller number of 
clusters. When constraints lead to efﬁciently solvable feasibility 
problems and standard agglomerative algorithms do not give rise to 
dead-end solutions, we empirically illustrate the beneﬁts of using 
constraints to improve cluster purity and average distortion. 
Furthermore, we introduce the new γ constraint and use it in conjunction
 with the triangle inequality to considerably improve the efﬁciency of 
agglomerative clustering.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Agglomerative Hierarchical Clustering with Constraints</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/10/2020 à 19:02:07</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:09</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>Constrained clustering</li>
					<li>Hierarchcal clustering</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_QEHQH3QT">Davidson et Ravi - 2005 - Agglomerative Hierarchical Clustering with Constra.pdf					</li>
				</ul>
			</li>


			<li id="item_PM68TPE9" class="item conferencePaper">
			<h2>Agile corpus creation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Holger Voormann</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ulrike Gut</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://api.semanticscholar.org/CorpusID:56885448">https://api.semanticscholar.org/CorpusID:56885448</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2008</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: voormann-gut:2008:agile-corpus-creationa</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 16:55:23</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>31/08/2023 à 16:55:40</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_IA3GKTAD" class="item computerProgram">
			<h2>AI dungeon</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Latitude Inc.</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Oasis Tech Inc.</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://play.aidungeon.com/">https://play.aidungeon.com/</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: latitude-inc.-oasis-tech-inc.:2019:ai-dungeon</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Latitude Inc.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>09/10/2023 à 20:06:16</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 20:07:07</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_2GG9RQG7" class="item newspaperArticle">
			<h2>AI is a lot of work</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Josh Dzieza</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html">https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>New York Magazine</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-06-20</td>
					</tr>
					<tr>
					<th>Section</th>
						<td>Artificial Intelligence</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: dzieza:2023:ai-lot-work</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>As the technology becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 09:47:37</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:59:18</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_PWP6CRCK" class="item journalArticle">
			<h2>Algorithms for hierarchical clustering: An overview</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Fionn Murtagh</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Pedro Contreras</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>86-97</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Wiley Interdisc. Rew.: Data Mining and Knowledge Discovery</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2012</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: murtagh-contreras:2012:algorithms-hierarchical-clustering</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1002/widm.53">10.1002/widm.53</a></td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We survey agglomerative hierarchical clustering algorithms and
 discuss efficient implementations that are available in R and other 
software environments. We look at hierarchical self-organizing maps, and
 mixture models. We review grid-based clustering, focusing on 
hierarchical density-based approaches. Finally, we describe a recently 
developed very efficient (linear time) hierarchical clustering 
algorithm, which can also be viewed as a hierarchical grid-based 
algorithm. © 2011 Wiley Periodicals, Inc.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/10/2020 à 18:52:07</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:43</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>Hierarchcal clustering</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_INYWGMYY" class="item journalArticle">
			<h2>Amplifying Limitations, Harms and Risks of Large Language Models</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michael O'Neill</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mark Connor</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2307.04821">https://arxiv.org/abs/2307.04821</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Creative Commons Attribution Non Commercial No Derivatives 4.0 International</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: oneill-connor:2023:amplifying-limitations-harms</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2307.04821">10.48550/ARXIV.2307.04821</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>20/07/2023 à 14:29:12</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We present this article as a small gesture in an attempt to 
counter what appears to be exponentially growing hype around Artificial 
Intelligence (AI) and its capabilities, and the distraction provided by 
the associated talk of science-fiction scenarios that might arise if AI 
should become sentient and super-intelligent. It may also help those 
outside of the field to become more informed about some of the 
limitations of AI technology. In the current context of popular 
discourse AI defaults to mean foundation and large language models 
(LLMs) such as those used to create ChatGPT. This in itself is a 
misrepresentation of the diversity, depth and volume of research, 
researchers, and technology that truly represents the field of AI. AI 
being a field of research that has existed in software artefacts since 
at least the 1950's. We set out to highlight a number of limitations of 
LLMs, and in so doing highlight that harms have already arisen and will 
continue to arise due to these limitations. Along the way we also 
highlight some of the associated risks for individuals and organisations
 in using this technology.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>20/07/2023 à 14:29:12</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:32:44</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Artificial Intelligence</li>
					<li>Computation and Language</li>
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Computers and Society</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_T3MMECGA">O'Neill et Connor - 2023 - Amplifying Limitations, Harms and Risks of Large L.pdf					</li>
				</ul>
			</li>


			<li id="item_D2P9TFPY" class="item conferencePaper">
			<h2>An Overview of Chatbot Technology</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Eleni Adamopoulou</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Lefteris Moussiades</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Ilias Maglogiannis</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Lazaros Iliadis</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Elias Pimenidis</td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>IFIP Advances in Information and Communication Technology</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>373-383</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-030-49186-4</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2020</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: adamopoulou-moussiades:2020:overview-chatbot-technology</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10/ghj8">10/ghj8</a></td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>The use of chatbots evolved rapidly in numerous fields in 
recent years, including Marketing, Supporting Systems, Education, Health
 Care, Cultural Heritage, and Entertainment. In this paper, we first 
present a historical overview of the evolution of the international 
community’s interest in chatbots. Next, we discuss the motivations that 
drive the use of chatbots, and we clarify chatbots’ usefulness in a 
variety of areas. Moreover, we highlight the impact of social 
stereotypes on chatbots design. After clarifying necessary technological
 concepts, we move on to a chatbot classification based on various 
criteria, such as the area of knowledge they refer to, the need they 
serve and others. Furthermore, we present the general architecture of 
modern chatbots while also mentioning the main platforms for their 
creation. Our engagement with the subject so far, reassures us of the 
prospects of chatbots and encourages us to study them in greater extent 
and depth.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Artificial Intelligence Applications and Innovations</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>14/06/2021 à 10:19:28</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:17:09</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Artificial Intelligence</li>
					<li>Machine learning</li>
					<li>*CITATION</li>
					<li>Chatbot</li>
					<li>Chatbot architecture</li>
					<li>NLU</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_IKPC4LT8">Springer Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_GHCEI3ME" class="item journalArticle">
			<h2>Analyse statistique des données textuelles et traitement automatique des langues. Une étude comparée</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mathieu Valette</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://inalco.hal.science/hal-01335084">https://inalco.hal.science/hal-01335084</a></td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Proceedings of 13th international conference on statistical analysis of textual data, 7-10 june 2016, nice (france)</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>697-706</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International conference on statistical analysis of textual data (JADT2016)</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: valette:2016:analyse-statistique-donnees</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Notre propos dans cet article est de comparer le TAL et l’ADT 
selon des points de vue gnoséologique, méthodologique, applicatif et des
 objets d’étude (texte, corpus). Il s’agit d’expliciter, au moyen de 
cinq positions antagonistes, les relations entretenues par ces deux 
sous-disciplines pour envisager les terrains de conciliation possibles :
 (i) automatisation vs herméneutique ; (ii) tekhnè vs épistémè ; (iii) 
test vs jugement d’acceptabilité ; (v) algorithmique vs ergonomie ; (v) 
corpus comme ressources vs corpus comme sources.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>01/09/2023 à 13:22:23</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>24/10/2023 à 08:05:41</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>NLP</li>
					<li>*CITATION</li>
					<li>discussion</li>
					<li>Statistical Analysis of Textual Data</li>
					<li>Textometrics</li>
					<li>Methods</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_M7JCR35V">Valette - 2016 - Analyse statistique des données textuelles et trai.pdf					</li>
				</ul>
			</li>


			<li id="item_TWBLETDR" class="item journalArticle">
			<h2>Analysis of Binary Data. 2nd Edn.</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ian Diamond</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>D. R. Cox</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>E. J. Snell</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.jstor.org/stable/10.2307/2347766?origin=crossref">https://www.jstor.org/stable/10.2307/2347766?origin=crossref</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>39</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>260</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Applied Statistics</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>00359254</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1990</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: diamond-etal:1990:analysis-binary-data</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Applied Statistics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.2307/2347766">10.2307/2347766</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 16:06:49</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 16:06:49</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:11</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>R²</li>
				</ul>
			</li>


			<li id="item_9PZ9MXKK" class="item conferencePaper">
			<h2>Annotation en actes de dialogue pour les conversations d'Assistance en ligne</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Robin Perrotin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alexis Nasr</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jeremy Auguste</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.science/hal-01943345">https://hal.science/hal-01943345</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Rennes, France</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: perrotin-etal:2018:annotation-actes-dialogue</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Les conversations techniques en ligne sont un type de 
productions linguistiques qui par de nombreux aspects se démarquent des 
objets plus usuellement étudiés en traitement automatique des langues : 
il s’agit de dialogues écrits entre deux locuteurs qui servent de 
support à la résolution coopérative des problèmes des usagers. Nous 
proposons de décrire ici ces conversations par un étiquetage en actes de
 dialogue spécifiquement conçu pour les conversations en ligne. 
Différents systèmes de prédictions ont été évalués ainsi qu’une méthode 
permettant de s’abstraire des spécificités lexicales du corpus 
d’apprentissage.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>25e conférence sur le traitement automatique des langues naturelles (TALN)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 14:45:20</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>31/08/2023 à 17:34:14</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>NLP</li>
					<li>*CITATION</li>
					<li>Actes de Dialogues</li>
					<li>Big Data</li>
					<li>Conditional Random Fields</li>
					<li>Conversations en Ligne</li>
					<li>CRF</li>
					<li>Dialog Acts</li>
					<li>Neural Networks</li>
					<li>Online Chats</li>
					<li>TAL</li>
					<li>Traitement Automatique des Langues</li>
					<li>Réseaux neuronaux</li>
					<li>Natural language processing</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_UG79YI8I">Perrotin et al. - 2018 - Annotation en actes de dialogue pour les conversat.pdf					</li>
				</ul>
			</li>


			<li id="item_LI7DMFLM" class="item journalArticle">
			<h2>Annotation guidelines for machine learning-based named entity recognition in microbiology</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Claire Nédellec</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Philippe Bessieres</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Robert Bossy</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alain Kotoujansky</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2006-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: nedellec-etal:2006:annotation-guidelines-machine</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>28/09/2023 à 10:02:47</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:52:27</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_7243BLRY">Nédellec et al. - 2006 - Annotation guidelines for machine learning-based n.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_H298UN4D">De la complexité de l'annotation manuelle : méthodologie, biais et recommandations</li>
				</ul>
			</li>


			<li id="item_EHSK7S4L" class="item book">
			<h2>ANOVA</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ellen Girden</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://methods.sagepub.com/book/anova">https://methods.sagepub.com/book/anova</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>2455 Teller Road,&nbsp;Thousand Oaks&nbsp;California&nbsp;91320&nbsp;United States of America</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>SAGE Publications, Inc.</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-0-8039-4257-8 978-1-4129-8341-9</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1992</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: girden:1992:anova</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 18:03:37</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 18:03:37</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:16</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_VIQN2LXS" class="item journalArticle">
			<h2>Are Large Pre-Trained Language Models Leaking Your Personal Information?</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jie Huang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hanyin Shao</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kevin Chen-Chuan Chang</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2205.12628">https://arxiv.org/abs/2205.12628</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: huang-etal:2022:are-large-pretrained</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2205.12628">10.48550/ARXIV.2205.12628</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>20/07/2023 à 14:31:12</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Are Large Pre-Trained Language Models Leaking Your Personal 
Information? In this paper, we analyze whether Pre-Trained Language 
Models (PLMs) are prone to leaking personal information. Specifically, 
we query PLMs for email addresses with contexts of the email address or 
prompts containing the owner's name. We find that PLMs do leak personal 
information due to memorization. However, since the models are weak at 
association, the risk of specific personal information being extracted 
by attackers is low. We hope this work could help the community to 
better understand the privacy risk of PLMs and bring new insights to 
make PLMs safe.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>20/07/2023 à 14:31:12</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:32:07</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Artificial Intelligence</li>
					<li>Computation and Language</li>
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Cryptography and Security</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_YTDTZXU8">Huang et al. - 2022 - Are Large Pre-Trained Language Models Leaking Your.pdf					</li>
				</ul>
			</li>


			<li id="item_XQAMLWIG" class="item conferencePaper">
			<h2>Ask Me Anything: Dynamic Memory Networks for Natural Language Processing</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ankit Kumar</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ozan Irsoy</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Peter Ondruska</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mohit Iyyer</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>James Bradbury</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ishaan Gulrajani</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Victor Zhong</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Romain Paulus</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Richard Socher</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1506.07285">http://arxiv.org/abs/1506.07285</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>48</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1378-1387</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-03-05</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kumar-etal:2016:ask-me-anything</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>28/12/2018 à 16:08:42</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Most tasks in natural language processing can be cast into 
question answering (QA) problems over language input. We introduce the 
dynamic memory network (DMN), a neural network architecture which 
processes input sequences and questions, forms episodic memories, and 
generates relevant answers. Questions trigger an iterative attention 
process which allows the model to condition its attention on the inputs 
and the result of previous iterations. These results are then reasoned 
over in a hierarchical recurrent sequence model to generate answers. The
 DMN can be trained end-to-end and obtains state-of-the-art results on 
several types of tasks and datasets: question answering (Facebook's bAbI
 dataset), text classification for sentiment analysis (Stanford 
Sentiment Treebank) and sequence modeling for part-of-speech tagging 
(WSJ-PTB). The training for these different tasks relies exclusively on 
trained word vector representations and input-question-answer triplets.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>International Conference on Machine Learning</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Ask Me Anything</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>28/12/2018 à 16:08:42</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>23/10/2023 à 23:05:05</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Standford-CS224N</li>
					<li>Question answering</li>
					<li>Computation and Language</li>
					<li>Neural and Evolutionary Computing</li>
					<li>Machine learning</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_U66BBLWN">Kumar et al. - 2015 - Ask Me Anything Dynamic Memory Networks for Natur.pdf					</li>
				</ul>
			</li>


			<li id="item_49U93MFN" class="item computerProgram">
			<h2>Audacity: Free Audio Editor and Recorder</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Audacity Team</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.audacityteam.org/">https://www.audacityteam.org/</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2000</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: audacity-team:2000:audacity-free-audio</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Muse Group</td>
					</tr>
					<tr>
					<th>Archive</th>
						<td>https://github.com/audacity/audacity</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>27/09/2023 à 12:59:53</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>27/09/2023 à 13:04:34</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_WVG4JFGM" class="item computerProgram">
			<h2>Bard - chat based AI tool from Google</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Google</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://bard.google.com/chat">https://bard.google.com/chat</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-07-13</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: google:2023:bard-chat-based</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>09/10/2023 à 19:55:46</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 19:56:30</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_LXKUMNE4" class="item journalArticle">
			<h2>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mike Lewis</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yinhan Liu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Naman Goyal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Marjan Ghazvininejad</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Abdelrahman Mohamed</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Omer Levy</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ves Stoyanov</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Luke Zettlemoyer</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/1910.13461">https://arxiv.org/abs/1910.13461</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: lewis-etal:2019:bart-denoising-sequencetosequence</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.1910.13461">10.48550/ARXIV.1910.13461</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>17/07/2023 à 17:20:05</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We present BART, a denoising autoencoder for pretraining 
sequence-to-sequence models. BART is trained by (1) corrupting text with
 an arbitrary noising function, and (2) learning a model to reconstruct 
the original text. It uses a standard Tranformer-based neural machine 
translation architecture which, despite its simplicity, can be seen as 
generalizing BERT (due to the bidirectional encoder), GPT (with the 
left-to-right decoder), and many other more recent pretraining schemes. 
We evaluate a number of noising approaches, finding the best performance
 by both randomly shuffling the order of the original sentences and 
using a novel in-filling scheme, where spans of text are replaced with a
 single mask token. BART is particularly effective when fine tuned for 
text generation but also works well for comprehension tasks. It matches 
the performance of RoBERTa with comparable training resources on GLUE 
and SQuAD, achieves new state-of-the-art results on a range of 
abstractive dialogue, question answering, and summarization tasks, with 
gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a 
back-translation system for machine translation, with only target 
language pretraining. We also report ablation experiments that replicate
 other pretraining schemes within the BART framework, to better measure 
which factors most influence end-task performance.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>BART</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>17/07/2023 à 17:20:05</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:32:18</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Computation and Language</li>
					<li>Machine learning</li>
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_HMB79SIK">Lewis et al. - 2019 - BART Denoising Sequence-to-Sequence Pre-training .pdf					</li>
				</ul>
			</li>


			<li id="item_YIP4H8QU" class="item journalArticle">
			<h2>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jacob Devlin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ming-Wei Chang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kenton Lee</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kristina Toutanova</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-05-24</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: devlin-etal:2019:bert-pretraining-deep</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>10/06/2020 à 11:28:45</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We introduce a new language representation model called BERT, 
which stands for Bidirectional Encoder Representations from 
Transformers. Unlike recent language representation models, BERT is 
designed to pre-train deep bidirectional representations from unlabeled 
text by jointly conditioning on both left and right context in all 
layers. As a result, the pre-trained BERT model can be fine-tuned with 
just one additional output layer to create state-of-the-art models for a
 wide range of tasks, such as question answering and language inference,
 without substantial task-specific architecture modifications. BERT is 
conceptually simple and empirically powerful. It obtains new 
state-of-the-art results on eleven natural language processing tasks, 
including pushing the GLUE score to 80.5% (7.7% point absolute 
improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), 
SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute 
improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute 
improvement).</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>BERT</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>10/06/2020 à 11:28:45</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:30:36</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Computation and Language</li>
					<li>Transformers</li>
					<li>BERT</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_E53CNC5D">Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_IJGCWIVB">Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing</li>
				</ul>
			</li>


			<li id="item_7PP23HLX" class="item journalArticle">
			<h2>Building Task-Oriented Dialogue Systems for Online Shopping</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zhao Yan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nan Duan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Peng Chen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ming Zhou</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jianshe Zhou</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zhoujun Li</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ojs.aaai.org/index.php/AAAI/article/view/11182">https://ojs.aaai.org/index.php/AAAI/article/view/11182</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>31</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2374-3468, 2159-5399</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2012-02-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: yan-etal:2017:building-taskoriented-dialogue</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>AAAI</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1609/aaai.v31i1.11182">10.1609/aaai.v31i1.11182</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>26/07/2023 à 14:25:54</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We present a general solution towards building task-oriented 
dialogue systems for online shopping, aiming to assist online customers 
in completing various purchase-related tasks, such as searching products
 and answering questions, in a natural language conversation manner. As a
 pioneering work, we show what &amp; how existing natural language 
processing techniques, data resources, and crowdsourcing can be 
leveraged to build such task-oriented dialogue systems for E-commerce 
usage. To demonstrate its effectiveness, we integrate our system into a 
mobile online shopping application. To the best of our knowledge, this 
is the ﬁrst time that an dialogue system in Chinese is practically used 
in online shopping scenario with millions of real consumers. Interesting
 and insightful observations are shown in the experimental part, based 
on the analysis of human-bot conversation log. Several current 
challenges are also pointed out as our future directions.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/07/2023 à 14:25:54</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>23/10/2023 à 18:06:44</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*ALIRE/AIMPLÉMENTER</li>
					<li>*CITATION</li>
					<li>Chatbot</li>
					<li>Intention</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_LGGHDIB7">
<div><div data-schema-version="8"><p>NOTES DE LECTURE</p>
<ul>
<li>
Difference between task-oriented and chat-oriented.
</li>
<li>
Focus on a task-oriented chatbot for e-commerce
</li>
</ul>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_RQEW55YJ">Yan et al. - 2017 - Building Task-Oriented Dialogue Systems for Online.pdf					</li>
				</ul>
			</li>


			<li id="item_JJGV4AMD" class="item journalArticle">
			<h2>Can I use this publicly available dataset to build commercial AI software? -- A Case Study on Publicly Available Image Datasets</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gopi Krishnan Rajbahadur</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Erika Tuck</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Li Zi</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dayi Lin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Boyuan Chen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zhen Ming</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jiang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Daniel M. German</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/2111.02374">http://arxiv.org/abs/2111.02374</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-04-11</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: rajbahadur-etal:2022:can-use-this</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 10:29:22</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Publicly available datasets are one of the key drivers for 
commercial AI software. The use of publicly available datasets 
(particularly for commercial purposes) is governed by dataset licenses. 
These dataset licenses outline the rights one is entitled to on a given 
dataset and the obligations that one must fulfil to enjoy such rights 
without any license compliance violations. However, unlike standardized 
Open Source Software (OSS) licenses, existing dataset licenses are 
defined in an ad-hoc manner and do not clearly outline the rights and 
obligations associated with their usage. This makes checking for 
potential license compliance violations difficult. Further, a public 
dataset may be hosted in multiple locations and created from multiple 
data sources each of which may have different licenses. Hence, existing 
approaches on checking OSS license compliance cannot be used. In this 
paper, we propose a new approach to assess the potential license 
compliance violations if a given publicly available dataset were to be 
used for building commercial AI software. We conduct trials of our 
approach on two product groups within Huawei on 6 commonly used publicly
 available datasets. Our results show that there are risks of license 
violations on 5 of these 6 studied datasets if they were used for 
commercial purposes. Consequently, we provide recommendations for AI 
engineers on how to better assess publicly available datasets for 
license compliance violations.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Can I use this publicly available dataset to build commercial AI software?</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 10:29:22</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:33:00</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Computer Science - Artificial Intelligence</li>
					<li>Computer Science - Machine Learning</li>
					<li>Computer Science - Software Engineering</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_SVEZGLXJ">Rajbahadur et al. - 2022 - Can I use this publicly available dataset to build.pdf					</li>
				</ul>
			</li>


			<li id="item_8H89HS4H" class="item standard">
			<h2>CC BY-NC 4.0 LEGAL CODE - Attribution-NonCommercial 4.0 International</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Standard</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Creative commons</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://creativecommons.org/licenses/by-nc/4.0/legalcode.en">https://creativecommons.org/licenses/by-nc/4.0/legalcode.en</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2013</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: creative-commons:2013:cc-bync-legal</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>BY-NC</td>
					</tr>
					<tr>
					<th>Version</th>
						<td>4.0</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Creative Commons Corporation ("Creative Commons") is not a law
 firm and does not provide legal services or legal advice. Distribution 
of Creative Commons public licenses does not create a lawyer-client or 
other relationship. Creative Commons makes its licenses and related 
information available on an "as-is" basis. Creative Commons gives no 
warranties regarding its licenses, any material licensed under their 
terms and conditions, or any related information. Creative Commons 
disclaims all liability for damages resulting from their use to the 
fullest extent possible.</td>
					</tr>
					<tr>
					<th>Type</th>
						<td>Licence</td>
					</tr>
					<tr>
					<th>Organization</th>
						<td>Creative commons</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 14:27:30</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>05/10/2023 à 09:23:36</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_P8AFKE6N" class="item journalArticle">
			<h2>Challenges and Applications of Large Language Models</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jean Kaddour</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Joshua Harris</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Maximilian Mozes</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Herbie Bradley</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Roberta Raileanu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Robert McHardy</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2307.10169">https://arxiv.org/abs/2307.10169</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Creative Commons Attribution 4.0 International</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kaddour-etal:2023:challenges-applications-large</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2307.10169">10.48550/ARXIV.2307.10169</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>20/07/2023 à 13:58:58</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Large Language Models (LLMs) went from non-existent to 
ubiquitous in the machine learning discourse within a few years. Due to 
the fast pace of the field, it is difficult to identify the remaining 
challenges and already fruitful application areas. In this paper, we aim
 to establish a systematic set of open problems and application 
successes so that ML researchers can comprehend the field's current 
state more quickly and become productive.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>20/07/2023 à 13:58:58</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:32:10</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Artificial Intelligence</li>
					<li>Computation and Language</li>
					<li>Machine learning</li>
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Problèmes</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_R7GUR649">Kaddour et al. - 2023 - Challenges and Applications of Large Language Mode.pdf					</li>
				</ul>
			</li>


			<li id="item_SG2EW6CZ" class="item bookSection">
			<h2>Chapter 7: Overfitting</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>William Collins</td>
					</tr>
					<tr>
						<th class="bookAuthor">Auteur du livre</th>
						<td>Brian Christian</td>
					</tr>
					<tr>
						<th class="bookAuthor">Auteur du livre</th>
						<td>Tom Griffiths</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>149–168</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-0-00-754799-9</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-04</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: collins:2017:chapter-overfitting</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Algorithms To Live By: The computer science of human decisions</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/09/2023 à 16:04:41</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:09:08</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_53GJNM6J">Algorithms to live by: the computer science of human decisions</li>
				</ul>
			</li>


			<li id="item_RIMV3BYJ" class="item journalArticle">
			<h2>Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Wei-Lin Chiang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Lianmin Zheng</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ying Sheng</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Anastasios Nikolas Angelopoulos</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tianle Li</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dacheng Li</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hao Zhang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Banghua Zhu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michael Jordan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Joseph E. Gonzalez</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ion Stoica</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2403.04132">https://arxiv.org/abs/2403.04132</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2024-03-07</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: chiang-etal:2024:chatbot-arena-open</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2403.04132">10.48550/ARXIV.2403.04132</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>20/03/2024 à 08:23:44</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Large Language Models (LLMs) have unlocked new capabilities 
and applications; however, evaluating the alignment with human 
preferences still poses significant challenges. To address this issue, 
we introduce Chatbot Arena, an open platform for evaluating LLMs based 
on human preferences. Our methodology employs a pairwise comparison 
approach and leverages input from a diverse user base through 
crowdsourcing. The platform has been operational for several months, 
amassing over 240K votes. This paper describes the platform, analyzes 
the data we have collected so far, and explains the tried-and-true 
statistical methods we are using for efficient and accurate evaluation 
and ranking of models. We confirm that the crowdsourced questions are 
sufficiently diverse and discriminating and that the crowdsourced human 
votes are in good agreement with those of expert raters. These analyses 
collectively establish a robust foundation for the credibility of 
Chatbot Arena. Because of its unique value and openness, Chatbot Arena 
has emerged as one of the most referenced LLM leaderboards, widely cited
 by leading LLM developers and companies. Our demo is publicly available
 at \url{https://chat.lmsys.org}.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Chatbot Arena</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>20/03/2024 à 08:23:44</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>20/03/2024 à 08:35:53</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Artificial Intelligence</li>
					<li>Computation and Language</li>
					<li>FOS: Computer and information sciences</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_373IY7FS">Chiang et al. - 2024 - Chatbot Arena An Open Platform for Evaluating LLM.pdf					</li>
				</ul>
			</li>


			<li id="item_JCB6KUXT" class="item newspaperArticle">
			<h2>Chatbots Will Appeal to Modern Workers</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Laurence Goasduff</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.gartner.com/smarterwithgartner/chatbots-will-appeal-to-modern-workers/">https://www.gartner.com/smarterwithgartner/chatbots-will-appeal-to-modern-workers/</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Gartner, Inc</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-07-31</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: goasduff:2019:chatbots-will-appeal</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>23/10/2020 à 09:11:59</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en-US</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>The proliferation of chatbots in the modern workplace calls 
for IT leaders to create a conversational platform strategy that ensures
 an effective solution for employees, customers and key partners.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2020 à 09:11:59</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 17:01:18</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_LA45G5QI" class="item computerProgram">
			<h2>ChatGPT</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>OpenAI</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://chat.openai.com/">https://chat.openai.com</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: openai:2023:chatgpt</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>25/07/2023 à 09:53:19</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>27/09/2023 à 09:25:33</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_UTSRX6NJ" class="item journalArticle">
			<h2>Cheap and Fast - But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Rion Snow</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Brendan O'Connor</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Daniel Jurafsky</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Andrew Ng</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>254-263</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2008-10</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: snow-etal:2008:cheap-fast-it</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Human linguistic annotation is crucial for many natural 
language processing tasks but can be expensive and time-consuming. We 
explore the use of Amazon’s Mechanical Turk system, a signiﬁcantly 
cheaper and faster method for collecting annotations from a broad base 
of paid non-expert contributors over the Web. We investigate ﬁve tasks: 
affect recognition, word similarity, recognizing textual entailment, 
event temporal ordering, and word sense disambiguation. For all ﬁve, we 
show high agreement between Mechanical Turk non-expert annotations and 
existing gold standard labels provided by expert labelers. For the task 
of affect recognition, we also show that using non-expert labels for 
training machine learning algorithms can be as effective as using gold 
standard annotations from experts. We propose a technique for bias 
correction that signiﬁcantly improves annotation quality on two tasks. 
We conclude that many large labeling tasks can be effectively designed 
and carried out in this method at a fraction of the usual expense.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 15:38:15</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:54:59</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_3X8VAD2U">
<div><div data-schema-version="8"><p>NOTE ERWAN</p>
<blockquote>
<ul>
<li>
Appel à <strong>Amazon Mechanical Turk</strong>
</li>
</ul>
</blockquote>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_7UTBTBGX">Snow et al. - 2008 - Cheap and Fast - But is it Good Evaluating Non-Ex.pdf					</li>
				</ul>
			</li>


			<li id="item_TR26RBPI" class="item journalArticle">
			<h2>Classification Techniques in Machine Learning: Applications and Issues</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Aized Amin Soofi</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Arshad Awan</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://setpublisher.com/pms/index.php/jbas/article/view/1715">https://setpublisher.com/pms/index.php/jbas/article/view/1715</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>13</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>459-465</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of Basic &amp; Applied Sciences</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1927-5129, 1814-8085</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-01-05</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: aized-amin-soofi-arshad-awan:2017:classification-techniques-machine</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>J. Basic Appl. Sci.</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.6000/1927-5129.2017.13.76">10.6000/1927-5129.2017.13.76</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>18/09/2023 à 14:17:03</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Classification is a data mining (machine learning) technique 
used to predict group membership for data instances. There are several 
classification techniques that can be used for classification purpose. 
In this paper, we present the basic classification techniques. Later we 
discuss some major types of classification method including Bayesian 
networks, decision tree induction, k-nearest neighbor classifier and 
Support Vector Machines (SVM) with their strengths, weaknesses, 
potential applications and issues with their available solution. The 
goal of this study is to provide a comprehensive review of different 
classification techniques in machine learning. This work will be helpful
 for both academia and new comers in the field of machine learning to 
further strengthen the basis of classification methods.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Classification Techniques in Machine Learning</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 14:17:03</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:08:56</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_F6U6GM2B">Aized Amin Soofi et Arshad Awan - 2017 - Classification Techniques in Machine Learning App.pdf					</li>
				</ul>
			</li>


			<li id="item_3IQSQGFI" class="item journalArticle">
			<h2>Clustering with Instance-level Constraints</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kiri Wagstaﬀ</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Claire Cardie</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1103--1110</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Proceedings of the Seventeenth International Conference on Machine Learning</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2000</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: wagstaff-cardie:2000:clustering-instancelevel-constraints</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Clustering algorithms conduct a search through the space of 
possible organizations of a data set. In this paper, we propose two 
types of instance-level clustering constraints – must-link and 
cannot-link constraints – and show how they can be incorporated into a 
clustering algorithm to aid that search. For three of the four data sets
 tested, our results indicate that the incorporation of surprisingly few
 such constraints can increase clustering accuracy while decreasing 
runtime. We also investigate the relative eﬀects of each type of 
constraint and ﬁnd that the type that contributes most to accuracy 
improvements depends on the behavior of the clustering algorithm without
 constraints.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/10/2020 à 18:17:37</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:57</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>INTERACTIVE_CLUSTERING</li>
					<li>Constrained clustering</li>
					<li>Contraintes</li>
					<li>Must-link and Cannot-Link</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_8WNCENKV">Wagstaﬀ et Cardie - 2000 - Clustering with Instance-level Constraints.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_MGCGYXYL">Constrained distance based clustering for time-series: a comparative and experimental study</li>
				</ul>
			</li>


			<li id="item_KLMUZA7A" class="item standard">
			<h2>Codes for the representation of names of languages – Part 3: Alpha-3 code for comprehensive coverage of languages</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Standard</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>International Organization for Standardization</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.iso.org/standard/39534.html">https://www.iso.org/standard/39534.html</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Geneva, CH</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>International Organization for Standardization</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2007-02-16</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: international-organization-for-standardization:2007:codes-representation-names</td>
					</tr>
					<tr>
					<th>Commission</th>
						<td>ISO/TC 37/SC 2</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>ISO 639-3:2007</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>ISO 639-3:2007 provides a code, published by the Registration 
Authority of ISO 639-3, consisting of language code elements comprising 
three-letter language identifiers for the representation of languages. 
The language identifiers according to this ISO 639-3:2007 were devised 
for use in a wide range of applications, especially in computer systems,
 where there is potential need to support a large number of the 
languages that are known to have ever existed. Whereas ISO 639-1 and ISO
 639-2 are intended to focus on the major languages of the world that 
are most frequently represented in the total body of the world's 
literature, ISO 639-3:2007 attempts to provide as complete an 
enumeration of languages as possible, including living, extinct, ancient
 and constructed languages, whether major or minor, written or 
unwritten. As a result, ISO 639-3:2007 deals with a very large number of
 lesser-known languages. Languages designed exclusively for machine use,
 such as computer-programming languages and reconstructed languages, are
 not included in this code.</td>
					</tr>
					<tr>
					<th>Type</th>
						<td>Standard</td>
					</tr>
					<tr>
					<th>Status</th>
						<td>Published</td>
					</tr>
					<tr>
					<th>Organization</th>
						<td>International Organization for Standardization</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>21/09/2023 à 15:32:03</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>19/10/2023 à 12:06:19</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_P9D9RWRC" class="item computerProgram">
			<h2>cognitivefactory/features-maximization-metric</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.5281/zenodo.7646382">https://doi.org/10.5281/zenodo.7646382</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Open Access</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-02-16</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild:2023:cognitivefactory-featuresmaximizationmetric</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>16/02/2023 à 13:42:05</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Zenodo</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>cognitivefactory/features-maximization-metric</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>16/02/2023 à 13:42:05</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>16/10/2023 à 10:08:25</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_IY66JIX8" class="item computerProgram">
			<h2>cognitivefactory/interactive-clustering</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Esther Lenôtre</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>David Nicolazo</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Marc Trutt</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.5281/zenodo.4775251">https://doi.org/10.5281/zenodo.4775251</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Open Access</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-08-22</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild:2022:cognitivefactory-interactiveclustering</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>13/02/2023 à 15:04:12</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Zenodo</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>cognitivefactory/interactive-clustering</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>13/02/2023 à 15:04:12</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>20/10/2023 à 12:33:33</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_BK779LMD" class="item computerProgram">
			<h2>cognitivefactory/interactive-clustering-comparative-study</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.5281/zenodo.5648255">https://doi.org/10.5281/zenodo.5648255</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>CeCILL-C Free Software License Agreement, Open Access</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-11-05</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild:2021:cognitivefactory-interactiveclusteringcomparativestudy</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>13/02/2023 à 15:03:29</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Zenodo</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>13/02/2023 à 15:03:29</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>16/10/2023 à 10:08:21</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>Python</li>
					<li>*CITATION</li>
					<li>Comparative-study</li>
					<li>Natural language processing</li>
					<li>Interactive-clustering</li>
					<li>Constraints</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_7SEJPTW4">French trainset for chatbots dealing with usual requests on bank cards</li>
				</ul>
			</li>


			<li id="item_42NJDFYV" class="item computerProgram">
			<h2>cognitivefactory/interactive-clustering-gui</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Thomas Lepine</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Clémentine Misiak</td>
					</tr>
					<tr>
						<th class="contributor">Collaborateur</th>
						<td>Thomas Tremble</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.5281/zenodo.4775270">https://doi.org/10.5281/zenodo.4775270</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Open Access</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-09-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild-etal:2022:cognitivefactory-interactiveclusteringgui</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>13/02/2023 à 15:04:02</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Zenodo</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>cognitivefactory/interactive-clustering-gui</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>13/02/2023 à 15:04:02</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>20/10/2023 à 12:34:41</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_6THW34MI" class="item computerProgram">
			<h2>Cohere Sandbox</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Jay Alammar</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Edward Grefenstette</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://github.com/cohere-ai/sandbox-topically">https://github.com/cohere-ai/sandbox-topically</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: alammar-grefenstette:2022:cohere-sandbox</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Cohere.ai</td>
					</tr>
					<tr>
					<th>Langage de programmation</th>
						<td>Python</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>17/07/2023 à 17:41:44</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>17/07/2023 à 17:46:24</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_V8MPV6KA" class="item journalArticle">
			<h2>Comparing Individual Means in the Analysis of Variance</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>John W. Tukey</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.jstor.org/stable/3001913?origin=crossref">https://www.jstor.org/stable/3001913?origin=crossref</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>5</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>99</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Biometrics</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0006341X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1949-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: tukey:1949:comparing-individual-means</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Biometrics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.2307/3001913">10.2307/3001913</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 18:04:55</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 18:04:55</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:48:33</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_VIGTEAY6" class="item journalArticle">
			<h2>Competitive algorithms for the clustering of noisy data</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tai-Ning Yang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sheng-De Wang</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://linkinghub.elsevier.com/retrieve/pii/S0165011402005250">https://linkinghub.elsevier.com/retrieve/pii/S0165011402005250</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>141</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>281-299</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Fuzzy Sets and Systems</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>01650114</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2004-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: yang-wang:2004:competitive-algorithms-clustering</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Fuzzy Sets and Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/S0165-0114(02)00525-0">10.1016/S0165-0114(02)00525-0</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>17/10/2023 à 16:51:18</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>In this paper, we consider the issue of clustering when 
outliers exist. The outlier set is defined as the complement of the data
 set. Following this concept, a specially designed fuzzy membership 
weighted objective function is proposed and the corresponding optimal 
membership is derived. Unlike the membership of fuzzy c-means, the 
derived fuzzy membership does not reduce with the increase of the 
cluster number. With the suitable redefinition of the distance metric, 
we demonstrate that the objective function could be used to extract c 
spherical shells. A hard clustering algorithm alleviating the prototype 
under-utilization problem is also derived. Artificially generated data 
are used for comparisons.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>17/10/2023 à 16:51:18</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>17/10/2023 à 16:53:32</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_4W94SKAD" class="item conferencePaper">
			<h2>Complex linguistic annotation – no easy way out! A case from Bangla and Hindi POS labeling tasks</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sandipan Dandapat</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Priyanka Biswas</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Monojit Choudhury</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kalika Bali</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://aclanthology.org/W09-3002">https://aclanthology.org/W09-3002</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Suntec, Singapore</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>10–18</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2009-08</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: dandapat-etal:2009:complex-linguistic-annotation</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the third linguistic annotation workshop (LAW III)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>28/09/2023 à 10:25:30</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:55:41</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_GX7YEZSW">Dandapat et al. - 2009 - Complex linguistic annotation – no easy way out! A.pdf					</li>
				</ul>
			</li>


			<li id="item_VPXRYDZE" class="item computerProgram">
			<h2>Computer Vision Annotation Tool (CVAT)</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>CVAT.Ai Corporation</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.cvat.ai/">https://www.cvat.ai/</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>MIT License, Open Access</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-10-17</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: cvat.ai-corporation:2019:computer-vision-annotation</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>27/09/2023 à 08:57:06</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>CVAT.ai Corporation</td>
					</tr>
					<tr>
					<th>Langage de programmation</th>
						<td>Python</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Annotate better with CVAT, the industry-leading data engine 
for machine learning. Used and trusted by teams at any scale, for data 
of any scale.</td>
					</tr>
					<tr>
					<th>Archive</th>
						<td>https://zenodo.org/record/3497105</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>27/09/2023 à 08:57:06</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:10:40</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Deep learning</li>
					<li>*CITATION</li>
					<li>Annotation</li>
					<li>computer-vision</li>
					<li>computer-vision-annotation</li>
					<li>labeling-tool</li>
					<li>object-detection</li>
					<li>video-annotation</li>
					<li>Annotation-tool</li>
					<li>Image-classification</li>
					<li>Image-labeling</li>
					<li>Image-labeling-tool</li>
					<li>Semantic-segmentation</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_6P4USVW2">
<p class="plaintext">&lt;h2&gt;Other&lt;/h2&gt;
If you use this software, please cite it using the metadata from this file.</p>
					</li>
				</ul>
			</li>


			<li id="item_QNT6GMQ9" class="item conferencePaper">
			<h2>Conception itérative et semi-supervisée d'assistants conversationnels par regroupement interactif des questions</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gautier Durantin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jean-Charles Lamirel</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Florian Miconi</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.inria.fr/hal-03133007">https://hal.inria.fr/hal-03133007</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC-BY-NC-ND)</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>RNTI E-37</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Edition RNTI</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-01-25</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild-etal:2021:conception-iterative-semisupervisee</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>14/06/2021 à 10:01:10</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>hal.inria.fr</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>EGC 2021 - 21èmes Journées Francophones Extraction et Gestion des Connaissances</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>La création d’un jeu de données pour l’entrainement d’un 
chatbot repose sur un a priori de connaissance du domaine. En 
conséquence, cette étape est le plus souvent manuelle, fastidieuse et 
soumise aux biais. Pour garantir l’efficacité et l’objectivité de 
l’annotation, nous proposons une méthodologie d’apprentissage actif par 
annotation de contraintes. Il s’agit d’une approche itérative, reposant 
sur un algorithme de clustering pour segmenter les données et tirant 
parti de la connaissance de l’annotateur pour guider le regroupement des
 questions en une structure d’intentions. Dans cet article, nous 
étudions les paramètres optimaux de modélisation pour réaliser une 
segmentation exploitable en un minimum d’annotations, et montrons que 
cette approche permet d’aboutir à une structure cohérente pour 
l’entrainement d’un assistant conversationnel.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>14/06/2021 à 10:01:10</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:02:18</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>INTERACTIVE_CLUSTERING</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>*PUBLICATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_T7NYJRY8">Schild et al. - 2021 - Conception itérative et semi-supervisée d'assistan.pdf					</li>
				</ul>
			</li>


			<li id="item_BQQGU3CQ" class="item conferencePaper">
			<h2>Concevoir un assistant conversationnel de manière itérative et semi-supervisée avec le clustering interactif</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gautier Durantin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jean-Charles Lamirel</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.inria.fr/hal-03133060">https://hal.inria.fr/hal-03133060</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC-BY-NC-ND)</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Pascal Cuxac, Vincent Lemaire, Cédric Lopez</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>11-14</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-01-26</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild-etal:2021:concevoir-assistant-conversationnel</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>hal.inria.fr</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>Atelier - Fouille de Textes - Text Mine 2021 - En conjonction avec EGC 2021</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>La création d’un jeu de données nécessaire à la conception 
d’un assistant conversationnel résulte le plus souvent d’une étape 
manuelle et fastidieuse qui manque de techniques destinées à l’assister.
 Pour accélérer cette étape d’annotation, nous proposons une méthode de 
clustering interactif : il s’agit d’une approche itérative inspirée de 
l’apprentissage actif, reposant sur un algorithme de clustering et 
tirant parti d’une annotation de contraintes pour guider le regroupement
 des questions en une structure d’intentions. Dans cet article, nous 
exposons la méthodologie à mettre en oeuvre pour concevoir un assistant 
conversationnel opérationnel à l’aide du clustering interactif.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>TextMine 2021 (TM'2021) - En conjonction avec EGC 2021</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Concevoir un assistant conversationnel avec le clustering interactif</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>01/02/2021 à 09:27:08</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:02:08</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>INTERACTIVE_CLUSTERING</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>*PUBLICATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_IHVRXA2V">Schild et al - 2021 - PRESENTATION					</li>
					<li id="item_3GD3XG3E">Schild et al. - 2021 - Concevoir un assistant conversationnel de manière .pdf					</li>
				</ul>
			</li>


			<li id="item_MGCGYXYL" class="item journalArticle">
			<h2>Constrained distance based clustering for time-series: a comparative and experimental study</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Thomas Lampert</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Thi-Bich-Hanh Dao</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Baptiste Lafabregue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nicolas Serrette</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Germain Forestier</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Bruno Crémilleux</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Christel Vrain</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Pierre Gançarski</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/s10618-018-0573-y">http://link.springer.com/10.1007/s10618-018-0573-y</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>32</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1663-1707</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Data Mining and Knowledge Discovery</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1384-5810, 1573-756X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018-11</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: lampert-etal:2018:constrained-distance-based</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Data Min Knowl Disc</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10/gfbpj8">10/gfbpj8</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>02/06/2020 à 16:10:28</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Constrained clustering is becoming an increasingly popular 
approach in data mining. It offers a balance between the complexity of 
producing a formal deﬁnition of thematic classes—required by supervised 
methods—and unsupervised approaches, which ignore expert knowledge and 
intuition. Nevertheless, the application of constrained clustering to 
time-series analysis is relatively unknown. This is partly due to the 
unsuitability of the Euclidean distance metric, which is typically used 
in data mining, to time-series data. This article addresses this divide 
by presenting an exhaustive review of constrained clustering algorithms 
and by modifying publicly available implementations to use a more 
appropriate distance measure—dynamic time warping. It presents a 
comparative study, in which their performance is evaluated when applied 
to time-series. It is found that k-means based algorithms become 
computationally expensive and unstable under these modiﬁcations. 
Spectral approaches are easily applied and offer state-of-the-art 
performance, whereas declarative approaches are also easily applied and 
guarantee constraint satisfaction. An analysis of the results raises 
several inﬂuencing factors to an algorithm’s performance when 
constraints are introduced.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Constrained distance based clustering for time-series</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>02/06/2020 à 16:10:28</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:12:02</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>INTERACTIVE_CLUSTERING</li>
					<li>Constrained clustering</li>
					<li>Semi-supervised</li>
					<li>Partition clustering</li>
					<li>Time-series</li>
					<li>Dynamic time warping</li>
					<li>Comparaison</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_UMVKY7ZH">Lampert et al. - 2018 - Constrained distance based clustering for time-ser.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_3IQSQGFI">Clustering with Instance-level Constraints</li>
					<li id="item_5FHWVRCC">From Instance-level Constraints to Space-level Constraints: Making the Most of Prior Knowledge in Data Clustering</li>
					<li id="item_736X6GYW">Active Spectral Clustering</li>
					<li id="item_7MJQA4EJ">Semi-supervised Clustering by seeding</li>
					<li id="item_BZJ4VXIQ">An Improved Cop-Kmeans Clustering for Solving Constraint Violation Based on MapReduce Framework</li>
					<li id="item_HGV8NRHB">Constrained Distance based K-Means Clustering for Satellite Image Time-Series</li>
					<li id="item_I759GKQI">Flexible constrained spectral clustering</li>
					<li id="item_KS9R8T8U">Spectral Clustering for beginners</li>
					<li id="item_UR78PU6A">On constrained spectral clustering and its applications</li>
					<li id="item_VIVT6LVP">Collaborative multi-step mono-level multi-strategy classification</li>
					<li id="item_YLPNY89L">A Tutorial on Spectral Clustering</li>
				</ul>
			</li>


			<li id="item_HGV8NRHB" class="item conferencePaper">
			<h2>Constrained Distance based K-Means Clustering for Satellite Image Time-Series</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Thomas Lampert</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Baptiste Lafabregue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Pierre Gancarski</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/8900147/">https://ieeexplore.ieee.org/document/8900147/</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Yokohama, Japan</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>2419-2422</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-9154-0</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-07</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: lampert-etal:2019:constrained-distance-based</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10/ggx3tj">10/ggx3tj</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>02/06/2020 à 15:21:03</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>The advent of high-resolution instruments for time-series 
sampling poses added complexity for the formal deﬁnition of thematic 
classes in the remote sensing domain—required by supervised 
methods—while unsupervised methods ignore expert knowledge and 
intuition. Constrained clustering is becoming an increasingly popular 
approach in data mining because it offers a solution to these problems, 
however, its application in remote sensing is relatively unknown. This 
article addresses this divide by adapting publicly available k-Means 
constrained clustering implementations to use the dynamic time warping 
(DTW) dissimilarity measure, which is thought to be more appropriate for
 time-series analysis. Adding constraints to the clustering problem 
increases accuracy when compared to unconstrained clustering. The output
 of such algorithms are homogeneous in spatially deﬁned regions.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>02/06/2020 à 15:21:03</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:11:28</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>K-Means</li>
					<li>INTERACTIVE_CLUSTERING</li>
					<li>Constrained clustering</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_UNDG3ZHC">Lampert et al. - 2019 - Constrained Distance based K-Means Clustering for .pdf					</li>
					<li id="item_KWERLC9W">Lampert et al. - 2019 - PRÉSENTATION					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_MGCGYXYL">Constrained distance based clustering for time-series: a comparative and experimental study</li>
					<li id="item_VIVT6LVP">Collaborative multi-step mono-level multi-strategy classification</li>
				</ul>
			</li>


			<li id="item_SQT6GYBS" class="item conferencePaper">
			<h2>Constrained K-means clustering with background knowledge</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kiri Wagstaff</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Claire Cardie</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Seth Rogers</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Stefan Schrödl</td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Proceedings of 18th International Conference on Machine Learning</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>577-584</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2001-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: wagstaff-etal:2001:constrained-kmeans-clustering</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/07/2023 à 09:20:48</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:50:59</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_TGGJZZWD">Wagstaff et al. - 2001 - Constrained K-means clustering with background kno.pdf					</li>
				</ul>
			</li>


			<li id="item_M36HMNXG" class="item book">
			<h2>Content analysis: an introduction to its methodology</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Klaus Krippendorff</td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>2nd ed</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Thousand Oaks, Calif</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Sage</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-0-7619-1544-7 978-0-7619-1545-4</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2004</td>
					</tr>
					<tr>
					<th>Cote</th>
						<td>P93 .K74 2004</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: krippendorff:2004:content-analysis-introduction</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Library of Congress ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Content analysis</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>413</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/08/2023 à 12:19:19</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>29/08/2023 à 12:19:32</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Content analysis</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_SBK8YVFI">Krippendorff - 2004 - Content analysis an introduction to its methodolo.pdf					</li>
				</ul>
			</li>


			<li id="item_9KV6P9UC" class="item journalArticle">
			<h2>Contextual correlates of semantic similarity</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>George A. Miller</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Walter G. Charles</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1080/01690969108406936">https://doi.org/10.1080/01690969108406936</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>6</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-28</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Language and Cognitive Processes</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1991</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: miller-charles:1991:contextual-correlates-semantic</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1080/01690969108406936">10.1080/01690969108406936</a></td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 13:17:31</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:43</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_EWZRQIQE">
<div><div data-schema-version="8"><p>NOTE ERWAN</p>
<blockquote>
<p><strong>URL</strong> : https://doi.org/10.1080/01690969108406936</p>
<p><strong>Note</strong> : Ordonner la similarité de paires de mots =&gt; score inter-annotateur très fort !</p>
</blockquote>
</div></div>
					</li>
				</ul>
			</li>


			<li id="item_VCSGAWQA" class="item bookSection">
			<h2>Corpus and Text: Basic Principles</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>John Sinclair</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Martin Wynne</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ahds.ac.uk/creating/guides/linguistic-corpora/chapter1.htm">http://ahds.ac.uk/creating/guides/linguistic-corpora/chapter1.htm</a></td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>Oxbow Books</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Oxford</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>AHDS: Literature, Languages, and Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-16</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-84217-205-6</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2004</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: sinclair:2004:corpus-text-basic</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>A corpus is a remarkable thing, not so much because it is a 
collection of language text, but because of the properties that it 
acquires if it is well-designed and carefully-constructed.
The guiding principles that relate corpus and text are concepts that are
 not strictly definable, but rely heavily on the good sense and clear 
thinking of the people involved, and feedback from a consensus of users.
 However unsteady is the notion of representativeness, it is an 
unavoidable one in corpus design, and others such as sample and balance 
need to be faced as well. It is probably time for linguists to be less 
squeamish about matters which most scientists take completely for 
granted.
I propose to defer offering a definition of a corpus until after these 
issues have been aired, so that the definition, when it comes, rests on 
as stable foundations as possible. For this reason, the definition of a 
corpus will come at the end of this paper, rather than at the beginning.</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Developing Linguistic Corpora: A Guide to Good Practice</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>05/09/2023 à 14:00:00</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/09/2023 à 15:33:14</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_6775IFEW">Developing linguistic corpora: a guide to good practice</li>
				</ul>
			</li>


			<li id="item_I8VLZMDR" class="item journalArticle">
			<h2>Corpus Annotation Schemes</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>G. Leech</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://academic.oup.com/dsh/article-lookup/doi/10.1093/llc/8.4.275">https://academic.oup.com/dsh/article-lookup/doi/10.1093/llc/8.4.275</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>275-281</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Literary and Linguistic Computing</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0268-1145, 1477-4615</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1993-10-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: leech:1993:corpus-annotation-schemes</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Literary and Linguistic Computing</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1093/llc/8.4.275">10.1093/llc/8.4.275</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>26/09/2023 à 09:10:38</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/09/2023 à 09:10:38</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>10/10/2023 à 09:30:09</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_HPUMXNB9">
<div><div data-schema-version="8"><p><strong>Notes Erwan:</strong></p>
<ol>
<li>
It should always be possible to come back to initial data (example BC). 
Note: can be hard after normalization (“l’arbre” ! “le arbre”, etc.)
</li>
<li>
Annotations should be extractable from the text
</li>
<li>
The annotation procedure should be documented (ex: Brown Corpus annotation guide, Penn Tree Bank annotation guide)
</li>
<li>
Mention should be made of the annotator(s) and the way annotation was 
made (manual/automatic annotation, number of annotators, manually 
corrected/uncorrected...)
</li>
<li>
Annotation is an act of interpretation (cannot be infallible)
</li>
<li>
Annotation schemas should be as independent as possible on formalisms
</li>
<li>
No annotation schema should consider itself a standard (it possibly becomes one)
</li>
</ol>
</div></div>
					</li>
				</ul>
			</li>


			<li id="item_Q4FFLM4C" class="item book">
			<h2>Corpus annotation: linguistic information from computer text corpora</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Roger Garside</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Geoffrey N. Leech</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Tony McEnery</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>London &amp; New York</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Longman</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-0-582-29837-8</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1997</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: garside-etal:1997:corpus-annotation-linguistic</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>K10plus ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Corpus Annotation gives an up-to-date picture of this 
fascinating new area of research, and will provide essential reading for
 newcomers to the field as well as those already involved in corpus 
annotation. Early chapters introduce the different levels and techniques
 of corpus annotation. Later chapters deal with software developments, 
applications, and the development of standards for the evaluation of 
corpus annotation. While the book takes detailed account of research 
world-wide, its focus is particularly on the work of the UCREL 
(University Centre for Computer Corpus Research on Language) team at 
Lancaster University, which has been at the forefront of developments in
 the field of corpus annotation since its beginnings in the 1970s.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Corpus annotation</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>281</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 11:44:05</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>05/09/2023 à 15:13:29</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_QWV7ZQE2">Garside et al. - 1997 - Corpus annotation linguistic information from com.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_R3SAWI72">La définition des annotations linguistiques selon les corpus: de l'écrit journalistique à l'oral</li>
				</ul>
			</li>


			<li id="item_RUVBT5W7" class="item conferencePaper">
			<h2>Creating speech and language data with Amazon's Mechanical Turk</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Chris Callison-Burch</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mark Dredze</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://aclanthology.org/W10-0701">https://aclanthology.org/W10-0701</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Los Angeles</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1–12</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2010-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: callison-burch-dredze:2010:creating-speech-language</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>In this paper we give an introduction to using Amazon’s 
Mechanical Turk crowdsourcing platform for the purpose of collecting 
data for human language technologies. We survey the papers published in 
the NAACL2010 Workshop. 24 researchers participated in the workshop’s 
shared task to create data for speech and language applications with 
$100.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the NAACL HLT 2010 workshop on creating speech and language data with Amazon's mechanical turk</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 15:11:32</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:55:57</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_PZWDA5T5">Callison-Burch et Dredze - 2010 - Creating speech and language data with Amazon's Me.pdf					</li>
				</ul>
			</li>


			<li id="item_8XBM35PZ" class="item conferencePaper">
			<h2>Crowdsourcing complex language resources: Playing to annotate dependency syntax</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Bruno Guillaume</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Karën Fort</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nicolas Lefèbvre</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://inria.hal.science/hal-01378980">https://inria.hal.science/hal-01378980</a></td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Proceedings of the 26th international conference on computational linguistics (COLING)</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Osaka, Japan</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: guillaume-etal:2016:crowdsourcing-complex-language</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This article presents the results we obtained on a complex 
annotation task (that of dependency syntax) using a specifically 
designed Game with a Purpose, ZombiLingo. We show that with suitable 
mechanisms (decomposition of the task, training of the players and 
regular control of the annotation quality during the game), it is 
possible to obtain annotations whose quality is significantly higher 
than that obtainable with a parser, provided that enough players 
participate. The source code of the game and the resulting annotated 
corpora (for French) are freely available.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>International conference on computational linguistics (COLING)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 15:22:26</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 12:10:09</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Annotation</li>
					<li>crowdsourcing</li>
					<li>game with a purpose</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_LDHE9V7J">Guillaume et al. - 2016 - Crowdsourcing complex language resources Playing .pdf					</li>
				</ul>
			</li>


			<li id="item_6BCJ7ZTM" class="item book">
			<h2>Crowdsourcing: how the power of the crowd is driving the future of business</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jeff Howe</td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>Random House Books</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>London</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>RH Business Books</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-905211-12-8 978-1-905211-11-1</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2008</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: howe:2008:crowdsourcing-how-power</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>K10plus ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Jeff Howe coined the word Crowdsourcing in a 2006 article for 
Wired magazine to describe the way in which the Internet has broken down
 traditional employer/employee relationships to create vibrant new 
enterprises that are staffed by informal, often large gatherings of 
enthusiasts. A few weeks before the article hit the newsstands, a Google
 search for the word Crowdsourcing returned zero results. One month 
after the article appeared, the same search returned nearly 500,000 
hits. These days anyone and everyone can write book reviews on Amazon, 
post videos on Youtube, come up with new uses for Google maps or design 
T-shirts for Threadless. What makes this phenomenon so remarkable is 
that it is starting to transform the way many companies operate and to 
change their relationship with their customers- iStockPhoto.com has 
revolutionised the world of digital photography; Cambrian House is 
having a profound impact on the way films get made; Second Life has 
created a vast, profitable business with only a few formal employees but
 thousands of dedicated contributors. Moreover this revolution is 
rapidly changing our culture, introducing a consumer democracy that has 
never existed befo</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Crowdsourcing</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>312</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>09/10/2023 à 12:31:01</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 12:34:14</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_3462XT5Y" class="item journalArticle">
			<h2>Data Representativity for Machine Learning and AI Systems</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Line H. Clemmensen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Rune D. Kjaersgaard</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2203.04706">https://arxiv.org/abs/2203.04706</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: clemmensen-kjaersgaard:2022:data-representativity-machine</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2203.04706">10.48550/ARXIV.2203.04706</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>03/10/2023 à 15:06:55</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Data representativity is crucial when drawing inference from 
data through machine learning models. Scholars have increased focus on 
unraveling the bias and fairness in models, also in relation to inherent
 biases in the input data. However, limited work exists on the 
representativity of samples (datasets) for appropriate inference in AI 
systems. This paper reviews definitions and notions of a representative 
sample and surveys their use in scientific AI literature. We introduce 
three measurable concepts to help focus the notions and evaluate 
different data samples. Furthermore, we demonstrate that the contrast 
between a representative sample in the sense of coverage of the input 
space, versus a representative sample mimicking the distribution of the 
target population is of particular relevance when building AI systems. 
Through empirical demonstrations on US Census data, we evaluate the 
opposing inherent qualities of these concepts. Finally, we propose a 
framework of questions for creating and documenting data with data 
representativity in mind, as an addition to existing dataset 
documentation templates.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>03/10/2023 à 15:06:55</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>03/10/2023 à 15:08:42</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Artificial Intelligence (cs.AI)</li>
					<li>Machine Learning (cs.LG)</li>
					<li>Machine Learning (stat.ML)</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_JMT5BBA7">Clemmensen et Kjaersgaard - 2022 - Data Representativity for Machine Learning and AI .pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_CY6GMSW5">Representative Sampling, II: Scientific Literature, Excluding Statistics</li>
					<li id="item_KB5QTCVP">Representative Sampling, III: The Current Statistical Literature</li>
					<li id="item_KQ2R4AS9">Representative Sampling, I: Non-Scientific Literature</li>
				</ul>
			</li>


			<li id="item_H298UN4D" class="item thesis">
			<h2>De la complexité de l'annotation manuelle : méthodologie, biais et recommandations</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Thèse</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Anaelle Baledent</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://theses.hal.science/tel-04011353">https://theses.hal.science/tel-04011353</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-12-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: baledent:2022:complexite-annotation-manuelle</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Université</th>
						<td>Normandie Université</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Les corpus de référence annotés constituent des éléments 
primordiaux de nombreuses tâches du Traitement Automatique des Langues. 
Leur construction fait l'objet d’une attention particulière, notamment 
lors de campagnes d’annotation manuelle. Ces dernières impliquent de 
multiples aspects, déjà étudiés dans la littérature mais souvent de 
manière séparée. Nous présentons une synthèse des problèmes rencontrés 
lors des différentes étapes d'une campagne, attirant l’attention des 
gestionnaires sur des points de vigilance, afin qu'ils fassent preuve de
 prudence durant leur campagne.Cette thèse donne une première définition
 des biais d’annotation, qui sont des phénomènes perturbateurs et variés
 pouvant avoir une incidence sur les annotations. Nous proposons une 
méthode et des moyens d'observation pour détecter et analyser la 
présence de biais d’annotation. Deux campagnes d’annotation, menées 
spécialement dans le but d'étudier des biais particuliers, servent 
d'illustration et nous ont permis de constater l'influence tangible de 
certains paramètres sur l’annotation. Dans cette optique, nous avons 
aussi introduit la notion de consensualité, qui permet en particulier de
 situer un annotateur par rapport à un groupe. Nous montrons un premier 
lien entre les annotateurs les moins consensuels et les moins 
performants.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>27/06/2023 à 09:28:23</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:58:27</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_PK64N4R8">Baledent - 2022 - De la complexité de l'annotation manuelle  méthod.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_LI7DMFLM">Annotation guidelines for machine learning-based named entity recognition in microbiology</li>
					<li id="item_R3SAWI72">La définition des annotations linguistiques selon les corpus: de l'écrit journalistique à l'oral</li>
				</ul>
			</li>


			<li id="item_XADAMTGI" class="item blogPost">
			<h2>Découvrir les métiers de la data science</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Billet de blog</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vincent Isoz</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://fr.linkedin.com/learning/decouvrir-les-metiers-de-la-data-science/decouvrir-la-data-science">https://fr.linkedin.com/learning/decouvrir-les-metiers-de-la-data-science/decouvrir-la-data-science</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-12-20</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: isoz:2017:decouvrir-metiers-data</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>26/09/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Avec Vincent Isoz, plongez-vous dans le thème à la fois 
actuel, étonnant et futuriste de la data science, ou science des 
données. Après en avoir jeté les bases, votre formateur vous présente 
les 7 métiers majeurs de la data science. Vous y découvrirez les rôles, 
les compétences mais également toutes les interactions et la synergie 
entre eux. À l'issue de cette formation, vous aurez une bonne idée de ce
 qu'est la data science et vous serez apte à mieux suivre l'actualité, 
l'information et les débats à ce sujet.</td>
					</tr>
					<tr>
					<th>Titre du blog</th>
						<td>LinkedIn Learning</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/09/2023 à 12:10:06</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:09:57</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_DYB9HIGA" class="item conferencePaper">
			<h2>Deflating dataset bias using synthetic data augmentation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nikita Jaipuria</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Xianling Zhang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Rohan Bhasin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mayar Arafa</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Punarjay Chakravarty</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Shubham Shrivastava</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sagar Manglani</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vidya N. Murali</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2020-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: jaipuria-etal:2020:deflating-dataset-bias</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Deep Learning has seen an unprecedented increase in vision 
applications since the publication of large-scale object recognition 
datasets and introduction of scalable compute hardware. State-of-the-art
 methods for most vision tasks for Autonomous Vehicles (AVs) rely on 
supervised learning and often fail to generalize to domain shifts and/or
 outliers. Dataset diversity is thus key to successful real-world 
deployment. No matter how big the size of the dataset, capturing long 
tails of the distribution pertaining to task-specific environmental 
factors is impractical. The goal of this paper is to investigate the use
 of targeted synthetic data augmentation - combining the benefits of 
gaming engine simulations and sim2real style transfer techniques - for 
filling gaps in real datasets for vision tasks. Empirical studies on 
three different computer vision tasks of practical use to AVs - parking 
slot detection, lane detection and monocular depth estimation - 
consistently show that having synthetic data in the training mix 
provides a significant boost in cross-dataset generalization performance
 as compared to training on real data only, for the same size of the 
training set.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR) workshops</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>04/10/2023 à 10:50:02</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:04:00</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_RBYWKHHJ">Jaipuria et al. - 2020 - Deflating dataset bias using synthetic data augmen.pdf					</li>
				</ul>
			</li>


			<li id="item_YBPGT7U6" class="item journalArticle">
			<h2>Demographic and occupational predictors of stress and fatigue in 
French intensive-care registered nurses and nurses' aides: A 
cross-sectional study</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gabrielle Jones</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mounia Hocine</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jérôme Salomon</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>William Dab</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Laura Temime</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://linkinghub.elsevier.com/retrieve/pii/S0020748914002016">https://linkinghub.elsevier.com/retrieve/pii/S0020748914002016</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>52</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>250-259</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Journal of Nursing Studies</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>00207489</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2015-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: jones-etal:2015:demographic-occupational-predictors</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>International Journal of Nursing Studies</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.ijnurstu.2014.07.015">10.1016/j.ijnurstu.2014.07.015</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>07/06/2023 à 14:53:40</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Demographic and occupational predictors of stress and fatigue in French intensive-care registered nurses and nurses' aides</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 14:53:40</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:07:09</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Fatigue des opérateurs</li>
					<li>Ergonomie</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_ZYB2IZRE">
<div><div data-schema-version="8"><p>NOTE ERWAN</p>
<blockquote>
<p>La fatigue est décrite comme un épuisement et/ou un inconfort corporel associés à une activité prolongée (Jones et al. (2015)).</p>
</blockquote>
</div></div>
					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_8BSTM6A4">Prise en compte de la fatigue des opérateurs dans la modélisation et la simulation des systèmes de production</li>
					<li id="item_V9825VLK">Integration of human behavioural aspects in a dynamic model for a manufacturing system</li>
				</ul>
			</li>


			<li id="item_47GDCB65" class="item journalArticle">
			<h2>Density-based semi-supervised clustering</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Carlos Ruiz</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Myra Spiliopoulou</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ernestina Menasalvas</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/s10618-009-0157-y">http://link.springer.com/10.1007/s10618-009-0157-y</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>21</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>345-370</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Data Mining and Knowledge Discovery</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1384-5810, 1573-756X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2010-11</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: ruiz-etal:2010:densitybased-semisupervised-clustering</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Data Min Knowl Disc</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/s10618-009-0157-y">10.1007/s10618-009-0157-y</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>12/01/2023 à 13:44:42</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>12/01/2023 à 13:44:42</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:56:14</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>Constrained clustering</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>DBScan</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_T78I7SNJ">Ruiz et al. - 2010 - Density-based semi-supervised clustering.pdf					</li>
				</ul>
			</li>


			<li id="item_AMIHN393" class="item journalArticle">
			<h2>Density‐based clustering</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hans‐Peter Kriegel</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Peer Kröger</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jörg Sander</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Arthur Zimek</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.30">https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.30</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>231-240</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>WIREs Data Mining and Knowledge Discovery</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1942-4787, 1942-4795</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2011-05</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kriegel-etal:2011:density-based-clustering</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>WIREs Data Min &amp; Knowl</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1002/widm.30">10.1002/widm.30</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>17/10/2023 à 16:52:52</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Abstract
            
              Clustering refers to the task of identifying groups or 
clusters in a data set. In
              density‐based clustering
              , a cluster is a set of data objects spread in the data 
space over a contiguous region of high density of objects. Density‐based
 clusters are separated from each other by contiguous regions of low 
density of objects. Data objects located in low‐density regions are 
typically considered noise or outliers. © 2011 John Wiley &amp; Sons, 
Inc.
              WIREs Data Mining Knowl Discov
              2011 1 231–240 DOI: 10.1002/widm.30
            
            
              This article is categorized under:
              
                
                  Technologies &gt; Structure Discovery and Clustering</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>17/10/2023 à 16:52:52</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>17/10/2023 à 16:53:20</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_6775IFEW" class="item book">
			<h2>Developing linguistic corpora: a guide to good practice</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Martin Wynne</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.ahds.ac.uk/creating/guides/linguistic-corpora/index.htm">http://www.ahds.ac.uk/creating/guides/linguistic-corpora/index.htm</a></td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>AHDS literature, languages and linguistics</td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>Oxbow Books</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Oxford</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>AHDS: Literature, Languages, and Linguistics</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-84217-205-6</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2004</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: wynne:2004:developing-linguistic-corpora</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>K10plus ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>A linguistic corpus is a collection of texts which have been 
selected and brought together so that language can be studied on the 
computer. Today, corpus linguistics offers some of the most powerful new
 procedures for the analysis of language, and the impact of this dynamic
 and expanding sub-discipline is making itself felt in many areas of 
language study.
In this volume, a selection of leading experts in various key areas of 
corpus construction offer advice in a readable and largely non-technical
 style to help the reader to ensure that their corpus is well designed 
and fit for the intended purpose.
This Guide is aimed at those who are at some stage of building a 
linguistic corpus. Little or no knowledge of corpus linguistics or 
computational procedures is assumed, although it is hoped that more 
advanced users will also find the guidelines here useful. It also has 
relevance for those who are not building a corpus, but who need to know 
something about the issues involved in the design of corpora in order to
 choose between available resources and to help draw conclusions from 
their analysis.
Increasing numbers of researchers are seeing the potential benefits of 
the use of an electronic corpus as a source of empirical language data 
for their research. Until now, where did they find out about how to 
build a corpus? There is a great deal of useful information available 
which covers principles of corpus design and development, but it is 
dispersed in handbooks, reports, monographs, journal articles and 
sometimes only in the heads of experienced practitioners. This Guide is 
an attempt to draw together the experience of corpus builders into a 
single source, as a starting point for obtaining advice and guidance on 
good practice in this field. It aims to bring together some key elements
 of the experience learned, over many decades, by leading practitioners 
in the field and to make it available to those developing corpora today.
The modest aim of this Guide is to take readers through the basic first 
steps involved in creating a corpus of language data in electronic form 
for the purpose of linguistic research. While some technical issues are 
covered, this Guide does not aim to offer the latest information on 
digitisation techniques. Rather, the emphasis is on the principles, and 
readers are invited to refer to other sources, such as the latest AHDS 
information papers, for the latest advice on technologies. In addition 
to the first chapter on the principles of corpus design, Professor 
Sinclair has also provided a more practical guide to building a corpus, 
which is added as an appendix to the Guide. This should help guide the 
user through some of the more specific decisions that are likely to be 
involved in building a corpus.
Alert readers will see that there are areas where the authors are not in
 accord with each other. It is for the reader to weigh up the advantages
 of each approach for his own particular project, and to decide which 
course to follow. This Guide not aim to synthesize the advice offered by
 the various practitioners into a single approach to creating corpora. 
The information on good practice which is sampled here comes from a 
variety of sources, reflecting different research goals, intellectual 
traditions and theoretical orientations. The individual authors were 
asked to state their opinion on what they think is the best way to deal 
with the relevant aspects of developing a corpus, and neither the 
authors nor the editor have tried to hide the differences in approaches 
which inevitably exist. It is anticipated that readers of this document 
will have differing backgrounds, will have very diverse aims and 
objectives, will be dealing with a variety of different languages and 
varieties, and that one single approach would not fit them all.
I would like to thank the authors of this volume for their goodwill and 
support to this venture, and for their patience through the long period 
it has taken to bring the Guide to publication. I would like to 
acknowledge the extremely helpful advice and editorial work from my 
colleague Ylva Berglund, which has improved many aspects of this guide.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Developing linguistic corpora</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>87</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>05/09/2023 à 14:51:43</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/09/2023 à 15:35:15</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_FZ6PT65D">Wynne - 2005 - Developing linguistic corpora a guide to good pra.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_6QQQVYXV">Adding linguistic annotation.</li>
					<li id="item_VCSGAWQA">Corpus and Text: Basic Principles</li>
				</ul>
			</li>


			<li id="item_JVVSLM4S" class="item bookSection">
			<h2>Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Peter A. Hancock</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Najmedin Meshkati</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sandra G. Hart</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Lowell E. Staveland</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.sciencedirect.com/science/article/pii/S0166411508623869">https://www.sciencedirect.com/science/article/pii/S0166411508623869</a></td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Advances in Psychology</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>52</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>North-Holland</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>139-183</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1988</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: hart-staveland:1988:development-nasatlx-task</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>The results of a multi-year research program to identify the 
factors associated with variations in subjective workload within and 
between different types of tasks are reviewed. Subjective evaluations of
 10 workload-related factors were obtained from 16 different 
experiments. The experimental tasks included simple cognitive and manual
 control tasks, complex laboratory and supervisory control tasks, and 
aircraft simulation. Task-, behavior-, and subject-related correlates of
 subjective workload experiences varied as a function of difficulty 
manipulations within experiments, different sources of workload between 
experiments, and individual differences in workload definition. A 
multi-dimensional rating scale is proposed in which information about 
the magnitude and sources of six workload-related factors are combined 
to derive a sensitive and reliable estimate of workload.</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Human Mental Workload</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 13:17:31</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:33</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Charge mentale</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_JN86584M">
<div><div data-schema-version="8"><p>NOTE ERWAN</p>
<blockquote>
<p><strong>Mental Workload</strong> : nombre de facteurs, difficulté de 
la tâche, nombre de tâche concurrentes, l'habitude de réaliser cette 
tâche, facteurs de l'environnement</p>
<p><strong>Abstract</strong>:</p>
<ul>
<li>
Mental - Combien d'activité mentale et perceptuelle était nécessaire ? 
La tâche était-elle facile ou exigeante, simple ou complexe, exigeante 
ou indulgente ?
</li>
<li>
Physique - Combien d'activité physique était nécessaire ? La tâche 
était-elle facile ou exigeante ? Lent ou rapide ? Lâche ou épuisant ? 
Reposant ou laborieux ?
</li>
<li>
Temporel - Quelle pression de temps avez-vous ressentie en raison de la 
vitesse ou du rythme auquel les tâches ou les éléments de tâche se sont 
produits ? Le rythme était-il lent et tranquille ou rapide et frénétique
 ?
</li>
<li>
Frustration - Dans quelle mesure vous êtes-vous senti insécurisé, 
découragé, irrité, stressé et ennuyé par rapport à sûr, satisfait, 
satisfait, détendu et complaisant pendant la tâche ?
</li>
<li>
Effort- À quel point avez-vous dû travailler (mentalement et physiquement) pour atteindre votre niveau de performance ?
</li>
<li>
Performance- Dans quelle mesure pensez-vous avoir réussi à atteindre les
 objectifs de la tâche définie par l'expérimentateur (ou vous-même) ? 
Quel est votre niveau de satisfaction ?
</li>
</ul>
</blockquote>
</div></div>
					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_X5GGWCMD">Usability assessment: how to measure the usability of products, services, and systems</li>
				</ul>
			</li>


			<li id="item_Q5DZ5XTK" class="item journalArticle">
			<h2>Dialogue Management in Conversational Systems: A Review of Approaches, Challenges, and Opportunities</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hayet Brabra</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Marcos Baez</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Boualem Benatallah</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Walid Gaaloul</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sara Bouguelia</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Shayan Zamanirad</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/9447005/">https://ieeexplore.ieee.org/document/9447005/</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>14</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>783-798</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IEEE Transactions on Cognitive and Developmental Systems</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2379-8920, 2379-8939</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-09</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: brabra-etal:2022:dialogue-management-conversational</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>IEEE Trans. Cogn. Dev. Syst.</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/TCDS.2021.3086565">10.1109/TCDS.2021.3086565</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>26/07/2023 à 13:37:31</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Attracted by their easy-to-use interfaces and captivating 
beneﬁts, conversational systems have been widely embraced by many 
individuals and organizations as side-by-side digital co-workers. They 
enable the understanding of user needs, expressed in natural language, 
and on fulﬁlling such needs by invoking the appropriate backend services
 (e.g., APIs). Controlling the conversation ﬂow, known as Dialogue 
Management, is one of the essential tasks in conversational systems and 
the key to its success and adoption as well. Nevertheless, designing 
scalable and robust dialogue management techniques to effectively 
support intelligent conversations remains a deeply challenging problem. 
This article studies dialogue management from an in-depth design 
perspective. We discuss the state of the art approaches, identify their 
recent advances and challenges, and provide an outlook on future 
research directions. Thus, we contribute to guiding researchers and 
practitioners in selecting the appropriate dialogue management approach 
aligned with their objectives, among the variety of approaches proposed 
so far.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Dialogue Management in Conversational Systems</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/07/2023 à 13:37:31</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>16/10/2023 à 17:03:08</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Dialogue</li>
					<li>Chat</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_TI5LAJ4X">Brabra et al. - 2022 - Dialogue Management in Conversational Systems A R.pdf					</li>
				</ul>
			</li>


			<li id="item_RRNIGX5N" class="item journalArticle">
			<h2>Different Methods Review for Speech to Text and Text to Speech Conversion</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Deep Kothadiya</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nitin Pise</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mangesh Bedekar</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.ijcaonline.org/archives/volume175/number20/kothadiya-2020-ijca-920727.pdf">http://www.ijcaonline.org/archives/volume175/number20/kothadiya-2020-ijca-920727.pdf</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>175</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>20</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>9-12</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Journal of Computer Applications</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>09758887</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2020-09-17</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kothadiya-etal:2020:different-methods-review</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>IJCA</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.5120/ijca2020920727">10.5120/ijca2020920727</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>18/09/2023 à 16:00:54</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>In the instant corporation, transmission is the primary 
fundamental to momentum. Transitory information, to the correct person 
with the correct aspect is very essential, not just on an industry 
level, but also on an individual position. Nature is inspiring in the 
direction of digitization and the mechanisms of intercommunication. 
Telephone calling, emails, text memorandums belong to a fundamental 
element of signal communication in this tech-intellect nature. In 
procedures to distribute the intention of adequate transmission 
intervening two endpoints without obstacles, numerous utilizations have 
shown up the impression, which operates as an intermediary and helps in 
efficiently transmitting signals in the scheme of text or speech 
messages accomplished huge structure of webs. Most of these 
implementations discover the Usage of tasks essentially articulatory and
 acoustic-positioned speech recognition, reorganization from audio 
messages to text, and then text to artificial speech signals, vocabulary
 interpretation amidst individual leftovers. Researchers will be 
penetrating distinct algorithms and techniques that are enforced to 
obtain the specified utilitarian.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 16:00:54</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:02:56</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_8JQQGUQT">Kothadiya et al. - 2020 - Different Methods Review for Speech to Text and Te.pdf					</li>
				</ul>
			</li>


			<li id="item_9S5FJH6M" class="item journalArticle">
			<h2>Distributional Structure</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zellig S. Harris</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.tandfonline.com/doi/full/10.1080/00437956.1954.11659520">http://www.tandfonline.com/doi/full/10.1080/00437956.1954.11659520</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>10</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2-3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>146-162</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Word</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0043-7956, 2373-5112</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1954-08</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: harris:1954:distributional-structure</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>&lt;i&gt;WORD&lt;/i&gt;</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1080/00437956.1954.11659520">10.1080/00437956.1954.11659520</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>21/10/2023 à 16:50:06</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>21/10/2023 à 16:50:06</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>21/10/2023 à 16:51:01</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Bag of words</li>
				</ul>
			</li>


			<li id="item_YNQZ5VG6" class="item newspaperArticle">
			<h2>Exclusive: OpenAI used Kenyan workers on less than $2 per hour to make ChatGPT less toxic</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Billy Perrigo</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Julia Zorthian</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://time.com/6247678/openai-chatgpt-kenya-workers/">https://time.com/6247678/openai-chatgpt-kenya-workers/</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>New York</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Time</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-01-18</td>
					</tr>
					<tr>
					<th>Section</th>
						<td>Business, Technology</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: perrigo-zorthian:2023:exclusive-openai-used</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 09:23:13</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:59:45</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_IXMEZNQL" class="item journalArticle">
			<h2>Experts ou (foule de) non-experts ? la question de l’expertise des annotateurs vue de la myriadisation (crowdsourcing)</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Karën Fort</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://journals.openedition.org/corela/4835">http://journals.openedition.org/corela/4835</a></td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>HS-21</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Corela</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1638-573X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-01-19</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: fort:2017:experts-ou-foule</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>corela</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.4000/corela.4835">10.4000/corela.4835</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>21/09/2023 à 18:32:42</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Experts ou (foule de) non-experts ?</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>21/09/2023 à 18:32:42</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:09:02</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_XJB2GERR">Fort - 2017 - Experts ou (foule de) non-experts  la question de.pdf					</li>
				</ul>
			</li>


			<li id="item_YJ4LTCVX" class="item book">
			<h2>Foundations of statistical natural language processing</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Christopher D. Manning</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hinrich Schütze</td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>2e éd. avec des corrections</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Cambridge, Mass</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>MIT Press</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2000</td>
					</tr>
					<tr>
					<th>Cote</th>
						<td>410.285</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: manning-schutze:2000:foundations-statistical-natural</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>BnF ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 15:27:32</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:27</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_WINIYV9I">Manning et Schütze - 2000 - Foundations of statistical natural language proces.pdf					</li>
				</ul>
			</li>


			<li id="item_7SEJPTW4" class="item dataset">
			<h2>French trainset for chatbots dealing with usual requests on bank cards</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Dataset</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.5281/zenodo.4769949">https://doi.org/10.5281/zenodo.4769949</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Creative Commons Attribution 4.0 International, Open Access</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-11-09</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild:2022:french-trainset-chatbots</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.5281/zenodo.4769949">10.5281/zenodo.4769949</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>13/02/2023 à 15:03:51</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>&lt;strong&gt;[EN] French training dataset for chatbots 
dealing with usual requests on bank cards.&lt;/strong&gt; 
&lt;strong&gt;Description&lt;/strong&gt;: This dataset represents 
examples of common customer requests relating to bank cards management. 
It can be used as a training set for a small chatbot intended to process
 these usual requests. &lt;strong&gt;Content&lt;/strong&gt;: The 
questions are asked in French. The dataset is divided into 10 intents of
 100 questions each, for a total of 1 000 questions. 
&lt;strong&gt;Intents scope&lt;/strong&gt;: Intents are constructed in 
such a way that all questions arising from the same intention have the 
same response or action. The scope covered concerns: loss or theft of 
cards; the swallowed card; the card order; consultation of the bank 
balance; insurance provided by a card; card unlocking; virtual card 
management; management of bank overdraft; management of payment limits; 
management of contactless mode. &lt;strong&gt;Origin&lt;/strong&gt;: 
Intents scope is inspired by a chatbot currently in production, and the 
wording of the questions are inspired by the usual customers requests. 
&lt;br&gt; &lt;strong&gt;[FR] Jeu d'entraînement en français 
d'assistants conversationnels traitant des demandes courantes sur les 
cartes bancaires.&lt;/strong&gt; &lt;strong&gt;Description 
&lt;/strong&gt;: Cet ensemble de données représente des exemples de 
demandes usuelles des clients concernant la gestion des cartes 
bancaires. Il peut être utilisé comme jeu d'entraînement pour un 
assistant conversationnel destiné à traiter ces demandes courantes. 
&lt;strong&gt;Contenu &lt;/strong&gt;: Les questions sont formulées en 
français. L'ensemble de données est divisé en 10 intentions de 100 
questions chacune, pour un total de 1 000 questions. 
&lt;strong&gt;Périmètre des intentions&lt;/strong&gt; : Les intentions 
sont construites de telle manière que toutes les questions issues d'une 
même intention ont la même réponse ou action. Le périmètre couvert 
concerne : la perte ou le vol de cartes ; la carte avalée ; la commande 
des cartes ; la consultation du solde bancaire ; l'assurance fournie par
 une carte ; le déverrouillage de la carte ; la gestion de cartes 
virtuelles ; la gestion du découvert bancaire ; la gestion des plafonds 
de paiement ; la gestion du mode sans contact. &lt;strong&gt;Origine 
&lt;/strong&gt;: Le périmètre des intentions est inspiré par un chatbot 
actuellement en production, et la formulation des questions est inspirée
 de demandes courantes de clients.</td>
					</tr>
					<tr>
					<th>Dépôt</th>
						<td>Zenodo</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>13/02/2023 à 15:03:51</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>16/10/2023 à 10:07:50</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>*PUBLICATION</li>
					<li>Chatbot</li>
					<li>Bank cards management</li>
					<li>Trainset</li>
					<li>Natural language processing</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_2YJEM4BD">French_trainset_for_chatbots_dealing_with_usual_requests_on_bank_cards_v1.0.0.xlsx					</li>
					<li id="item_FGW9EV2H">French_trainset_for_chatbots_dealing_with_usual_requests_on_bank_cards_v2.0.0_UNLABELED.xlsx					</li>
					<li id="item_KYG43CY9">French_trainset_for_chatbots_dealing_with_usual_requests_on_bank_cards_v2.0.0.xlsx					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_BK779LMD">cognitivefactory/interactive-clustering-comparative-study</li>
					<li id="item_H2VW9Y69">Iterative and Semi-Supervised Design of Chatbots Using Interactive Clustering</li>
				</ul>
			</li>


			<li id="item_DKT2BBXI" class="item journalArticle">
			<h2>Games with a Purpose</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>L. Von Ahn</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/1642623/">http://ieeexplore.ieee.org/document/1642623/</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>39</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>92-94</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Computer</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0018-9162</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2006-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: von-ahn:2006:games-purpose</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Computer</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/MC.2006.196">10.1109/MC.2006.196</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>09/10/2023 à 12:34:41</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Through online games, people can collectively solve 
large-scale computational problems. Such games constitute a general 
mechanism for using brain power to solve open problems. In fact, 
designing such a game is much like designing an algorithm - it must be 
proven correct, its efficiency can be analyzed, a more efficient version
 can supersede a less efficient one, and so on. "Games with a purpose" 
have a vast range of applications in areas as diverse as security, 
computer vision, Internet accessibility, adult content filtering, and 
Internet search. Any game designed to address these and other problems 
must ensure that game play results in a correct solution and, at the 
same time, is enjoyable. People will play such games to be entertained, 
not to solve a problem - no matter how laudable the objective</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>09/10/2023 à 12:34:41</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>24/10/2023 à 08:06:07</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_9GGTU76I" class="item newspaperArticle">
			<h2>Gartner Predicts Chatbots Will Become a Primary Customer Service Channel Within Five Years</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Katie Costello</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Matt LoDolce</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.gartner.com/en/newsroom/press-releases/2022-07-27-gartner-predicts-chatbots-will-become-a-primary-customer-service-channel-within-five-years">https://www.gartner.com/en/newsroom/press-releases/2022-07-27-gartner-predicts-chatbots-will-become-a-primary-customer-service-channel-within-five-years</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Gartner, Inc</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-07</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: costello-lodolce:2022:gartner-predicts-chatbots</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>09/10/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en-US</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Chatbot Investment on the Rise but Low ROI and Other Challenges Persist</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>09/10/2023 à 17:01:44</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 17:03:45</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_BRSPTZRL" class="item newspaperArticle">
			<h2>Gartner Top Technologies and Trends Driving the Digital Workplace</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Katie Costello</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Matt LoDolce</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.gartner.com/smarterwithgartner/top-10-technologies-driving-the-digital-workplace/">https://www.gartner.com/smarterwithgartner/top-10-technologies-driving-the-digital-workplace/</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Gartner, Inc</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-03-18</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: costello-lodolce:2019:gartner-top-technologies</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>23/10/2020 à 09:12:05</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en-US</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>How artificial intelligence, smart workspaces and talent 
markets will boost employee digital dexterity in future digital 
workplaces.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2020 à 09:12:05</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 17:11:27</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_XSZP4GXT" class="item journalArticle">
			<h2>Generalized Linear Models</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>J. A. Nelder</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>R. W. M. Wedderburn</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.jstor.org/stable/10.2307/2344614?origin=crossref">https://www.jstor.org/stable/10.2307/2344614?origin=crossref</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>135</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>370</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of the Royal Statistical Society. Series A (General)</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>00359238</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1972</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: nelder-wedderburn:1972:generalized-linear-models</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Journal of the Royal Statistical Society. Series A (General)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.2307/2344614">10.2307/2344614</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 16:28:13</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 16:28:13</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:44</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>GLM</li>
				</ul>
			</li>


			<li id="item_RW2SGFFZ" class="item newspaperArticle">
			<h2>Generative AI takes stereotypes and bias from bad to worse</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Leonardo Nicoletti</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dina Bass</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.bloomberg.com/graphics/2023-generative-ai-bias/">https://www.bloomberg.com/graphics/2023-generative-ai-bias/</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Bloomberg.com</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: nicoletti-bass:2023:generative-ai-takes</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>02/10/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>The world according to Stable Diffusion is run by White male 
CEOs. Women are rarely doctors, lawyers or judges. Men with dark skin 
commit crimes, while women with dark skin flip burgers.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>02/10/2023 à 10:49:37</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:59:24</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_MXUDSNHJ" class="item computerProgram">
			<h2>Google assistant, your own personal google</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Google</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://assistant.google.com/">https://assistant.google.com/</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: google:2016:google-assistant-your</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Google</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>09/10/2023 à 19:11:57</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 19:13:16</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_6XY3GGJM" class="item journalArticle">
			<h2>How many words do we read per minute? A review and meta-analysis of reading rate</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Marc Brysbaert</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://linkinghub.elsevier.com/retrieve/pii/S0749596X19300786">https://linkinghub.elsevier.com/retrieve/pii/S0749596X19300786</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>109</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>104047</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of Memory and Language</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0749596X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: brysbaert:2019:how-many-words</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Journal of Memory and Language</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.jml.2019.104047">10.1016/j.jml.2019.104047</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>27/06/2023 à 10:10:00</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>How many words do we read per minute?</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>27/06/2023 à 10:10:00</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:10:25</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_LFREK45J">
<div><div data-schema-version="8"><p><span style="color: rgb(51, 51, 51)"><span style="background-color: rgb(255, 255, 255)">Based
 on the analysis of 190 studies (18,573 participants), we estimate that 
the average silent reading rate for adults in English is 238 words per 
minute (wpm) for non-fiction and 260 wpm for fiction</span></span></p>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_6HQS5M2Y">Brysbaert - 2019 - How many words do we read per minute A review and.pdf					</li>
				</ul>
			</li>


			<li id="item_B6PVZKSG" class="item webpage">
			<h2>How Microsoft’s bet on Azure unlocked an AI revolution</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Page Web</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>John Roach</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://news.microsoft.com/">https://news.microsoft.com/</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: roach:2023:how-microsoft-bet</td>
					</tr>
					<tr>
					<th>Type de site Web</th>
						<td>Blog</td>
					</tr>
					<tr>
					<th>Titre du site Web</th>
						<td>Microsoft</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>20/07/2023 à 14:39:23</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>20/07/2023 à 14:54:44</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_KASL38UF" class="item dataset">
			<h2>Hugging Face - the AI community building the future.</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Dataset</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hugging Face</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://huggingface.co/datasets">https://huggingface.co/datasets</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: hugging-face:2016:hugging-face-ai</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 10:25:33</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>29/09/2023 à 10:26:51</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_YI7TERPH" class="item report">
			<h2>Human and Computer Control of Undersea Teleoperators</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Rapport</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Thomas B. Sheridan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>William L. Verplank</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.dtic.mil/docs/citations/ADA057655">http://www.dtic.mil/docs/citations/ADA057655</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Fort Belvoir, VA</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1978-07-15</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: sheridan-verplank:1978:human-computer-control</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>01/09/2023 à 16:54:36</td>
					</tr>
					<tr>
					<th>Institution</th>
						<td>Defense Technical Information Center</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Human and Computer Control of Undersea Teleoperators</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>01/09/2023 à 16:54:36</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:29:09</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_HIXFEHEF">Sheridan et Verplank - 1978 - Human and Computer Control of Undersea Teleoperato.pdf					</li>
				</ul>
			</li>


			<li id="item_JIKZIKB7" class="item newspaperArticle">
			<h2>IA : L'auteur de "Game of Thrones" et d'autres écrivains portent plainte contre le créateur de ChatGPT</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Les Echos</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.lesechos.fr/tech-medias/intelligence-artificielle/ia-lauteur-de-game-of-thrones-et-dautres-ecrivains-portent-plainte-contre-le-createur-de-chatgpt-1980235">https://www.lesechos.fr/tech-medias/intelligence-artificielle/ia-lauteur-de-game-of-thrones-et-dautres-ecrivains-portent-plainte-contre-le-createur-de-chatgpt-1980235</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Les Echos</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-09-21</td>
					</tr>
					<tr>
					<th>Section</th>
						<td>Tech-Médias</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: les-echos:2023:ia-auteur-game</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Ils accusent OpenAI d'avoir entraîné son intelligence 
artificielle avec leurs oeuvres, permettant ainsi à ChatGPT d'être en 
mesure de produire des contenus dérivés, imitant le style des écrivains.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 10:37:23</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:58:46</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_NX9XV2GL" class="item newspaperArticle">
			<h2>IA : Les médias français s'organisent face à la collecte de données par les robots</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Stéphane Loignon</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.lesechos.fr/tech-medias/medias/ia-les-medias-francais-sorganisent-face-a-la-collecte-de-donnees-par-les-robots-1973079">https://www.lesechos.fr/tech-medias/medias/ia-les-medias-francais-sorganisent-face-a-la-collecte-de-donnees-par-les-robots-1973079</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Les Echos</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-08-28</td>
					</tr>
					<tr>
					<th>Section</th>
						<td>Tech-Médias</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: loignon:2023:ia-medias-francais</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>04/10/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>A l'image du « New York Times », quelques sites français, dont
 ceux de Radio France et TF1, empêchent le robot GPTBot d'OpenAI de se 
nourrir de leurs contenus. Refusant d'être « pillé », le secteur 
réfléchit à la manière d'obtenir une juste rémunération de la part des 
géants de l'IA.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>04/10/2023 à 18:34:50</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:58:53</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_L2Z6AR5Q" class="item journalArticle">
			<h2>IBM Watson Analytics: Automating Visualization, Descriptive, and Predictive Statistics</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Robert Eugene Hoyt</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dallas Snider</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Carla Thompson</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sarita Mantravadi</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.2196/publichealth.5810">https://doi.org/10.2196/publichealth.5810</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>JMIR Public Health Surveill</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2369-2960</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-10-11</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: hoyt-etal:2016:ibm-watson-analytics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.2196/publichealth.5810">10.2196/publichealth.5810</a></td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Background: We live in an era of explosive data generation 
that will continue to grow and involve all industries. One of the 
results of this explosion is the need for newer and more efficient data 
analytics procedures. Traditionally, data analytics required a 
substantial background in statistics and computer science. In 2015, 
International Business Machines Corporation (IBM) released the IBM 
Watson Analytics (IBMWA) software that delivered advanced statistical 
procedures based on the Statistical Package for the Social Sciences 
(SPSS). The latest entry of Watson Analytics into the field of 
analytical software products provides users with enhanced functions that
 are not available in many existing programs. For example, Watson 
Analytics automatically analyzes datasets, examines data quality, and 
determines the optimal statistical approach. Users can request 
exploratory, predictive, and visual analytics. Using natural language 
processing (NLP), users are able to submit additional questions for 
analyses in a quick response format. This analytical package is 
available free to academic institutions (faculty and students) that plan
 to use the tools for noncommercial purposes. Objective: To report the 
features of IBMWA and discuss how this software subjectively and 
objectively compares to other data mining programs. Methods: The salient
 features of the IBMWA program were examined and compared with other 
common analytical platforms, using validated health datasets. Results: 
Using a validated dataset, IBMWA delivered similar predictions compared 
with several commercial and open source data mining software 
applications. The visual analytics generated by IBMWA were similar to 
results from programs such as Microsoft Excel and Tableau Software. In 
addition, assistance with data preprocessing and data exploration was an
 inherent component of the IBMWA application. Sensitivity and 
specificity were not included in the IBMWA predictive analytics results,
 nor were odds ratios, confidence intervals, or a confusion matrix. 
Conclusions: IBMWA is a new alternative for data analytics software that
 automates descriptive, predictive, and visual analytics. This program 
is very user-friendly but requires data preprocessing, statistical 
conceptual understanding, and domain expertise.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2020 à 10:29:40</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:08:24</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>NLP</li>
					<li>Machine learning</li>
					<li>*CITATION</li>
					<li>IBM Watson</li>
					<li>Data analysis</li>
					<li>Data mining</li>
					<li>Statistical data analysis</li>
				</ul>
			</li>


			<li id="item_GDX5QHRX" class="item book">
			<h2>Inductive Dependency Parsing</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Joakim Nivre</td>
					</tr>
					<tr>
						<th class="seriesEditor">Directeur de coll.</th>
						<td>Nancy Ide</td>
					</tr>
					<tr>
						<th class="seriesEditor">Directeur de coll.</th>
						<td>Jean Véronis</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/1-4020-4889-0">http://link.springer.com/10.1007/1-4020-4889-0</a></td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Text, Speech and Language Technology</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>34</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Dordrecht</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer Netherlands</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4020-4888-3 978-1-4020-4889-0</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2006</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: nivre:2006:inductive-dependency-parsing</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 15:37:04</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 15:32:36</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:44</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_YZEE8JPF">Nivre - 2006 - Inductive Dependency Parsing.pdf					</li>
				</ul>
			</li>


			<li id="item_S6593ULB" class="item conferencePaper">
			<h2>Influence of pre-annotation on POS-Tagged corpus development</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Karën Fort</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Benoît Sagot</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://aclanthology.org/W10-1807">https://aclanthology.org/W10-1807</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Uppsala, Sweden</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>56–63</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2010-07</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: fort-sagot:2010:influence-preannotation-postagged</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This article details a series of carefully designed 
experiments aiming at evaluating the influence of automatic 
pre-annotation on the manual part-of-speech annotation of a corpus, both
 from the quality and the time points of view, with a specific attention
 drawn to biases. For this purpose, we manually annotated parts of the 
Penn Treebank corpus (Marcus et al., 1993) under various experimental 
setups, either from scratch or using various pre-annotations. These 
experiments confirm and detail the gain in quality observed before 
(Marcus et al., 1993; Dandapat et al., 2009; Rehbein et al., 2009), 
while showing that biases do appear and should be taken into account. 
They finally demonstrate that even a notso accurate tagger can help 
improving annotation speed</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the fourth linguistic annotation workshop</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>28/09/2023 à 10:55:19</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 09:59:58</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_W6CEI465">Fort et Sagot - 2010 - Influence of pre-annotation on POS-Tagged corpus d.pdf					</li>
				</ul>
			</li>


			<li id="item_V9825VLK" class="item journalArticle">
			<h2>Integration of human behavioural aspects in a dynamic model for a manufacturing system</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>S. Elkosantini</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>D. Gien</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.tandfonline.com/doi/full/10.1080/00207540701663490">https://www.tandfonline.com/doi/full/10.1080/00207540701663490</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>47</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>10</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>2601-2623</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Journal of Production Research</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0020-7543, 1366-588X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2009-05-15</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: elkosantini-gien:2009:integration-human-behavioural</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>International Journal of Production Research</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1080/00207540701663490">10.1080/00207540701663490</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>07/06/2023 à 14:54:24</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 14:54:24</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:55:19</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Fatigue des opérateurs</li>
					<li>Ergonomie</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_6KNLG4GJ">
<div><div data-schema-version="8"><p>NOTE ERWAN</p>
<blockquote>
<p>Dans le travail de Elkosantini et Gien (2009), les auteurs ont défini
 la fatigue comme un état de capacité réduite à travailler après une 
période d’activité</p>
</blockquote>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_BVES3475">Elkosantini et Gien - 2009 - Integration of human behavioural aspects in a dyna.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_8BSTM6A4">Prise en compte de la fatigue des opérateurs dans la modélisation et la simulation des systèmes de production</li>
					<li id="item_YBPGT7U6">Demographic and occupational predictors of 
stress and fatigue in French intensive-care registered nurses and 
nurses' aides: A cross-sectional study</li>
				</ul>
			</li>


			<li id="item_VXL7USXF" class="item journalArticle">
			<h2>Inter-Coder Agreement for Computational Linguistics</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ron Artstein</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Massimo Poesio</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://direct.mit.edu/coli/article/34/4/555-596/1999">https://direct.mit.edu/coli/article/34/4/555-596/1999</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>34</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>555-596</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Computational Linguistics</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0891-2017, 1530-9312</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2008-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: artstein-poesio:2008:intercoder-agreement-computational</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Computational Linguistics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1162/coli.07-034-R2">10.1162/coli.07-034-R2</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>31/08/2023 à 15:26:20</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This article is a survey of methods for measuring agreement 
among corpus annotators. It exposes the mathematics and underlying 
assumptions of agreement coefficients, covering Krippendorff's alpha as 
well as Scott's pi and Cohen's kappa; discusses the use of coefficients 
in several annotation tasks; and argues that weighted, alpha-like 
coefficients, traditionally less used than kappa-like measures in 
computational linguistics, may be more appropriate for many corpus 
annotation tasks—but that their use makes the interpretation of the 
value of the coefficient even harder.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 15:26:20</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:55:04</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_5MU8HATV">Artstein et Poesio - 2008 - Inter-Coder Agreement for Computational Linguistic.pdf					</li>
				</ul>
			</li>


			<li id="item_8M6YG7LF" class="item journalArticle">
			<h2>Interactive Clustering: A Comprehensive Review</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Juhee Bae</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tove Helldin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Maria Riveiro</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sławomir Nowaczyk</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mohamed-Rafik Bouguelia</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Göran Falkman</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://dl.acm.org/doi/10.1145/3340960">https://dl.acm.org/doi/10.1145/3340960</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>53</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-39</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ACM Computing Surveys</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0360-0300, 1557-7341</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-01-31</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: bae-etal:2021:interactive-clustering-comprehensive</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>ACM Comput. Surv.</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3340960">10.1145/3340960</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>16/01/2023 à 11:23:19</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>In this survey, 105 papers related to interactive clustering 
were reviewed according to seven perspectives: (1) on what level is the 
interaction happening, (2) which interactive operations are involved, 
(3) how user feedback is incorporated, (4) how interactive clustering is
 evaluated, (5) which data and (6) which clustering methods have been 
used, and (7) what outlined challenges there are. This article serves as
 a comprehensive overview of the field and outlines the state of the art
 within the area as well as identifies challenges and future research 
needs.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Interactive Clustering</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>16/01/2023 à 11:23:19</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>16/10/2023 à 18:28:17</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>*PUBLICATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_MFPWVXQQ">Bae et al. - 2021 - Interactive Clustering A Comprehensive Review.pdf					</li>
				</ul>
			</li>


			<li id="item_KUFLC747" class="item webpage">
			<h2>Introducing the ai research supercluster - meta’s cutting-edge ai supercomputer for ai research</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Page Web</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kevin Lee</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Shubho Sengupta</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ai.meta.com/blog/ai-rsc/">https://ai.meta.com/blog/ai-rsc/</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: lee-sengupta:2022:introducing-ai-research</td>
					</tr>
					<tr>
					<th>Type de site Web</th>
						<td>Blog</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Developing the next generation of advanced AI will require 
powerful new computers capable of quintillions of operations per second.
 Today, Meta is announcing that we’ve designed and built the AI Research
 SuperCluster (RSC) — which we believe is among the fastest AI 
supercomputers running today and will be the fastest AI supercomputer in
 the world when it’s fully built out in mid-2022. Our researchers have 
already started using RSC to train large models in natural language 
processing (NLP) and computer vision for research, with the aim of one 
day training models with trillions of parameters.

RSC will help Meta’s AI researchers build new and better AI models that 
can learn from trillions of examples; work across hundreds of different 
languages; seamlessly analyze text, images, and video together; develop 
new augmented reality tools; and much more. Our researchers will be able
 to train the largest models needed to develop advanced AI for computer 
vision, NLP, speech recognition, and more. We hope RSC will help us 
build entirely new AI systems that can, for example, power real-time 
voice translations to large groups of people, each speaking a different 
language, so they can seamlessly collaborate on a research project or 
play an AR game together. Ultimately, the work done with RSC will pave 
the way toward building technologies for the next major computing 
platform — the metaverse, where AI-driven applications and products will
 play an important role.</td>
					</tr>
					<tr>
					<th>Titre du site Web</th>
						<td>Meta AI</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>20/07/2023 à 14:17:59</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>20/07/2023 à 14:22:33</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_6YRGVLZJ" class="item journalArticle">
			<h2>Issues,Challenges and Tools of Clustering Algorithms</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Parul Agarwal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>M. Afshar Alam</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ranjit Biswas</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/1110.2610">https://arxiv.org/abs/1110.2610</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IJCSI International Journal of Computer Science Issues</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2011-05</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: agarwal-etal:2011:issues-challenges-tools</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.1110.2610">10.48550/ARXIV.1110.2610</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>16/10/2023 à 18:20:03</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Clustering is an unsupervised technique of Data Mining. It 
means grouping similar objects together and separating the dissimilar 
ones. Each object in the data set is assigned a class label in the 
clustering process using a distance measure. This paper has captured the
 problems that are faced in real when clustering algorithms are 
implemented .It also considers the most extensively used tools which are
 readily available and support functions which ease the programming. 
Once algorithms have been implemented, they also need to be tested for 
its validity. There exist several validation indexes for testing the 
performance and accuracy which have also been discussed here.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>16/10/2023 à 18:20:03</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>16/10/2023 à 18:21:29</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Machine Learning (cs.LG)</li>
					<li>Information Retrieval (cs.IR)</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_B3XRJ53I">Agarwal et al. - 2011 - Issues,Challenges and Tools of Clustering Algorith.pdf					</li>
				</ul>
			</li>


			<li id="item_E4PG48ZP" class="item newspaperArticle">
			<h2>"It's destroyed me completely": Kenyan moderators decry toll of training of AI models</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de journal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Niamh Rowe</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.theguardian.com/technology/2023/aug/02/ai-chatbot-training-human-toll-content-moderator-meta-openai">https://www.theguardian.com/technology/2023/aug/02/ai-chatbot-training-human-toll-content-moderator-meta-openai</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>The Guardian</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-08-02</td>
					</tr>
					<tr>
					<th>Section</th>
						<td>Artificial Intelligence</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: rowe:2023:it-destroyed-me</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Employees describe the psychological trauma of reading and viewing graphic content, low pay and abrupt dismissals</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 09:18:57</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:59:00</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_H2VW9Y69" class="item journalArticle">
			<h2>Iterative and Semi-Supervised Design of Chatbots Using Interactive Clustering</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gautier Durantin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jean-Charles Lamirel</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Florian Miconi</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJDWM.298007">https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJDWM.298007</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>All rights reserved</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>18</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-19</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Journal of Data Warehousing and Mining (IJDWM)</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1548-3924</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-04-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild-etal:2022:iterative-semisupervised-design</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.4018/IJDWM.298007">10.4018/IJDWM.298007</a></td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Chatbots represent a promising tool to automate the processing
 of requests in a business context. However, despite major progress in 
natural language processing technologies, constructing a dataset deemed 
relevant by business experts is a manual, iterative and error-prone 
process. To assist these experts during modelling and labelling, the 
authors propose an active learning methodology coined Interactive 
Clustering. It relies on interactions between computer-guided 
segmentation of data in intents, and response-driven human annotations 
imposing constraints on clusters to improve relevance.This article 
applies Interactive Clustering on a realistic dataset, and measures the 
optimal settings required for relevant segmentation in a minimal number 
of annotations. The usability of the method is discussed in terms of 
computation time, and the achieved compromise between business relevance
 and classification performance during training.In this context, 
Interactive Clustering appears as a suitable methodology combining human
 and computer initiatives to efficiently develop a useable chatbot.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Iterative and Semi-Supervised Design of Chatbots Using Interactive Clustering</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>21/04/2022 à 10:11:00</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:00:56</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>INTERACTIVE_CLUSTERING</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>*PUBLICATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_QPFCLFA7">Schild et al. - 2022 - Iterative and Semi-Supervised Design of Chatbots U.pdf					</li>
					<li id="item_TW3MBXVX">Schild et al. - 2022 - Iterative and Semi-Supervised Design of Chatbots U.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_7SEJPTW4">French trainset for chatbots dealing with usual requests on bank cards</li>
				</ul>
			</li>


			<li id="item_2VHLGF84" class="item journalArticle">
			<h2>Keyword Research, Competitor Analysis, &amp; Website Ranking | Alexa</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alexa Internet</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.alexa.com/">https://www.alexa.com</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018-01-27</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: alexa-internet:2018:keyword-research-competitor</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2020 à 10:26:31</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 18:57:24</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_Y2YLI7B2" class="item book">
			<h2>L'ergonomie du travail mental</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jean-Claude Sperandio</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>FeniXX</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1987</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: sperandio:1987:ergonomie-travail-mental</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>01/09/2023 à 17:13:13</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>01/09/2023 à 17:13:36</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_QSMB67J7" class="item journalArticle">
			<h2>Language Models are Few-Shot Learners</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tom B. Brown</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Benjamin Mann</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nick Ryder</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Melanie Subbiah</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jared Kaplan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Prafulla Dhariwal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Arvind Neelakantan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Pranav Shyam</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Girish Sastry</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Amanda Askell</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sandhini Agarwal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ariel Herbert-Voss</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gretchen Krueger</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tom Henighan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Rewon Child</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Aditya Ramesh</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Daniel M. Ziegler</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jeffrey Wu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Clemens Winter</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Christopher Hesse</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mark Chen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Eric Sigler</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mateusz Litwin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Scott Gray</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Benjamin Chess</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jack Clark</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Christopher Berner</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sam McCandlish</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alec Radford</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ilya Sutskever</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dario Amodei</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2005.14165">https://arxiv.org/abs/2005.14165</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2020</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: brown-etal:2020:language-models-are</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2005.14165">10.48550/ARXIV.2005.14165</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>17/07/2023 à 17:29:25</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Recent work has demonstrated substantial gains on many NLP 
tasks and benchmarks by pre-training on a large corpus of text followed 
by fine-tuning on a specific task. While typically task-agnostic in 
architecture, this method still requires task-specific fine-tuning 
datasets of thousands or tens of thousands of examples. By contrast, 
humans can generally perform a new language task from only a few 
examples or from simple instructions - something which current NLP 
systems still largely struggle to do. Here we show that scaling up 
language models greatly improves task-agnostic, few-shot performance, 
sometimes even reaching competitiveness with prior state-of-the-art 
fine-tuning approaches. Specifically, we train GPT-3, an autoregressive 
language model with 175 billion parameters, 10x more than any previous 
non-sparse language model, and test its performance in the few-shot 
setting. For all tasks, GPT-3 is applied without any gradient updates or
 fine-tuning, with tasks and few-shot demonstrations specified purely 
via text interaction with the model. GPT-3 achieves strong performance 
on many NLP datasets, including translation, question-answering, and 
cloze tasks, as well as several tasks that require on-the-fly reasoning 
or domain adaptation, such as unscrambling words, using a novel word in a
 sentence, or performing 3-digit arithmetic. At the same time, we also 
identify some datasets where GPT-3's few-shot learning still struggles, 
as well as some datasets where GPT-3 faces methodological issues related
 to training on large web corpora. Finally, we find that GPT-3 can 
generate samples of news articles which human evaluators have difficulty
 distinguishing from articles written by humans. We discuss broader 
societal impacts of this finding and of GPT-3 in general.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>17/07/2023 à 17:29:25</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:31:35</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Computation and Language</li>
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_X8K8BLEW">Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf					</li>
				</ul>
			</li>


			<li id="item_AEVRWV3L" class="item journalArticle">
			<h2>Language Models are Unsupervised Multitask Learners</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alec Radford</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jeffrey Wu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Rewon Child</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>David Luan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dario Amodei</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ilya Sutskever</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>9</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>OpenAI blog</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: radford-etal:2019:language-models-are</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Natural language processing tasks, such as question answering,
 machine translation, reading comprehension, and summarization, are 
typically approached with supervised learning on taskspeciﬁc datasets. 
We demonstrate that language models begin to learn these tasks without 
any explicit supervision when trained on a new dataset of millions of 
webpages called WebText. When conditioned on a document plus questions, 
the answers generated by the language model reach 55 F1 on the CoQA 
dataset - matching or exceeding the performance of 3 out of 4 baseline 
systems without using the 127,000+ training examples. The capacity of 
the language model is essential to the success of zero-shot task 
transfer and increasing it improves performance in a log-linear fashion 
across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer 
that achieves state of the art results on 7 out of 8 tested language 
modeling datasets in a zero-shot setting but still underﬁts WebText. 
Samples from the model reﬂect these improvements and contain coherent 
paragraphs of text. These ﬁndings suggest a promising path towards 
building language processing systems which learn to perform tasks from 
their naturally occurring demonstrations.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>17/07/2023 à 17:32:09</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>17/07/2023 à 17:33:38</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_ARNHQL4P">Radford et al. - Language Models are Unsupervised Multitask Learner.pdf					</li>
				</ul>
			</li>


			<li id="item_LPG73P37" class="item conferencePaper">
			<h2>LanguageARC: Developing language resources through citizen linguistics</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>James Fiumara</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Christopher Cieri</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jonathan Wright</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mark Liberman</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://aclanthology.org/2020.cllrd-1.1">https://aclanthology.org/2020.cllrd-1.1</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Marseille, France</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>European Language Resources Association</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1–6</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>979-10-95546-59-7</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2020-05</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: fiumara-etal:2020:languagearc-developing-language</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>English</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This paper introduces the citizen science platform, 
LanguageARC, developed within the NIEUW (Novel Incentives and Workflows)
 project supported by the National Science Foundation under Grant No. 
1730377. LanguageARC is a community-oriented online platform bringing 
together researchers and “citizen linguists” with the shared goal of 
contributing to linguistic research and language technology development.
 Like other Citizen Science platforms and projects, LanguageARC 
harnesses the power and efforts of volunteers who are motivated by the 
incentives of contributing to science, learning and discovery, and 
belonging to a community dedicated to social improvement. Citizen 
linguists contribute language data and judgments by participating in 
research tasks such as classifying regional accents from audio clips, 
recording audio of picture descriptions and answering personality 
questionnaires to create baseline data for NLP research into autism and 
neurodegenerative conditions. Researchers can create projects on 
Language ARC without any coding or HTML required using our Project 
Builder Toolkit.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the LREC 2020 workshop on “Citizen linguistics in language resource development”</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 15:14:19</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:04:05</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_CKSNA5YF">Fiumara et al. - 2020 - LanguageARC Developing language resources through.pdf					</li>
				</ul>
			</li>


			<li id="item_E6DWT8NW" class="item journalArticle">
			<h2>Latent Dirichlet Allocation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>David M Blei</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Andrew Y. Ng</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michael I. Jordan</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>993-1022</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of machine Learning research</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2003</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: blei-etal:2003:latent-dirichlet-allocation</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We describe latent Dirichlet allocation (LDA), a generative 
probabilistic model for collections of discrete data such as text 
corpora. LDA is a three-level hierarchical Bayesian model, in which each
 item of a collection is modeled as a ﬁnite mixture over an underlying 
set of topics. Each topic is, in turn, modeled as an inﬁnite mixture 
over an underlying set of topic probabilities. In the context of text 
modeling, the topic probabilities provide an explicit representation of a
 document. We present efﬁcient approximate inference techniques based on
 variational methods and an EM algorithm for empirical Bayes parameter 
estimation. We report results in document modeling, text classiﬁcation, 
and collaborative ﬁltering, comparing to a mixture of unigrams model and
 the probabilistic LSI model.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>17/07/2023 à 15:42:19</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>17/07/2023 à 15:45:52</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_WW295LFP">Blei - 2003 - Latent Dirichlet Allocation.pdf					</li>
				</ul>
			</li>


			<li id="item_WZGLJJD9" class="item journalArticle">
			<h2>Learning from Few Examples: A Summary of Approaches to Few-Shot Learning</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Archit Parnami</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Minwoo Lee</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2203.04291">https://arxiv.org/abs/2203.04291</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: parnami-lee:2022:learning-few-examples</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2203.04291">10.48550/ARXIV.2203.04291</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/10/2023 à 15:28:00</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Few-Shot Learning refers to the problem of learning the 
underlying pattern in the data just from a few training samples. 
Requiring a large number of data samples, many deep learning solutions 
suffer from data hunger and extensively high computation time and 
resources. Furthermore, data is often not available due to not only the 
nature of the problem or privacy concerns but also the cost of data 
preparation. Data collection, preprocessing, and labeling are strenuous 
human tasks. Therefore, few-shot learning that could drastically reduce 
the turnaround time of building machine learning applications emerges as
 a low-cost solution. This survey paper comprises a representative list 
of recently proposed few-shot learning algorithms. Given the learning 
dynamics and characteristics, the approaches to few-shot learning 
problems are discussed in the perspectives of meta-learning, transfer 
learning, and hybrid approaches (i.e., different variations of the 
few-shot learning problem).</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Learning from Few Examples</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/10/2023 à 15:28:00</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>09/10/2023 à 10:00:13</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Machine Learning (cs.LG)</li>
					<li>Computer Vision and Pattern Recognition (cs.CV)</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_LE2RR2SZ">Parnami et Lee - 2022 - Learning from Few Examples A Summary of Approache.pdf					</li>
				</ul>
			</li>


			<li id="item_HFSXAUPA" class="item webpage">
			<h2>Les 10 métiers data les plus recherchés en 2023</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Page Web</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>DataBird</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.data-bird.co/blog/metiers-data">https://www.data-bird.co/blog/metiers-data</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-07</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: databird:2023:10-metiers-data</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>26/09/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>En 2023, l’analyse de données est un enjeu crucial pour les 
entreprises. Comment valoriser les nombreuses données qu’elles génèrent 
et qu’elles récoltent ? C’est là qu’interviennent les professionnels de 
la data. Cet article te décrit les 10 métiers les plus recherchés dans 
l’univers de la Data science.</td>
					</tr>
					<tr>
					<th>Titre du site Web</th>
						<td>DataBird</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/09/2023 à 13:02:07</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:59:11</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_RQL98RR5" class="item book">
			<h2>Les Cousins Dalton</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Morris</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>René Goscinny</td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Lucky Luke</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Dupuis</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-2-8001-1452-1</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1958</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: morris-goscinny:1958:cousins-dalton</td>
					</tr>
					<tr>
					<th>N° ds la coll.</th>
						<td>12</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fre</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/09/2023 à 17:36:41</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>19/10/2023 à 12:06:44</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_ELYQVNZC" class="item webpage">
			<h2>Les métiers de la data : mieux comprendre leurs différences</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Page Web</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Team Datascientest</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://datascientest.com/les-metiers-de-la-data">https://datascientest.com/les-metiers-de-la-data</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-09</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: team-datascientest:2022:metiers-data-mieux</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>26/09/2023 à 02:00:00</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Les métiers relatifs aux données sont souvent sources 
d’incompréhension et sont également parfois soumis à une hiérarchie, à 
tort, puisqu’il s’agit de métiers bien différents. Les non-initiés, 
également appelés Moldus dans le milieu, peuvent y voir certaines zones 
d’ombre. En effet, l’erreur souvent commise est de parler de “Data 
Scientist” sans distinction pour englober les métiers de la data, alors 
qu’il s’agit bel et bien de rôles différents.
Le but de cet article est de lever le voile sur les principaux métiers 
de la data, et de mieux comprendre leurs différences et spécificités. De
 plus, vous trouverez à la fin de cet article un diagramme illustrant 
les différents métiers..</td>
					</tr>
					<tr>
					<th>Titre du site Web</th>
						<td>Datascientest.com</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/09/2023 à 12:59:19</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:00:22</td>
					</tr>
				</tbody></table>
			</li>


			<li id="item_9U5PGI6B" class="item conferencePaper">
			<h2>LightTag: Text annotation platform</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tal Perry</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://aclanthology.org/2021.emnlp-demo.3">https://aclanthology.org/2021.emnlp-demo.3</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Online and Punta Cana, Dominican Republic</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>20–27</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-11</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: perry:2021:lighttag-text-annotation</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Label data for NLP faster with your team and our AI.
LightTag manages your workforce so you can focus on the important things.
Best of all, It. Just. Works.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the 2021 conference on empirical methods in natural language processing: System demonstrations</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>12/10/2023 à 19:23:59</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>12/10/2023 à 19:24:28</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_SISM9D6L" class="item book">
			<h2>Likelihood</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Anthony William Fairbank Edwards</td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>Expanded ed</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Baltimore</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Johns Hopkins Univ. Press</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-0-8018-4445-4 978-0-8018-4443-0</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1992</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: edwards:1992:likelihood</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>K10plus ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>275</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 16:14:31</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:12</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Metric</li>
					<li>Log vraissemblance</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_MR3G4IWY">
<p class="plaintext">Includes bibliographical references (p. 259 - 264) and index</p>
					</li>
				</ul>
			</li>


			<li id="item_LM6EG8UT" class="item journalArticle">
			<h2>Llama 2: Open Foundation and Fine-Tuned Chat Models</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hugo Touvron</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Louis Martin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kevin Stone</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Peter Albert</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Amjad Almahairi</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yasmine Babaei</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nikolay Bashlykov</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Soumya Batra</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Prajjwal Bhargava</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Shruti Bhosale</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dan Bikel</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Lukas Blecher</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Cristian Canton Ferrer</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Moya Chen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Guillem Cucurull</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>David Esiobu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jude Fernandes</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jeremy Fu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Wenyin Fu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Brian Fuller</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Cynthia Gao</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vedanuj Goswami</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Naman Goyal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Anthony Hartshorn</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Saghar Hosseini</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Rui Hou</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hakan Inan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Marcin Kardas</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Viktor Kerkez</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Madian Khabsa</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Isabel Kloumann</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Artem Korenev</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Punit Singh Koura</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Marie-Anne Lachaux</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Thibaut Lavril</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jenya Lee</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Diana Liskovich</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yinghai Lu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yuning Mao</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Xavier Martinet</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Todor Mihaylov</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Pushkar Mishra</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Igor Molybog</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yixin Nie</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Andrew Poulton</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jeremy Reizenstein</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Rashi Rungta</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kalyan Saladi</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alan Schelten</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ruan Silva</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Eric Michael Smith</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ranjan Subramanian</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Xiaoqing Ellen Tan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Binh Tang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ross Taylor</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Adina Williams</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jian Xiang Kuan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Puxin Xu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zheng Yan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Iliyan Zarov</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yuchen Zhang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Angela Fan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Melanie Kambadur</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sharan Narang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Aurelien Rodriguez</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Robert Stojnic</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sergey Edunov</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Thomas Scialom</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2307.09288">https://arxiv.org/abs/2307.09288</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: touvron-etal:2023:llama-open-foundation</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2307.09288">10.48550/ARXIV.2307.09288</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>20/07/2023 à 14:02:44</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>In this work, we develop and release Llama 2, a collection of 
pretrained and fine-tuned large language models (LLMs) ranging in scale 
from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called 
Llama 2-Chat, are optimized for dialogue use cases. Our models 
outperform open-source chat models on most benchmarks we tested, and 
based on our human evaluations for helpfulness and safety, may be a 
suitable substitute for closed-source models. We provide a detailed 
description of our approach to fine-tuning and safety improvements of 
Llama 2-Chat in order to enable the community to build on our work and 
contribute to the responsible development of LLMs.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Llama 2</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>20/07/2023 à 14:02:44</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:33:27</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Artificial Intelligence</li>
					<li>Computation and Language</li>
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_VFE8SRBF">Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf					</li>
				</ul>
			</li>


			<li id="item_9SXU5KRR" class="item journalArticle">
			<h2>Logistic regression in data analysis: an overview</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Maher Maalouf</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.inderscience.com/link.php?id=41335">http://www.inderscience.com/link.php?id=41335</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>281</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Journal of Data Analysis Techniques and Strategies</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1755-8050, 1755-8069</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2011</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: maalouf:2011:logistic-regression-data</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>IJDATS</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1504/IJDATS.2011.041335">10.1504/IJDATS.2011.041335</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>15/09/2023 à 16:34:29</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Logistic regression (LR) continues to be one of the most 
widely used methods in data mining in general and binary data 
classification in particular. This paper is focused on providing an 
overview of the most important aspects of LR when used in data analysis,
 specifically from an algorithmic and machine learning perspective and 
how LR can be applied to imbalanced and rare events data.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Logistic regression in data analysis</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>15/09/2023 à 16:34:29</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>15/09/2023 à 16:44:20</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_X6V7BHIP" class="item computerProgram">
			<h2>Louis</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Air France</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://corporate.airfrance.com/fr/communiques-presse/air-france-presente-louis-son-chatbot-intelligent">https://corporate.airfrance.com/fr/communiques-presse/air-france-presente-louis-son-chatbot-intelligent</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: air-france:2017:louis</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Air France - KLM</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2023 à 11:20:03</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>23/10/2023 à 11:23:00</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_RGD5DJWB" class="item book">
			<h2>Machine learning</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zhi-Hua Zhou</td>
					</tr>
					<tr>
						<th class="translator">Traducteur</th>
						<td>Shaowu Liu</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://books.google.fr/books?id=Zd5hywEACAAJ">https://books.google.fr/books?id=Zd5hywEACAAJ</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Singapore</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>9789811519673 9789811519666</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: zhou:2021:machine-learning</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>K10plus ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Machine Learning, a vital and core area of artificial 
intelligence (AI), is propelling the AI field ever further and making it
 one of the most compelling areas of computer science research. This 
textbook offers a comprehensive and unbiased introduction to almost all 
aspects of machine learning, from the fundamentals to advanced topics. 
It consists of 16 chapters divided into three parts: Part 1 (Chapters 
1-3) introduces the fundamentals of machine learning, including 
terminology, basic principles, evaluation, and linear models; Part 2 
(Chapters 4-10) presents classic and commonly used machine learning 
methods, such as decision trees, neural networks, support vector 
machines, Bayesian classifiers, ensemble methods, clustering, dimension 
reduction and metric learning; Part 3 (Chapters 11-16) introduces some 
advanced topics, covering feature selection and sparse learning, 
computational learning theory, semi-supervised learning, probabilistic 
graphical models, rule learning, and reinforcement learning. Each 
chapter includes exercises and further reading, so that readers can 
explore areas of interest.
The book can be used as an undergraduate or postgraduate textbook for 
computer science, computer engineering, electrical engineering, data 
science, and related majors. It is also a useful reference resource for 
researchers and practitioners of machine learning.</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>458</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/09/2023 à 11:24:32</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>22/09/2023 à 11:32:24</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_B9HJFNET" class="item journalArticle">
			<h2>Machine learning: a review of classification and combining techniques</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>S. B. Kotsiantis</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>I. D. Zaharakis</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>P. E. Pintelas</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/s10462-007-9052-3">http://link.springer.com/10.1007/s10462-007-9052-3</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>26</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>159-190</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Artificial Intelligence Review</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0269-2821, 1573-7462</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2006-11</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kotsiantis-etal:2006:machine-learning-review</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Artif Intell Rev</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/s10462-007-9052-3">10.1007/s10462-007-9052-3</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>18/09/2023 à 14:16:56</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Supervised classification is one of the tasks most frequently 
carried out by so-called Intelligent Systems. Thus, a large number of 
techniques have been developed based on Artificial Intelligence 
(Logic-based techniques, Perceptron-based techniques) and Statistics 
(Bayesian Networks, Instance-based techniques). The goal of supervised 
learning is to build a concise model of the distribution of class labels
 in terms of predictor features. The resulting classifier is then used 
to assign class labels to the testing instances where the values of the 
predictor features are known, but the value of the class label is 
unknown. This paper describes various classification algorithms and the 
recent attempt for improving classification accuracy—ensembles of 
classifiers.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Machine learning</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 14:16:56</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:52:52</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_3EQB3EGF" class="item presentation">
			<h2>Manual Annotation:   What is it ? How to do it (properly)?</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Présentation</td>
					</tr>
					<tr>
						<th class="presenter">Présentateur</th>
						<td>Karën Fort</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://members.loria.fr/KFort/files/fichiers_cours/AnnotationQuality.pdf">https://members.loria.fr/KFort/files/fichiers_cours/AnnotationQuality.pdf</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-03-31</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: fort:2022:manual-annotation-what</td>
					</tr>
					<tr>
					<th>Type</th>
						<td>École thématique d’été</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>21/09/2023 à 18:11:34</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>24/10/2023 à 13:56:49</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*ALIRE/AIMPLÉMENTER</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_ET2VDZLQ">Fort - Manual Annotation   What is it  How to do it (pr.pdf					</li>
				</ul>
			</li>


			<li id="item_H558SDQX" class="item journalArticle">
			<h2>Manuel d’annotation en actes de dialogue pour le corpus Datcha</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nicholas Asher</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alexis Nasr</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Robin Perrotin</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-05-02</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: asher-etal:2017:manuel-annotation-actes</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 14:38:47</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:09:24</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_PSXD8FDM">Asher et al. - Manuel d’annotation en actes de dialogue pour le c.pdf					</li>
				</ul>
			</li>


			<li id="item_SH7TUSMX" class="item journalArticle">
			<h2>Mean squared error of prediction in models for studying ecological and agronomic systems</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Daniel Wallach</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Bruno Goffinet</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>561–573</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Biometrics. Journal of the International Biometric Society</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1987</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: wallach-goffinet:1987:mean-squared-error</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Biometrics</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/09/2023 à 17:19:57</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>22/09/2023 à 17:20:58</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Mean squared error</li>
				</ul>
			</li>


			<li id="item_LKGKAFXC" class="item journalArticle">
			<h2>Measuring the Reliability of Manual Annotations of Speech Corpora</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ulrike Gut</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Petra Saskia Bayerl</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://api.semanticscholar.org/CorpusID:27970161">https://api.semanticscholar.org/CorpusID:27970161</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2004-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: gut-bayerl:2004:measuring-reliability-manual</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>The quality of manual annotations of speech corpora depends on
 the ability of human annotators to cope with phonetic and prosodic 
coding schemas such as SAMPA and ToBI. It has been proposed widely that 
an acceptable amount of reliability among and within individual 
annotators is impossible to achieve. In this paper, we present an 
extensive evaluation of annotator reliability in a multilevel 
phonetically annotated speech corpus, using two methods for measuring 
annotator reliability. The results show that manual annotations can be 
very reliable, but that reliability is correlated with the complexity of
 the coding schema.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 17:52:46</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:51:31</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_FDKDZD7X">Gut et Bayerl - Measuring the Reliability of Manual Annotations of.pdf					</li>
				</ul>
			</li>


			<li id="item_DJ233VSX" class="item journalArticle">
			<h2>Microsoft COCO: Common Objects in Context</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tsung-Yi Lin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michael Maire</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Serge Belongie</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Lubomir Bourdev</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ross Girshick</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>James Hays</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Pietro Perona</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Deva Ramanan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>C. Lawrence Zitnick</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Piotr Dollár</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://cocodataset.org/">https://cocodataset.org</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2014</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: lin-etal:2014:microsoft-coco-common</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.1405.0312">10.48550/ARXIV.1405.0312</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/10/2023 à 14:53:28</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We present a new dataset with the goal of advancing the 
state-of-the-art in object recognition by placing the question of object
 recognition in the context of the broader question of scene 
understanding. This is achieved by gathering images of complex everyday 
scenes containing common objects in their natural context. Objects are 
labeled using per-instance segmentations to aid in precise object 
localization. Our dataset contains photos of 91 objects types that would
 be easily recognizable by a 4 year old. With a total of 2.5 million 
labeled instances in 328k images, the creation of our dataset drew upon 
extensive crowd worker involvement via novel user interfaces for 
category detection, instance spotting and instance segmentation. We 
present a detailed statistical analysis of the dataset in comparison to 
PASCAL, ImageNet, and SUN. Finally, we provide baseline performance 
analysis for bounding box and segmentation detection results using a 
Deformable Parts Model.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Microsoft COCO</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/10/2023 à 14:53:28</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:04:38</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Computer Vision and Pattern Recognition (cs.CV)</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_8Y5FLDIK">Lin et al. - 2014 - Microsoft COCO Common Objects in Context.pdf					</li>
				</ul>
			</li>


			<li id="item_RZI7VKTW" class="item computerProgram">
			<h2>Microsoft Excel</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Microsoft Corporation</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://office.microsoft.com/excel">https://office.microsoft.com/excel</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: microsoft-corporation:2018:microsoft-excel</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Microsoft Corporation</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>27/09/2023 à 09:22:02</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>27/09/2023 à 09:29:15</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_R5NI67R5" class="item dataset">
			<h2>MLSUM: The Multilingual Summarization Corpus</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Dataset</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Thomas Scialom</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Paul-Alexis Dray</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sylvain Lamprier</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Benjamin Piwowarski</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jacopo Staiano</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/2004.14900">http://arxiv.org/abs/2004.14900</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2020-04-30</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: scialom-etal:2020:mlsum-multilingual-summarization</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>07/06/2023 à 13:10:49</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We present MLSUM, the first large-scale MultiLingual 
SUMmarization dataset. Obtained from online newspapers, it contains 
1.5M+ article/summary pairs in five different languages -- namely, 
French, German, Spanish, Russian, Turkish. Together with English 
newspapers from the popular CNN/Daily mail dataset, the collected data 
form a large scale multilingual dataset which can enable new research 
directions for the text summarization community. We report cross-lingual
 comparative analyses based on state-of-the-art systems. These highlight
 existing biases which motivate the use of a multi-lingual dataset.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>MLSUM</td>
					</tr>
					<tr>
					<th>Dépôt</th>
						<td>arXiv</td>
					</tr>
					<tr>
					<th>Identifier</th>
						<td>arXiv:2004.14900</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 13:10:49</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:04:10</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Computation and Language</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_SJDKVTSQ">Scialom et al. - 2020 - MLSUM The Multilingual Summarization Corpus.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_WYT8SAK5">Subset of 'MLSUM: The Multilingual Summarization Corpus' for constraints annotation experiment</li>
				</ul>
			</li>


			<li id="item_AD8KK4IC" class="item conferencePaper">
			<h2>Modeling the complexity of manual annotation tasks: a grid of analysis</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Karen Fort</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Adeline Nazarenko</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sophie Rosset</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.science/hal-00769631">https://hal.science/hal-00769631</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Mumbaï, India</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>The COLING 2012 Organizing Committee</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>895–910</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2012-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: fort-etal:2012:modeling-complexity-manual</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Manual corpus annotation is getting widely used in Natural 
Language Processing (NLP). While being recognized as a difﬁcult task, no
 in-depth analysis of its complexity has been performed yet. We provide 
in this article a grid of analysis of the different complexity 
dimensions of an annotation task, which helps estimating beforehand the 
difﬁculties and cost of annotation campaigns. We observe the 
applicability of this grid on existing annotation campaigns and detail 
its application on a real-world example.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of COLING 2012</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 14:01:32</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:06:06</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Annotation campaign cost estimate</li>
					<li>Annotation campaign management</li>
					<li>Manual corpus annotation</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_NCX95JS3">Fort et al. - 2012 - Modeling the complexity of manual annotation tasks.pdf					</li>
				</ul>
			</li>


			<li id="item_VM3Q5NRW" class="item journalArticle">
			<h2>Multiple Parameter Based Clustering (MPC): Prospective Analysis 
for Effective Clustering in Wireless Sensor Network (WSN) Using K-Means 
Algorithm</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Md. Asif Khan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Israfil Tamim</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Emdad Ahmed</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>M. Abdul Awal</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.scirp.org/journal/doi.aspx?DOI=10.4236/wsn.2012.41003">http://www.scirp.org/journal/doi.aspx?DOI=10.4236/wsn.2012.41003</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>04</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>01</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>18-24</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Wireless Sensor Network</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1945-3078, 1945-3086</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2012</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: khan-etal:2012:multiple-parameter-based</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>WSN</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.4236/wsn.2012.41003">10.4236/wsn.2012.41003</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>16/01/2023 à 11:06:57</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Multiple Parameter Based Clustering (MPC)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>16/01/2023 à 11:06:57</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:21</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>K-Means</li>
					<li>Constrained clustering</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_LQ5DZJVB">Khan et al. - 2012 - Multiple Parameter Based Clustering (MPC) Prospec.pdf					</li>
				</ul>
			</li>


			<li id="item_XSI5W2GL" class="item book">
			<h2>Natural language annotation for machine learning</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>James Pustejovsky</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Amber Stubbs</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://api.semanticscholar.org/CorpusID:60457717">https://api.semanticscholar.org/CorpusID:60457717</a></td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>O'Reilly Media, Inc.</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4493-0666-3</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2012-10-10</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: pustejovsky-stubbs:2012:natural-language-annotation</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This book is intended as a resource for people who are 
interested in using computers to help process natural language. A 
natural language refers to any language spoken by humans, either 
currently (e.g., English, Chinese, Spanish) or in the past (e.g., Latin,
 ancient Greek, Sanskrit). Annotation refers to the process of adding 
metadata informa tion to the text in order to augment a computer’s 
capability to perform Natural Language Processing (NLP). In particular, 
we examine how information can be added to natural language text through
 annotation in order to increase the performance of machine learning 
algorithms—computer programs designed to extrapolate rules from the 
infor mation provided over texts in order to apply those rules to 
unannotated texts later on.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/08/2023 à 11:36:29</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>25/10/2023 à 13:19:17</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_F3DGR2HW">
<div><div data-schema-version="8"><p>MATTER: Modelize, Annotate, Train, Test, Evaluate, Revise</p>
<p>MAMA: Modelize, Annotate, Evaluate, Revise</p>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_YTFHRWN9">Pustejovsky et Stubbs - 2012 - Natural language annotation for machine learning.pdf					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_C6SAHHTC">Unifying Linguistic Annotations: A TimeML Case Study</li>
				</ul>
			</li>


			<li id="item_WN77W8XV" class="item conferencePaper">
			<h2>Neural Approaches to Conversational AI</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jianfeng Gao</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michel Galley</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Lihong Li</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://aclanthology.org/P18-5002">https://aclanthology.org/P18-5002</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Melbourne, Australia</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>2–7</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018-07</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: gao-etal:2018:neural-approaches-conversational</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.18653/v1/P18-5002">10.18653/v1/P18-5002</a></td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This tutorial surveys neural approaches to conversational AI 
that were developed in the last few years. We group conversational 
systems into three categories: (1) question answering agents, (2) 
taskoriented dialogue agents, and (3) social bots. For each category, we
 present a review of state-of-the-art neural approaches, draw the 
connection between neural approaches and traditional symbolic 
approaches, and discuss the progress we have made and challenges we are 
facing, using speciﬁc systems and models as case studies.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the 56th annual meeting of the association for computational linguistics: Tutorial abstracts</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>24/10/2023 à 02:15:23</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>24/10/2023 à 02:16:51</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_XX6NL54Z">Gao et al. - Neural Approaches to Conversational AI.pdf					</li>
				</ul>
			</li>


			<li id="item_7FILC5N8" class="item journalArticle">
			<h2>Neural Information Retrieval: A Literature Review</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ye Zhang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Md Mustafizur Rahman</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alex Braylan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Brandon Dang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Heng-Lu Chang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Henna Kim</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Quinten McNamara</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Aaron Angert</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Edward Banner</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vivek Khetan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tyler McDonnell</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>An Thanh Nguyen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dan Xu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Byron C. Wallace</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Matthew Lease</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/1611.06792">https://arxiv.org/abs/1611.06792</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: zhang-etal:2016:neural-information-retrieval</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.1611.06792">10.48550/ARXIV.1611.06792</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>24/10/2023 à 02:07:17</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>A recent "third wave" of Neural Network (NN) approaches now 
delivers state-of-the-art performance in many machine learning tasks, 
spanning speech recognition, computer vision, and natural language 
processing. Because these modern NNs often comprise multiple 
interconnected layers, this new NN research is often referred to as deep
 learning. Stemming from this tide of NN work, a number of researchers 
have recently begun to investigate NN approaches to Information 
Retrieval (IR). While deep NNs have yet to achieve the same level of 
success in IR as seen in other areas, the recent surge of interest and 
work in NNs for IR suggest that this state of affairs may be quickly 
changing. In this work, we survey the current landscape of Neural IR 
research, paying special attention to the use of learned representations
 of queries and documents (i.e., neural embeddings). We highlight the 
successes of neural IR thus far, catalog obstacles to its wider 
adoption, and suggest potentially promising directions for future 
research.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Neural Information Retrieval</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>24/10/2023 à 02:07:17</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>24/10/2023 à 02:17:36</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Information Retrieval (cs.IR)</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_8JPFU7SD">Zhang et al. - 2016 - Neural Information Retrieval A Literature Review.pdf					</li>
				</ul>
			</li>


			<li id="item_R7A4DYGV" class="item bookSection">
			<h2>On Spectral Clustering: Analysis and an algorithm</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Andrew Y. Ng</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michael I. Jordan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yair Weiss</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>T. G. Dietterich</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>S. Becker</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Z. Ghahramani</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://papers.nips.cc/paper/2092-on-spectral-clustering-analysis-and-an-algorithm.pdf">http://papers.nips.cc/paper/2092-on-spectral-clustering-analysis-and-an-algorithm.pdf</a></td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>MIT Press</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>849–856</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2002</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: ng-etal:2002:spectral-clustering-analysis</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>22/10/2020 à 19:13:13</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Neural Information Processing Systems</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Despite many empirical successes of spectral clustering 
methodsalgorithms that cluster points using eigenvectors of matrices 
derived from the data- there are several unresolved issues. First,
there are a wide variety of algorithms that use the eigenvectors
in slightly different ways. Second, many of these algorithms have
no proof that they will actually compute a reasonable clustering.
In this paper, we present a simple spectral clustering algorithm
that can be implemented using a few lines of Matlab. Using tools
from matrix perturbation theory, we analyze the algorithm, and
give conditions under which it can be expected to do well. We
also show surprisingly good experimental results on a number of
challenging clustering problems.</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Advances in Neural Information Processing Systems 14</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>On Spectral Clustering</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/10/2020 à 19:13:13</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:44</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>Spectral clustering</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_DTJJCJL4">Ng et al. - 2002 - On Spectral Clustering Analysis and an algorithm.pdf					</li>
				</ul>
			</li>


			<li id="item_WPG5PGAC" class="item report">
			<h2>On the Use of Information Retrieval Measures for Speech Recognition Evaluation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Rapport</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Iain McCowan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Daren Moore</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>John Dines</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Daniel Gatica-Perez</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mike Flynn</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Pierre Wellner</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hervé Bourlard</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Martigny, Switzerland</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2005-03</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: mccowan-etal:2005:use-information-retrieval</td>
					</tr>
					<tr>
					<th>Institution</th>
						<td>IDIAP Research Institute</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This paper discusses the evaluation of automatic speech 
recognition (ASR) systems developed for practical applications, 
suggesting a set of criteria for application-oriented performance 
measures. The commonly used word error rate (WER), which poses ASR 
evaluation as a string editing process, is shown to have a number of 
limitations with respect to these criteria, motivating alternative or 
additional measures. This paper suggests that posing speech recognition 
evaluation as an information retrieval problem, where each word is one 
unit of information, outliers a flexible framework for 
application-oriented performance analysis based on the concepts of 
recall and precision.</td>
					</tr>
					<tr>
					<th>N° du rapport</th>
						<td>IDIAP-RR 04-73</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/09/2023 à 17:03:35</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:51:51</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>WER</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_4GUNCZIT">McCowan et al. - 2005 - On the Use of Information Retrieval Measures for S.pdf					</li>
				</ul>
			</li>


			<li id="item_4AT34D7B" class="item conferencePaper">
			<h2>Optical character recognition: An overview and an insight</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Deepa Berchmans</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>S. S. Kumar</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/6993174/">http://ieeexplore.ieee.org/document/6993174/</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Kanyakumari</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1361-1365</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4799-4191-9 978-1-4799-4190-2</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2014-07</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: berchmans-kumar:2014:optical-character-recognition</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICCICCT.2014.6993174">10.1109/ICCICCT.2014.6993174</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>15/09/2023 à 16:43:40</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>2014 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Many researches are going on in the field of optical character
 recognition (OCR) for the last few decades and a lot of articles have 
been published. Also a large number of OCR is available commercially. In
 this literature a review of the OCR history and the various techniques 
used for OCR development in the chronological order is being done.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>2014 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT)</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Optical character recognition</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>15/09/2023 à 16:43:40</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:06:50</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_PFBA3TRT" class="item bookSection">
			<h2>Ordinary Least-Squares (OLS) Model</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Alex C. Michalos</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Bozena Zdaniuk</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-94-007-0753-5_2008">http://link.springer.com/10.1007/978-94-007-0753-5_2008</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Dordrecht</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer Netherlands</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>4515-4517</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-94-007-0752-8 978-94-007-0753-5</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2014</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: zdaniuk:2014:ordinary-leastsquares-ols</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>15/09/2023 à 15:19:07</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Ordinary least-squares (OLS) models assume that the analysis 
is fitting a model of a relationship between one or more explanatory 
variables and a continuous or at least interval outcome variable that 
minimizes the sum of square errors, where an error is the difference 
between the actual and the predicted value of the outcome variable. The 
most common analytical method that utilizes OLS models is linear 
regression (with a single or multiple predictor variables).</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Encyclopedia of Quality of Life and Well-Being Research</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>15/09/2023 à 15:19:07</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>15/09/2023 à 15:20:31</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_RSWSFEZN" class="item journalArticle">
			<h2>Overview of Annotation Creation: Processes &amp; Tools</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mark A. Finlayson</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tomaž Erjavec</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1602.05753">http://arxiv.org/abs/1602.05753</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-02-18</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: finlayson-erjavec:2016:overview-annotation-creation</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>14/06/2021 à 10:04:56</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Creating linguistic annotations requires more than just a 
reliable annotation scheme. Annotation can be a complex endeavour 
potentially involving many people, stages, and tools. This chapter 
outlines the process of creating end-to-end linguistic annotations, 
identifying specific tasks that researchers often perform. Because tool 
support is so central to achieving high quality, reusable annotations 
with low cost, the focus is on identifying capabilities that are 
necessary or useful for annotation tools, as well as common problems 
these tools present that reduce their utility. Although examples of 
specific tools are provided in many cases, this chapter concentrates 
more on abstract capabilities and problems because new tools appear 
continuously, while old tools disappear into disuse or disrepair. The 
two core capabilities tools must have are support for the chosen 
annotation scheme and the ability to work on the language under study. 
Additional capabilities are organized into three categories: those that 
are widely provided; those that often useful but found in only a few 
tools; and those that have as yet little or no available tool support.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Overview of Annotation Creation</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>14/06/2021 à 10:04:56</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:30:30</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Computation and Language</li>
					<li>*CITATION</li>
					<li>Human-Computer Interaction</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_YGEMRHIK">Finlayson and Erjavec - 2016 - Overview of Annotation Creation Processes &amp; Tools.pdf					</li>
				</ul>
			</li>


			<li id="item_IGLMK8K2" class="item bookSection">
			<h2>Pearson's Correlation Coefficient</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Wilhelm Kirch</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://link.springer.com/10.1007/978-1-4020-5614-7_2569">https://link.springer.com/10.1007/978-1-4020-5614-7_2569</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Dordrecht</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer Netherlands</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1090-1091</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4020-5613-0 978-1-4020-5614-7</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2008</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kirch:2008:pearson-correlation-coefficient</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 16:26:21</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Encyclopedia of Public Health</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 16:26:21</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>19/10/2023 à 12:05:08</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Metric</li>
					<li>Correlation</li>
				</ul>
			</li>


			<li id="item_PCXQDRR7" class="item journalArticle">
			<h2>PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jingqing Zhang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yao Zhao</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mohammad Saleh</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Peter J. Liu</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/1912.08777">https://arxiv.org/abs/1912.08777</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: zhang-etal:2019:pegasus-pretraining-extracted</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.1912.08777">10.48550/ARXIV.1912.08777</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>17/07/2023 à 17:21:25</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Recent work pre-training Transformers with self-supervised 
objectives on large text corpora has shown great success when fine-tuned
 on downstream NLP tasks including text summarization. However, 
pre-training objectives tailored for abstractive text summarization have
 not been explored. Furthermore there is a lack of systematic evaluation
 across diverse domains. In this work, we propose pre-training large 
Transformer-based encoder-decoder models on massive text corpora with a 
new self-supervised objective. In PEGASUS, important sentences are 
removed/masked from an input document and are generated together as one 
output sequence from the remaining sentences, similar to an extractive 
summary. We evaluated our best PEGASUS model on 12 downstream 
summarization tasks spanning news, science, stories, instructions, 
emails, patents, and legislative bills. Experiments demonstrate it 
achieves state-of-the-art performance on all 12 downstream datasets 
measured by ROUGE scores. Our model also shows surprising performance on
 low-resource summarization, surpassing previous state-of-the-art 
results on 6 datasets with only 1000 examples. Finally we validated our 
results using human evaluation and show that our model summaries achieve
 human performance on multiple datasets.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>PEGASUS</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>17/07/2023 à 17:21:25</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:33:29</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Computation and Language</li>
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_UWWCFCEF">Zhang et al. - 2019 - PEGASUS Pre-training with Extracted Gap-sentences.pdf					</li>
				</ul>
			</li>


			<li id="item_XSWXV7IZ" class="item book">
			<h2>Principles of cognitive neuroscience</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Dale Purves</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Elizabeth M. Brannon</td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>2. ed</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Sunderland, Mass</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Sinauer</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-0-87893-573-4</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2013</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: purves-brannon:2013:principles-cognitive-neuroscience</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>K10plus ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>601</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 15:54:10</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:46</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_AN729HIU">
<p class="plaintext">Cognitive neuroscience : definitions, themes, and approaches -- Cognitive neuroscience methods -- Sensory systems and perception : vision -- Sensory systems and perception : auditory, mechanical, and chemical senses -- Motor systems : organization of action -- Attention and its effects on stimulus processing -- The control of attention -- Memory : varieties and mechanisms -- Declarative memory -- Emotion -- Social cognition -- Language -- Executive control -- Decision making -- Evolution and development of brain and cognition</p>
					</li>
					<li id="item_BGFTT2MG">
<p class="plaintext">Cognitive neuroscience : definitions, themes, and approaches -- Cognitive neuroscience methods -- Sensory systems and perception : vision -- Sensory systems and perception : auditory, mechanical, and chemical senses -- Motor systems : organization of action -- Attention and its effects on stimulus processing -- The control of attention -- Memory : varieties and mechanisms -- Declarative memory -- Emotion -- Social cognition -- Language -- Executive control -- Decision making -- Evolution and development of brain and cognition</p>
					</li>
					<li id="item_JG2AVTRT">
<p class="plaintext">Cognitive neuroscience : definitions, themes, and approaches -- Cognitive neuroscience methods -- Sensory systems and perception : vision -- Sensory systems and perception : auditory, mechanical, and chemical senses -- Motor systems : organization of action -- Attention and its effects on stimulus processing -- The control of attention -- Memory : varieties and mechanisms -- Declarative memory -- Emotion -- Social cognition -- Language -- Executive control -- Decision making -- Evolution and development of brain and cognition</p>
					</li>
					<li id="item_98GC78BK">
<p class="plaintext">Literaturangaben</p>
					</li>
					<li id="item_SGP4F56B">
<p class="plaintext">Literaturangaben</p>
					</li>
					<li id="item_8DC6PW9V">
<p class="plaintext">Literaturangaben</p>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_XKKHDBM8">Purves et Brannon - 2013 - Principles of cognitive neuroscience.pdf					</li>
				</ul>
			</li>


			<li id="item_D8Y62EFR" class="item computerProgram">
			<h2>Prodigy: A modern and scriptable annotation tool for creating training data for machine learning models</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Logiciel</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Ines Montani</td>
					</tr>
					<tr>
						<th class="programmer">Programmeur</th>
						<td>Matthew Honnibal</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://prodi.gy/">https://prodi.gy/</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-12-18</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: montani-honnibal:2017:prodigy-modern-scriptable</td>
					</tr>
					<tr>
					<th>Société</th>
						<td>Explosion</td>
					</tr>
					<tr>
					<th>Langage de programmation</th>
						<td>Python</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Prodigy is a modern annotation tool for creating training and 
evaluation data for machine learning models. You can also use Prodigy to
 help you inspect and clean your data, do error analysis and develop 
rule-based systems to use in combination with your statistical models.
The Python library includes a range of pre-built workflows and 
command-line commands for various tasks, and well-documented components 
for implementing your own workflow scripts. Your scripts can specify how
 the data is loaded and saved, change which questions are asked in the 
annotation interface, and can even define custom HTML and JavaScript to 
change the behavior of the front-end. The web application is optimized 
for fast, intuitive and efficient annotation.
Prodigy’s mission is to help you do more of all those manual or 
semi-automatic processes that we all know we don’t do enough of. To most
 data scientists, the advice to spend more time looking at your data is 
sort of like the advice to floss or get more sleep: it’s easy to 
recognize that it’s sound advice, but not always easy to put into 
practice. Prodigy helps by giving you a practical, flexible tool that 
fits easily into your workflow. With concrete steps to follow instead of
 a vague goal, annotation and data inspection will change from something
 you should do, to something you will do.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>27/09/2023 à 09:00:52</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:09:48</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_YI5MTS37" class="item bill">
			<h2>Proposal for a Regulation of the European Parliament and the 
Council laying down harmonised rules on Artificial Intelligence 
(Artificial Intelligence Act) and amending certain Union Legislative 
Acts</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Projet/proposition de loi</td>
					</tr>
					<tr>
						<th class="sponsor">Auteur</th>
						<td>European Commission</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206">https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-04-21</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: european-commission:2021:proposal-regulation-european</td>
					</tr>
					<tr>
					<th>Code</th>
						<td>52021PC0206</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>N° de projet</th>
						<td>2021/0106 (COD)</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>The Artificial Intelligence Act</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 09:56:45</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:01:46</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_74X9BPTL">European Commission - 2021 - Proposal for a Regulation of the European Parliame.pdf					</li>
				</ul>
			</li>


			<li id="item_YM333KYG" class="item book">
			<h2>Python 3 Reference Manual</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Guido Van Rossum</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Fred L. Drake</td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>CreateSpace</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Scotts Valley, CA</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>1-4414-1269-7</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2009</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: van-rossum-drake:2009:python-reference-manual</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2020 à 13:01:41</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:56</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_ZKUEZ7JS" class="item book">
			<h2>Python machine learning: machine learning and deep learning with Python, scikit-learn, and TensorFlow 2</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sebastian Raschka</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vahid Mirjalili</td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Expert insight</td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>Third edition</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Birmingham Mumbai</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Packt</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-78995-575-0</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: raschka-mirjalili:2019:python-machine-learning</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>K10plus ISBN</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Python machine learning</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>741</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 10:18:05</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>22/09/2023 à 14:08:14</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_IZWAM845">Raschka et Mirjalili - 2019 - Python machine learning machine learning and deep.pdf					</li>
				</ul>
			</li>


			<li id="item_Q2Q9PRX7" class="item report">
			<h2>R: A language and environment for statistical   computing</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Rapport</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>R Core Team</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.r-project.org/">https://www.R-project.org/</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Vienna, Austria</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: r-core-team:2017:language-environment-statistical</td>
					</tr>
					<tr>
					<th>Institution</th>
						<td>R Foundation for Statistical Computing</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2020 à 17:32:35</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>16/10/2023 à 09:55:00</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_3VXNMCCH" class="item conferencePaper">
			<h2>Ranking Generated Summaries by Correctness: An Interesting but Challenging Application for Natural Language Inference</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tobias Falke</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Leonardo F. R. Ribeiro</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Prasetya Ajie Utama</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ido Dagan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Iryna Gurevych</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.aclweb.org/anthology/P19-1213">https://www.aclweb.org/anthology/P19-1213</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Florence, Italy</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>2214-2220</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: falke-etal:2019:ranking-generated-summaries</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.18653/v1/P19-1213">10.18653/v1/P19-1213</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>24/08/2023 à 14:54:58</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Ranking Generated Summaries by Correctness</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>24/08/2023 à 14:54:58</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>24/08/2023 à 14:58:20</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_Z3F4SRMP">
<div><div data-schema-version="8"><p>NOTE: <a href="https://www.anyscale.com/blog/llama-2-is-about-as-factually-accurate-as-gpt-4-for-summaries-and-is-30x-cheaper?s=09" rel="noopener noreferrer nofollow">https://www.anyscale.com/blog/llama-2-is-about-as-factually-accurate-as-gpt-4-for-summaries-and-is-30x-cheaper?s=09</a></p>
<p></p>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_T4IGJ5QQ">Falke et al. - 2019 - Ranking Generated Summaries by Correctness An Int.pdf					</li>
				</ul>
			</li>


			<li id="item_WSUHKM7R" class="item journalArticle">
			<h2>Rasa: Open Source Language Understanding and Dialogue Management</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tom Bocklisch</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Joey Faulkner</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Nick Pawlowski</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alan Nichol</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1712.05181">http://arxiv.org/abs/1712.05181</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-12-15</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: bocklisch-etal:2017:rasa-open-source</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>23/10/2020 à 11:41:06</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We introduce a pair of tools, Rasa NLU and Rasa Core, which 
are open source python libraries for building conversational software. 
Their purpose is to make machine-learning based dialogue management and 
language understanding accessible to non-specialist software developers.
 In terms of design philosophy, we aim for ease of use, and 
bootstrapping from minimal (or no) initial training data. Both packages 
are extensively documented and ship with a comprehensive suite of tests.
 The code is available at https://github.com/RasaHQ/</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Rasa</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2020 à 11:41:06</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:30:35</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Artificial Intelligence</li>
					<li>Computation and Language</li>
					<li>Machine learning</li>
					<li>*CITATION</li>
					<li>Rasa</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_4ME935TW">Bocklisch et al. - 2017 - Rasa Open Source Language Understanding and Dialo.pdf					</li>
				</ul>
			</li>


			<li id="item_46EASIMU" class="item journalArticle">
			<h2>Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jinjie Ni</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Tom Young</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vlad Pandelea</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Fuzhao Xue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Erik Cambria</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/2105.04387">http://arxiv.org/abs/2105.04387</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2022-03-29</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: ni-etal:2022:recent-advances-deep</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>26/07/2023 à 15:04:47</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Dialogue systems are a popular natural language processing 
(NLP) task as it is promising in real-life applications. It is also a 
complicated task since many NLP tasks deserving study are involved. As a
 result, a multitude of novel works on this task are carried out, and 
most of them are deep learning based due to the outstanding performance.
 In this survey, we mainly focus on the deep learning based dialogue 
systems. We comprehensively review state-of-the-art research outcomes in
 dialogue systems and analyze them from two angles: model type and 
system type. Speciﬁcally, from the angle of model type, we discuss the 
principles, characteristics, and applications of different models that 
are widely used in dialogue systems. This will help researchers acquaint
 these models and see how they are applied in state-of-the-art 
frameworks, which is rather helpful when designing a new dialogue 
system. From the angle of system type, we discuss task-oriented and 
open-domain dialogue systems as two streams of research, providing 
insight into the hot topics related. Furthermore, we comprehensively 
review the evaluation methods and datasets for dialogue systems to pave 
the way for future research. Finally, some possible research trends are 
identiﬁed based on the recent research outcomes. To the best of our 
knowledge, this survey is the most comprehensive and up-to-date one at 
present for deep learning based dialogue systems, extensively covering 
the popular techniques1. We speculate that this work is a good starting 
point for academics who are new to the dialogue systems or those who 
want to quickly grasp up-to-date techniques in this area.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Recent Advances in Deep Learning Based Dialogue Systems</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/07/2023 à 15:04:47</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:32:40</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*ALIRE/AIMPLÉMENTER</li>
					<li>*CITATION</li>
					<li>Chatbot</li>
					<li>Dialogue</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_S28MGQZ8">
<div><div data-schema-version="8"><p>NOTE DE LECTURE</p>
<p></p>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_VPJSKSAR">Ni et al. - 2022 - Recent Advances in Deep Learning Based Dialogue Sy.pdf					</li>
				</ul>
			</li>


			<li id="item_TT6S87FR" class="item journalArticle">
			<h2>Recent Named Entity Recognition and Classification techniques: A systematic review</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Archana Goyal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vishal Gupta</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Manish Kumar</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://linkinghub.elsevier.com/retrieve/pii/S1574013717302782">https://linkinghub.elsevier.com/retrieve/pii/S1574013717302782</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>29</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>21-43</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Computer Science Review</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>15740137</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018-08</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: goyal-etal:2018:recent-named-entity</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Computer Science Review</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.cosrev.2018.06.001">10.1016/j.cosrev.2018.06.001</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>18/09/2023 à 15:13:16</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Textual information is becoming available in abundance on the 
web, arising the requirement of techniques and tools to extract the 
meaningful information. One of such an important information extraction 
task is Named Entity Recognition and Classification. It is the problem 
of finding the members of various predetermined classes, such as person,
 organization, location, date/time, quantities, numbers etc. The concept
 of named entity extraction was first proposed in Sixth Message 
Understanding Conference in 1996. Since then, a number of techniques 
have been developed by many researchers for extracting diversity of 
entities from different languages and genres of text. Still, there is a 
growing interest among research community to develop more new approaches
 to extract diverse named entities which are helpful in various natural 
language applications. Here we present a survey of developments and 
progresses made in Named Entity Recognition and Classification research.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Recent Named Entity Recognition and Classification techniques</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 15:13:16</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:12:15</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_K7PJ7NIL" class="item bill">
			<h2>Regulation (EU) 2016/679 of the European Parliament and of the 
Council of 27 April 2016 on the protection of natural persons with 
regard to the processing of personal data and on the free movement of 
such data, and repealing Directive 95/46/EC (General Data Protection 
Regulation)</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Projet/proposition de loi</td>
					</tr>
					<tr>
						<th class="sponsor">Auteur</th>
						<td>European Commission</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679">https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-05-04</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: european-commission:2016:regulation-eu-2016</td>
					</tr>
					<tr>
					<th>Code</th>
						<td>32016R0679</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>N° de projet</th>
						<td>2016/679</td>
					</tr>
					<tr>
					<th>Volume de code</th>
						<td>OJ L 119</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>General Data Protection Regulation</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 10:41:30</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>19/10/2023 à 12:20:24</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_Q86DQLZD">European Commission - 2016 - Regulation (EU) 2016679 of the European Parliamen.pdf					</li>
				</ul>
			</li>


			<li id="item_KQ2R4AS9" class="item journalArticle">
			<h2>Representative Sampling, I: Non-Scientific Literature</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>William Kruskal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Frederick Mosteller</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.jstor.org/stable/1403202?origin=crossref">https://www.jstor.org/stable/1403202?origin=crossref</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>47</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>13</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Statistical Review / Revue Internationale de Statistique</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>03067734</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1979-04</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kruskal-mosteller:1979:representative-sampling-nonscientific</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>International Statistical Review / Revue Internationale de Statistique</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.2307/1403202">10.2307/1403202</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>03/10/2023 à 14:17:57</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>By classifying and illustrating non-scientific uses of the 
term 'representative sample', its meanings can be clarified. The 
principal meanings seem to be: generalized if unjustified acclaim for 
data; absence of selective forces; miniature of the population; typical 
case or cases, the ideal case; and coverage of the population. Because 
of its ambiguities and imprecision, we recommend great caution in the 
use of the expression 'representative sample'. Usually a more specific 
expression will add clarity.
---
Les différents sens du terme 'échantillon représentatif' peuvent être 
clarifiés en classant et illustrant ses emplois non-scientifiques. Les 
principaux sens semblent être: un enthousiasme généralisé et non 
justifié pour les données l'absence de forces déformantes dans les choix
 une miniaturisation de la population un ou des exemples typiques; un 
exemple idéal une situation où l'ensemble de la population est couvert. A
 cause de son ambiguité et de son manque de précision, nous recommandons
 la plus grande précaution dans l'emploi de l'expression 'échantillon 
représentatif'. En général, utiliser une expression plus spécifique 
ajoutera de la clarté.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Representative Sampling, I</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>03/10/2023 à 14:17:57</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:49:18</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_3462XT5Y">Data Representativity for Machine Learning and AI Systems</li>
				</ul>
			</li>


			<li id="item_CY6GMSW5" class="item journalArticle">
			<h2>Representative Sampling, II: Scientific Literature, Excluding Statistics</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>William Kruskal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Frederick Mosteller</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.jstor.org/stable/1402564?origin=crossref">https://www.jstor.org/stable/1402564?origin=crossref</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>47</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>111</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Statistical Review / Revue Internationale de Statistique</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>03067734</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1979-08</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kruskal-mosteller:1979:representative-sampling-ii</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>International Statistical Review / Revue Internationale de Statistique</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.2307/1402564">10.2307/1402564</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>03/10/2023 à 14:18:07</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This paper describes and illustrates the meanings of 
'representative sample' and 'representative sampling' as used in the 
extrastatistical scientific literature. Six categories seem adequate to 
describe these uses. The first five appeared also in the review of 
non-scientific uses in 'Representative Sampling, I' (Kruskal and 
Mosteller, 1979). We define and illustrate these in Sections 1-5 of the 
paper. Meaning 1 General, unjustified acclaim for the data. Here the 
investigator gives the data a pat on the back by using a seemingly 
scientific term to raise its stature. No grounds, either in study design
 or empirical information, are given to support this usage, and hence we
 recommend that it be abandoned in scientific discourse. Meaning 2 
Absence (or presence) of selective forces. If grounds for the absence 
are given, this meaning may revert to Meaning 6, a vague term to be made
 specific. Otherwise it reverts to Meaning 1. In proclaiming the 
presence of selective forces, one is denying Meaning 6. Meaning 3 Mirror
 or miniature of the population. The sample has the same distribution as
 the population. This rare feature carries with it severe constraints. 
We would avoid calling this a 'representative sample' because it seems 
much more. Meaning 4 Typical or ideal case. An item from the population 
that represents it on the average or modally (or ideally). We call it a 
representative, but not a 'representative sample'. Meaning 5 Coverage of
 the population. Samples designed to reflect variation, especially among
 strata. A sample containing at least one item from each stratum of a 
partition of the population is said to cover it for that partition. We 
would not use the term 'representative sample' for such samples. The new
 meaning found in the scientific literature is that of a vague term; we 
describe it in Section 0. Meaning 6 A vague term to be made precise. It 
often takes a good deal of space to describe a formal sampling scheme 
and it may be a convenience to have a term like 'representative sample' 
or 'representative sampling' to refer to the sample or the process 
generating it. We recommend that this usage be preserved for probability
 samples, and that the sampling method be described in the same work.
---
Cet article d'ecrit et explique à l'aide d'exemples les sens des termes 
'échantillon représentatif' et 'échantillonnage représentatif' tels 
qu'ils sont utilisés dans la littérature scientifique extrastatistique. 
Six catégories semblent adéquates pour décrire ces emplois. Les cinq 
premières ont également paru dans la revue des emplois non-scientifiques
 dans 'Echantillonnage Représentatif I', Kruskal et Mosteller (1979). 
Nous les définissons et les expliquons à l'aide d'exemples dans les 
parties 1 à 5 du présent article.
- Sens 1. Un enthousiasme général et non justifié pour les données. Le 
chercheur 'gonfle' les données en utilisant un terme apparemment 
scientifique pour rehausser leur stature. Aucune raison valable, soit 
dans le plan de l'étude soit dans l'information empirique, n'est 
apportée pour justifier cet emploi, et c'est pourquoi nous suggérons 
qu'il soit rayé du langage scientifique.
- Sens 2. Absence (ou présence) de forces discriminatoires. Si des 
raisons valables pour leur absence sont données, ce sens peut revenir au
 sens numéro six, un terme vague qu'il reste à rendre scientifique. 
Sinon, il revient au sens numéro un. En soulignant la présence de forces
 discriminatoires, on dément le sens numéro six.
- Sens 3. Reflet ou miniature de la population. L'échantillon a la même 
répartition que la population. Cette caractéristique rare s'accompagne 
de contraintes sévères. Nous éviterions d'appeler ceci un échantillon 
représentatif car il semble être beaucoup plus.
- Sens 4. Cas typique ou idéal. Un élément de la population qui la 
représente en moyenne ou de façon la plus probable (ou idéale). Nous 
appelons ceci un représentant et non un 'échantillon représentatif'.
- Sens 5. Recouvrement de la population. Echantillons conçus pour 
refléter la variation, particulièrement entre les strates. Un 
échantillon contenant au moins un élément de chaque strate d'une 
partition de la population est dit la recouvrir pour cette partition. 
Nous n'emploierions pas le terme 'échantillon représentatif' pour de 
tels échantillons.
(Le nouveau sens trouvé dans la littérature scientifique est celui d'un 
terme vague. Nous le décrivons dans la partie 0.)
- Sens 6. Une terme vague qu'il reste à préciser. La description d'une 
méthode d'échantillonnage demande de longues explications et il peut 
être pratique d'avoir à sa disposition un terme tel qu' 'échantillon 
représentatif' ou 'échantillonnage représentatif' pour se rapporter à 
l'échantillon ou au procédé qui l'engendre. Nous suggérons que cet usage
 soit réservé aux échantillons probabilistes et que la méthode 
d'échantillonnage soit décrite dans la même étude.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Representative Sampling, II</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>03/10/2023 à 14:18:07</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:49:23</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_3462XT5Y">Data Representativity for Machine Learning and AI Systems</li>
				</ul>
			</li>


			<li id="item_J54J9T35" class="item journalArticle">
			<h2>Representativeness in Corpus Design</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Douglas Biber</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1093/llc/8.4.243">https://doi.org/10.1093/llc/8.4.243</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Literary and Linguistic Computing</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1993</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: biber:1993:representativeness-corpus-design</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1093/llc/8.4.243">10.1093/llc/8.4.243</a></td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>The present paper addresses a number of issues related to 
achieving 'representativeness' in linguistic corpus design, including: 
discussion of what it means to 'represent' a language, definition of the
 target population, stratified versus proportional sampling of a 
language, sampling within texts, and issues relating to the required 
sample size (number of texts) of a corpus. The paper distinguishes among
 various ways that linguistic features can be distributed within and 
across texts; it analyses the distributions of several particular 
features, and it discusses the implications of these distributions for 
corpus design.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>01/09/2023 à 13:13:10</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>10/10/2023 à 09:21:22</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_IEZTUK6S">Biber - 1993 - Representativeness in Corpus Design.pdf					</li>
				</ul>
			</li>


			<li id="item_Z86465JE" class="item journalArticle">
			<h2>Retrieval Augmentation Reduces Hallucination in Conversation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Kurt Shuster</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Spencer Poff</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Moya Chen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Douwe Kiela</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jason Weston</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2104.07567">https://arxiv.org/abs/2104.07567</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>arXiv.org perpetual, non-exclusive license</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: shuster-etal:2021:retrieval-augmentation-reduces</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2104.07567">10.48550/ARXIV.2104.07567</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>24/10/2023 à 09:19:03</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Despite showing increasingly human-like conversational 
abilities, state-of-the-art dialogue models often suffer from factual 
incorrectness and hallucination of knowledge (Roller et al., 2020). In 
this work we explore the use of neural-retrieval-in-the-loop 
architectures - recently shown to be effective in open-domain QA (Lewis 
et al., 2020b; Izacard and Grave, 2020) - for knowledge-grounded 
dialogue, a task that is arguably more challenging as it requires 
querying based on complex multi-turn dialogue context and generating 
conversationally coherent responses. We study various types of 
architectures with multiple components - retrievers, rankers, and 
encoder-decoders - with the goal of maximizing knowledgeability while 
retaining conversational ability. We demonstrate that our best models 
obtain state-of-the-art performance on two knowledge-grounded 
conversational tasks. The models exhibit open-domain conversational 
capabilities, generalize effectively to scenarios not within the 
training data, and, as verified by human evaluations, substantially 
reduce the well-known problem of knowledge hallucination in 
state-of-the-art chatbots.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>24/10/2023 à 09:19:03</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>25/10/2023 à 21:33:52</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Computation and Language (cs.CL)</li>
					<li>FOS: Computer and information sciences</li>
					<li>Artificial Intelligence (cs.AI)</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_6CZKD7TM">Shuster et al. - 2021 - Retrieval Augmentation Reduces Hallucination in Co.pdf					</li>
				</ul>
			</li>


			<li id="item_NNFH79CW" class="item journalArticle">
			<h2>Review of data preprocessing techniques in data mining</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Suad A Alasadi</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Wesam S Bhaya</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.academia.edu/download/54509277/4102-4107.pdf">https://www.academia.edu/download/54509277/4102-4107.pdf</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>12</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>16</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>4102–4107</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of Engineering and Applied Sciences</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1816-949X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: alasadi-bhaya:2017:review-data-preprocessing</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>04/10/2023 à 14:40:24</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>04/10/2023 à 14:43:58</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_EU53T374">Alasadi et Bhaya - 2017 - Review of data preprocessing techniques in data mi.pdf					</li>
				</ul>
			</li>


			<li id="item_DC5UYQLC" class="item journalArticle">
			<h2>Review of end-to-end speech synthesis technology based on deep learning</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zhaoxi Mu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Xinyu Yang</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yizhuo Dong</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/2104.09995">http://arxiv.org/abs/2104.09995</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-04-20</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: mu-etal:2021:review-endtoend-speech</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/https://doi.org/10.48550/arXiv.2104.09995">https://doi.org/10.48550/arXiv.2104.09995</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>18/09/2023 à 16:15:13</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>As an indispensable part of modern human-computer interaction 
system, speech synthesis technology helps users get the output of 
intelligent machine more easily and intuitively, thus has attracted more
 and more attention. Due to the limitations of high complexity and low 
efficiency of traditional speech synthesis technology, the current 
research focus is the deep learning-based end-to-end speech synthesis 
technology, which has more powerful modeling ability and a simpler 
pipeline. It mainly consists of three modules: text front-end, acoustic 
model, and vocoder. This paper reviews the research status of these 
three parts, and classifies and compares various methods according to 
their emphasis. Moreover, this paper also summarizes the open-source 
speech corpus of English, Chinese and other languages that can be used 
for speech synthesis tasks, and introduces some commonly used subjective
 and objective speech quality evaluation method. Finally, some 
attractive future research directions are pointed out.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 16:15:13</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:32:26</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Computer Science - Sound</li>
					<li>Electrical Engineering and Systems Science - Audio and Speech Processing</li>
					<li>Computer Science - Computation and Language</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_RMUDP3MB">Mu et al. - 2021 - Review of end-to-end speech synthesis technology b.pdf					</li>
				</ul>
			</li>


			<li id="item_S7DY55W8" class="item journalArticle">
			<h2>Review on Optical Character Recognition</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Muna Ahmed Awel</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ali Imam Abidi</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>06</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>06</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: awel-abidi:2019:review-optical-character</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Optical Character Recognition is the area of Pattern 
Recognition that has a topic of studies over the past some decades. 
Optical character recognition is technique of automatically identifying 
of different character from a record picture additionally provide full 
alphanumeric recognition of printed or handwritten characters, text 
numerical, letters, and symbols in to a computer process able layout 
including ASCII, Unicode and so forth. Optical character recognition is 
the bottom for many distinct styles of programs in diverse fields, a lot
 of which we use in our daily lives. Cost effective and less time 
consuming, corporations, submit offices, banks, security systems, and 
even the field of robotics hire this system as the base in their 
Operations. These days, there are numerous portions of research and 
making use of OCR technology. These OCR technologies help to examine 
unique documents written in English, Chinese, Hindu, Arabic, Russian, 
and others languages. On This paper present review of some researches 
has been made in English, Arabic and Devanagaricharacters. And explained
 the methodology they use and challenge they face during development of 
Optical character recognition.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>15/09/2023 à 16:38:20</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>15/09/2023 à 16:40:02</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_IND7PUJD">Awel et Abidi - 2019 - Review on Optical Character Recognition.pdf					</li>
				</ul>
			</li>


			<li id="item_XVKNKEE9" class="item book">
			<h2>Rodeo</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Morris</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>René Goscinny</td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Lucky Luke</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Dupuis</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-2-8001-0141-5</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1950</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: morris-goscinny:1950:rodeo</td>
					</tr>
					<tr>
					<th>N° ds la coll.</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fre</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 12:20:40</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>18/09/2023 à 12:22:11</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_MALQLH7I" class="item conferencePaper">
			<h2>SemEval-2007 task 17: English lexical sample, SRL and all words</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sameer S. Pradhan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Edward Loper</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dmitriy Dligach</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Martha Palmer</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://portal.acm.org/citation.cfm?doid=1621474.1621490">http://portal.acm.org/citation.cfm?doid=1621474.1621490</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Prague, Czech Republic</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>87-92</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2007</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: pradhan-etal:2007:semeval2007-task-17</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.3115/1621474.1621490">10.3115/1621474.1621490</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>27/06/2023 à 18:55:12</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>the 4th International Workshop</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This paper describes our experience in preparing the data and 
evaluating the results for three subtasks of SemEval-2007 Task-17 – 
Lexical Sample, Semantic Role Labeling (SRL) and All-Words respectively.
 We tabulate and analyze the results of participating systems.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the 4th International Workshop on Semantic Evaluations - SemEval '07</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>SemEval-2007 task 17</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>27/06/2023 à 18:55:12</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:45</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_WXHN2Z2U">Pradhan et al. - 2007 - SemEval-2007 task 17 English lexical sample, SRL .pdf					</li>
				</ul>
			</li>


			<li id="item_KUZIZC47" class="item journalArticle">
			<h2>Semi-Supervised Aﬃnity Propagation with Instance-Level Constraints</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Inmar E Givoni</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Brendan J Frey</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2009</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: givoni-frey:2009:semisupervised-affinity-propagation</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Recently, aﬃnity propagation (AP) was introduced as an 
unsupervised learning algorithm for exemplar based clustering. Here we 
extend the AP model to account for semisupervised clustering. AP, which 
is formulated as inference in a factor-graph, can be naturally extended 
to account for ‘instancelevel’ constraints: pairs of data points that 
cannot belong to the same cluster (cannotlink), or must belong to the 
same cluster (must-link). We present a semi-supervised AP algorithm 
(SSAP) that can use instancelevel constraints to guide the clustering. 
We demonstrate the applicability of SSAP to interactive image 
segmentation by using SSAP to cluster superpixels while taking into 
account user instructions regarding which superpixels belong to the same
 object. We demonstrate SSAP can achieve better performance compared to 
other semi-supervised methods.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>12/01/2023 à 13:20:53</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:16</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>Affinity propagation</li>
					<li>Constrained clustering</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_SMP6WJN6">Givoni et Frey - 2009 - Semi-Supervised Aﬃnity Propagation with Instance-L.pdf					</li>
				</ul>
			</li>


			<li id="item_I59KKTIR" class="item journalArticle">
			<h2>Skills Requirements of Business Data Analytics and Data Science Jobs: A Comparative Analysis</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Zinovy Radovilsky</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vishwanath Hegde</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Anuja Acharya</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>16</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: radovilsky-etal:2018:skills-requirements-business</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/09/2023 à 12:39:12</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>26/09/2023 à 12:52:05</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_TPG8D56J">Radovilsky et al. - 2018 - Skills Requirements of Business Data Analytics and.pdf					</li>
				</ul>
			</li>


			<li id="item_M46T8HPS" class="item journalArticle">
			<h2>Some methods for classification and analysis of multivariate observations.</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>J MacQueen</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>14</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>281-297</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Proceedings of the fifth Berkeley symposium on mathematical statistics and probability</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1967</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: macqueen:1967:methods-classification-analysis</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/10/2020 à 18:44:33</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:26</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>K-Means</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_NUMFXV2C">MacQueen - 1967 - Some methods for classification and analysis of mu.pdf					</li>
				</ul>
			</li>


			<li id="item_GFGQCQE2" class="item book">
			<h2>Sous le ciel de l'ouest</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Morris</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>René Goscinny</td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Lucky Luke</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Dupuis</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-2-8001-0143-9</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1952</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: morris-goscinny:1952:sous-ciel-ouest</td>
					</tr>
					<tr>
					<th>N° ds la coll.</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fre</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 12:17:43</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>18/09/2023 à 12:19:44</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_HZF8FND8" class="item journalArticle">
			<h2>spaCy 2 : Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Matthew Honnibal</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ines Montani</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: honnibal-montani:2017:spacy-natural-language</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>23/10/2020 à 13:04:34</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:34</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Spacy</li>
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_5UTPGAGF" class="item journalArticle">
			<h2>Spectral Learning</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Sepandar D Kamvar</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Dan Klein</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Christopher D Manning</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>561-566</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Proceedings of the international joint conference on artificial intelligence</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2003</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kamvar-etal:2003:spectral-learning</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We present a simple, easily implemented spectral learning 
algorithm that applies equally whether we have no supervisory 
information, pairwise link constraints, or labeled examples. In the 
unsupervised case, it performs consistently with other spectral 
clustering algorithms. In the supervised case, our approach achieves 
high accuracy on the categorization of thousands of documents given only
 a few dozen labeled training documents for the 20 Newsgroups data set. 
Furthermore, its classiﬁcation accuracy increases with the addition of 
unlabeled documents, demonstrating effective use of unlabeled data.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/10/2020 à 19:02:29</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:19</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Clustering</li>
					<li>Constrained clustering</li>
					<li>Spectral clustering</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_GX9HEA6W">Kamvar et al. - 2003 - Spectral Learning.pdf					</li>
				</ul>
			</li>


			<li id="item_MPIIBQM7" class="item conferencePaper">
			<h2>Statsmodels: Econometric and Statistical Modeling with Python</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Skipper Seabold</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Josef Perktold</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://conference.scipy.org/proceedings/scipy2010/seabold.html">https://conference.scipy.org/proceedings/scipy2010/seabold.html</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Austin, Texas</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>92-96</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2010</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: seabold-perktold:2010:statsmodels-econometric-statistical</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.25080/Majora-92bf1922-011">10.25080/Majora-92bf1922-011</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>07/07/2023 à 10:22:20</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>Python in Science Conference</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Statsmodels</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/07/2023 à 10:22:20</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>07/07/2023 à 10:22:24</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_N79637BD">Texte intégral					</li>
				</ul>
			</li>


			<li id="item_QUAV2E4L" class="item conferencePaper">
			<h2>Stop Word Lists in Free Open-source Software Packages</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Joel Nothman</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Hanmin Qin</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Roman Yurchak</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://aclweb.org/anthology/W18-2502">http://aclweb.org/anthology/W18-2502</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Melbourne, Australia</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7-12</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: nothman-etal:2018:stop-word-lists</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.18653/v1/W18-2502">10.18653/v1/W18-2502</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 15:07:51</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>Proceedings of Workshop for NLP Open Source Software (NLP-OSS)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of Workshop for NLP Open Source Software (NLP-OSS)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 15:07:51</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:45</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Preprocessing</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>Stopwords</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_VGBMUBTE">Nothman et al. - 2018 - Stop Word Lists in Free Open-source Software Packa.pdf					</li>
				</ul>
			</li>


			<li id="item_WYT8SAK5" class="item dataset">
			<h2>Subset of 'MLSUM: The Multilingual Summarization Corpus' for constraints annotation experiment</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Dataset</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Erwan Schild</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Marie Adler</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.5281/ZENODO.8399301">https://doi.org/10.5281/ZENODO.8399301</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>MIT License, Open Access</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2023-10-02</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: schild-adler:2023:subset-mlsum-multilingual</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.5281/ZENODO.8399301">10.5281/ZENODO.8399301</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>02/10/2023 à 16:02:24</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Version</th>
						<td>1.0.0 [subset: fr+train+filtered]</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>fr</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>&lt;strong&gt;[EN] Subset of 'MLSUM: The Multilingual 
Summarization Corpus' for constraints annotation 
experiment.&lt;/strong&gt; &lt;strong&gt;Description&lt;/strong&gt;: 
MLSUM is a dataset of newspappers articles aimed at training summaring 
model. We use it for a constraints annotation experiment on newspapper 
titles according to their topic classification. 
&lt;strong&gt;Content&lt;/strong&gt;: For constraints annotation 
experiment based on data similarity, this dataset have been subsetted 
(randomly pick 75 articles in the following 14 most used topics: 
'economie', 'politique', 'sport', 'planete' (renamed in 'ecologie'), 
'sciences', 'police-justice', 'disparitions', 'emploi', 'sante', 
'musiques', 'arts', 'educations', 'climat' (renamed in 'meteo'), 
'immobilier') and filtered (keep articles that have an obvious topics 
regarding their titles, without their bodies). Two reviewers have 
working on this task in order to limit the subjectivity of the 
filtering. This subsetted dataset is used (1) to estimate needed time to
 annotate titles similarity with constraints (MUST-LINK, CANNOT-LINK) 
and (2) to test interactive clustering methodology (constraints 
annotation and constrained clustering). 
&lt;strong&gt;Origin&lt;/strong&gt;: The dataset is bassed on the 
original 'MLSUM: The Multilingual Summarization Corpus' dataset 
(https://doi.org/10.48550/arXiv.2004.14900). &lt;br&gt; 
&lt;strong&gt;[FR] Echantillon de 'MLSUM: The Multilingual Summarization
 Corpus' pour une expériemnt d'annotation de contraintes.&lt;/strong&gt;
 &lt;strong&gt;Description &lt;/strong&gt;: MLSUM est un ensemble de 
données d'articles de journaux destinés à l'entraînement d'un modèle de 
résumé automatique. Nous l'utilisons pour une expérience d'annotation de
 contraintes sur des titres de journaux en fonction de leur 
classification thématique. &lt;strong&gt;Contenu &lt;/strong&gt;: Pour 
une expérience d'annotation de contraintes basée sur la similarité des 
données, cet ensemble de données a été échantillonné (sélectionner au 
hasard de 75 articles dans les 14 sujets les plus utilisés : 'économie',
 'politique', 'sport', 'planète' (renommé en « écologie »). ), 
'sciences', 'police-justice', 'disparitions', 'emploi', 'sante', 
'musiques', 'arts', 'éducations', 'climat' (renommé en 'meteo'), 
'immobilier' ) et filtré (conserver les articles qui ont un sujet 
évident par rapport à leur titre, sans leur corps). Deux relecteurs ont 
travaillé sur cette tâche afin de limiter la subjectivité du filtrage. 
Ce sous-ensemble de données est utilisé (1) pour estimer le temps 
nécessaire pour annoter la similarité des titres avec des contraintes 
(MUST-LINK, CANNOT-LINK) et (2) pour tester la méthodologie de 
clustering interactif (annotation de contraintes et clustering 
contraint). &lt;strong&gt;Origine &lt;/strong&gt;: L'ensemble de données
 est basé sur l'ensemble de données original 'MLSUM : The Multilingual 
Summarization Corpus' (https://doi.org/10.48550/arXiv.2004.1490).</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Subset of 'MLSUM</td>
					</tr>
					<tr>
					<th>Dépôt</th>
						<td>Zenodo</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>02/10/2023 à 16:02:24</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>16/10/2023 à 10:08:03</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Computation and Language</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
					<li>*PUBLICATION</li>
					<li>Trainset</li>
					<li>Natural Language Processing</li>
					<li>Newspapper article</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_VN46BQAB">mlsum_fr_train_subset_v1.0.0.schild_UNLABELLED.xlsx					</li>
					<li id="item_8MEAE6CJ">mlsum_fr_train_subset_v1.0.0.schild.xlsx					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_R5NI67R5">MLSUM: The Multilingual Summarization Corpus</li>
				</ul>
			</li>


			<li id="item_TJ5GT9KX" class="item journalArticle">
			<h2>Support-vector networks</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Corinna Cortes</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vladimir Vapnik</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/BF00994018">http://link.springer.com/10.1007/BF00994018</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>20</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>273-297</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Machine Learning</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0885-6125, 1573-0565</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1995-09</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: cortes-vapnik:1995:supportvector-networks</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Mach Learn</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/BF00994018">10.1007/BF00994018</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>18/09/2023 à 14:20:07</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>18/09/2023 à 14:20:07</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:50:09</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_FEREHLHS">Texte intégral					</li>
				</ul>
			</li>


			<li id="item_2WLBFLXW" class="item journalArticle">
			<h2>Text Data Augmentation for Deep Learning</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Connor Shorten</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Taghi M. Khoshgoftaar</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Borko Furht</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00492-0">https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00492-0</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>101</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of Big Data</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2196-1115</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: shorten-etal:2021:text-data-augmentation</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>J Big Data</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1186/s40537-021-00492-0">10.1186/s40537-021-00492-0</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>29/09/2023 à 11:04:09</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Natural Language Processing (NLP) is one of the most 
captivating applications of Deep Learning. In this survey, we consider 
how the Data Augmentation training strategy can aid in its development. 
We begin with the major motifs of Data Augmentation summarized into 
strengthening local decision boundaries, brute force training, causality
 and counterfactual examples, and the distinction between meaning and 
form. We follow these motifs with a concrete list of augmentation 
frameworks that have been developed for text data. Deep Learning 
generally struggles with the measurement of generalization and 
characterization of overfitting. We highlight studies that cover how 
augmentations can construct test sets for generalization. NLP is at an 
early stage in applying Data Augmentation compared to Computer Vision. 
We highlight the key differences and promising ideas that have yet to be
 tested in NLP. For the sake of practical implementation, we describe 
tools that facilitate Data Augmentation such as the use of consistency 
regularization, controllers, and offline and online augmentation 
pipelines, to preview a few. Finally, we discuss interesting topics 
around Data Augmentation in NLP such as task-specific augmentations, the
 use of prior knowledge in self-supervised learning versus Data 
Augmentation, intersections with transfer and multi-task learning, and 
ideas for AI-GAs (AI-Generating Algorithms). We hope this paper inspires
 further research interest in Text Data Augmentation.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 11:04:09</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:01:31</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_KHRQ5F9J">
<div><div data-schema-version="8"><p><strong>NOTES ERWAN:</strong></p>
<ul>
<li>
Symbolic augmentation, Rule-based augmentation, Graph-structured augmentation
</li>
<li>
Neural augmentation: Back-translation augmentation, Style augmentation
</li>
<li>
PB: Consistency regularization
</li>
</ul>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_JJ3JB4X5">Shorten et al. - 2021 - Text Data Augmentation for Deep Learning.pdf					</li>
				</ul>
			</li>


			<li id="item_G4LCQFJH" class="item book">
			<h2>The Architecture of Cognition</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>John R. Anderson</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.taylorfrancis.com/books/9781317759539">https://www.taylorfrancis.com/books/9781317759539</a></td>
					</tr>
					<tr>
					<th>Édition</th>
						<td>0</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Psychology Press</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-317-75953-9</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2013-11-19</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: anderson:2013:architecture-cognition</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>07/06/2023 à 14:32:34</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 14:32:34</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:06:16</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Ergonomie</li>
					<li>Temps adaptation</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_AFEUZH3H">
<div><div data-schema-version="8"><p>NOTE ERWAN</p>
<blockquote>
<p>3 phases :</p>
<ol>
<li>
<strong>Phase declarative</strong> : Acquisition des connaissances, mais
 recours systèmatique à des instructions ; Exécution lente et avec 
erreurs ; Besoin d’instructions détaillées ;
</li>
<li>
<strong>Phase associative</strong> : gains de vitesse, moins besoin de lire les instructions. Juste besoin de rappel du type SI … ALORS … ;
</li>
<li>
<strong>Phase autonome</strong> : Plus besoin de consignes, vitesse de croissière atteinte, exécution rapide et sans erreur.
</li>
</ol>
</blockquote>
</div></div>
					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_X5GGWCMD">Usability assessment: how to measure the usability of products, services, and systems</li>
				</ul>
			</li>


			<li id="item_TFUJFX8V" class="item bookSection">
			<h2>The Challenges of Clustering High Dimensional Data</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Luc T. Wille</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michael Steinbach</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Levent Ertöz</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Vipin Kumar</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-662-08968-2_16">http://link.springer.com/10.1007/978-3-662-08968-2_16</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Berlin, Heidelberg</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer Berlin Heidelberg</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>273-309</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-642-07739-5 978-3-662-08968-2</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2004</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: steinbach-etal:2004:challenges-clustering-high</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>16/10/2023 à 18:22:57</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>New Directions in Statistical Physics</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>16/10/2023 à 18:22:57</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>25/10/2023 à 21:34:27</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_5WDVI8KB">Steinbach et al. - 2004 - The Challenges of Clustering High Dimensional Data.pdf					</li>
				</ul>
			</li>


			<li id="item_RFGUSG7J" class="item conferencePaper">
			<h2>The INCEpTION platform: Machine-assisted and knowledge-oriented interactive annotation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jan-Christoph Klie</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michael Bugert</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Beto Boullosa</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Richard Eckart de Castilho</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Iryna Gurevych</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://inception-project.github.io/">https://inception-project.github.io/</a></td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>5–9</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: klie-etal:2018:inception-platform-machineassisted</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We introduce INCEpTION, a new annotation platform for tasks 
including interactive and semantic annotation (e.g., concept linking, 
fact linking, knowledge base population, semantic frame annotation). 
These tasks are very time consuming and demanding for annotators, 
especially when knowledge bases are used. We address these issues by 
developing an annotation platform that incorporates machine learning 
capabilities which actively assist and guide annotators. The platform is
 both generic and modular. It targets a range of research domains in 
need of semantic annotation, such as digital humanities, bioinformatics,
 or linguistics. INCEpTION is publicly available as open-source 
software.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the 27th international conference on computational linguistics: System demonstrations</td>
					</tr>
					<tr>
					<th>Archive</th>
						<td>http://tubiblio.ulb.tu-darmstadt.de/106270/</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/09/2023 à 19:29:32</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:12:30</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>UKP_a_LangTech4eHum</li>
					<li>UKP_p_INCEpTION</li>
					<li>UKP_reviewed</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_ICABSAPT">
<p class="plaintext">Event Title: The 27th International Conference on Computational Linguistics (COLING 2018)</p>
					</li>
				</ul>
			</li>


			<li id="item_5YTX4Y78" class="item journalArticle">
			<h2>The Measurement of Observer Agreement for Categorical Data</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>J. Richard Landis</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gary G. Koch</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.jstor.org/stable/2529310?origin=crossref">https://www.jstor.org/stable/2529310?origin=crossref</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>33</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>159</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Biometrics</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0006341X</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1977-03</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: landis-koch:1977:measurement-observer-agreement</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Biometrics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.2307/2529310">10.2307/2529310</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>14/10/2023 à 18:27:38</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>14/10/2023 à 18:27:38</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>14/10/2023 à 18:28:18</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_YDJ49MP4">Version acceptée					</li>
				</ul>
			</li>


			<li id="item_EQH9XZ5U" class="item conferencePaper">
			<h2>The Multilingual Amazon Reviews Corpus</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Phillip Keung</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yichao Lu</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>György Szarvas</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Noah A. Smith</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.aclweb.org/anthology/2020.emnlp-main.369">https://www.aclweb.org/anthology/2020.emnlp-main.369</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Online</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Association for Computational Linguistics</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>4563-4568</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2020</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: keung-etal:2020:multilingual-amazon-reviewsa</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.18653/v1/2020.emnlp-main.369">10.18653/v1/2020.emnlp-main.369</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>03/10/2023 à 17:34:39</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Intitulé du colloque</th>
						<td>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We present the Multilingual Amazon Reviews Corpus (MARC), a 
large-scale collection of Amazon reviews for multilingual text 
classification. The corpus contains reviews in English, Japanese, 
German, French, Spanish, and Chinese, which were collected between 2015 
and 2019. Each record in the dataset contains the review text, the 
review title, the star rating, an anonymized reviewer ID, an anonymized 
product ID, and the coarse-grained product category (e.g., ‘books’, 
‘appliances’, etc.) The corpus is balanced across the 5 possible star 
ratings, so each rating constitutes 20% of the reviews in each language.
 For each language, there are 200,000, 5,000, and 5,000 reviews in the 
training, development, and test sets, respectively. We report baseline 
results for supervised text classification and zero-shot cross-lingual 
transfer learning by fine-tuning a multilingual BERT model on reviews 
data. We propose the use of mean absolute error (MAE) instead of 
classification accuracy for this task, since MAE accounts for the 
ordinal nature of the ratings.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>03/10/2023 à 17:34:39</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>03/10/2023 à 17:35:01</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_QQ9HP3I4">Texte intégral					</li>
				</ul>
			</li>


			<li id="item_FKQ2N4QI" class="item conferencePaper">
			<h2>The PASCAL Recognising Textual Entailment Challenge</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ido Dagan</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Oren Glickman</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Bernardo Magnini</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/11736790_9">http://link.springer.com/10.1007/11736790_9</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>3944</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Berlin, Heidelberg</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer Berlin Heidelberg</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>177-190</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-540-33427-9</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2005-01</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: dagan-etal:2005:pascal-recognising-textual</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/11736790_9">10.1007/11736790_9</a></td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>This paper describes the Second PASCAL Recognising Textual 
Entailment Challenge (RTE-2).1 We describe the RTE2 dataset and overview
 the submissions for the challenge. One of the main goals for this 
year’s dataset was to provide more “realistic” text-hypothesis examples,
 based mostly on outputs of actual systems. The 23 submissions for the 
challenge present diverse approaches and research directions, and the 
best results achieved this year are considerably higher than last year’s
 state of the art.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 13:17:31</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:51:46</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_PY2ZLBEI">
<div><div data-schema-version="8"><p>NOTE ERWAN</p>
<blockquote>
<p><strong>Note</strong>: The RTE task is defined as recognizing, given 
two text fragments, whether the meaning of one text can be inferred (en-
 tailed) from the other</p>
</blockquote>
</div></div>
					</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_NXZHY47L">Dagan et al. - 2006 - The PASCAL Recognising Textual Entailment Challeng.pdf					</li>
				</ul>
			</li>


			<li id="item_TI7Y65GT" class="item bookSection">
			<h2>The Prague Dependency Treebank</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Chapitre de livre</td>
					</tr>
					<tr>
						<th class="editor">Éditeur</th>
						<td>Anne Abeillé</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alena Böhmová</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jan Hajič</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Eva Hajičová</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Barbora Hladká</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-94-010-0201-1_7">http://link.springer.com/10.1007/978-94-010-0201-1_7</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>20</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Dordrecht</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Springer Netherlands</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>103-127</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4020-1335-5 978-94-010-0201-1</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2003</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: bohmova-etal:2003:prague-dependency-treebank</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>21/09/2023 à 18:05:03</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Titre du livre</th>
						<td>Treebanks</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>21/09/2023 à 18:05:03</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>29/10/2023 à 10:01:11</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_FS7DFHPZ">
<div><div data-schema-version="8"><p><strong>NOTES ERWAN</strong></p>
<ul>
<li>
manual annotation of the morphological and analytical levels
</li>
<li>
time: <strong>5</strong> years
</li>
<li>
nb of persons: <strong>22</strong> persons, incl. <strong>17</strong> simultaneously during the most demanding periods
</li>
<li>
cost estimate: <strong>$600,000</strong>
</li>
</ul>
</div></div>
					</li>
				</ul>
			</li>


			<li id="item_AUFKWGEH" class="item journalArticle">
			<h2>The Regulation of Working Methods as a Function of Work-load among Air Traffic Controllers</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jean-Claude Sperandio</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.tandfonline.com/doi/full/10.1080/00140137808931713">https://www.tandfonline.com/doi/full/10.1080/00140137808931713</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>21</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>195-202</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Ergonomics</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0014-0139, 1366-5847</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1978-03</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: sperandio:1978:regulation-working-methods</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Ergonomics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1080/00140137808931713">10.1080/00140137808931713</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>01/09/2023 à 17:12:31</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>01/09/2023 à 17:12:31</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:49:02</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
			</li>


			<li id="item_CZE23BKU" class="item journalArticle">
			<h2>The truth of the F-measure</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Yutaka Sasaki</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2007-10-26</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: sasaki:2007:truth-fmeasure</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>It has been past more than 15 years since the F-measure was 
ﬁrst introduced to evaluation tasks of information extraction technology
 at the Fourth Message Understanding Conference (MUC-4) in 1992. 
Recently, sometimes I see some confusion with the deﬁnition of the 
Fmeasure, which seems to be triggered by lack of background knowledge 
about how the F-measure was derived. Since I was not involved in the 
process of the introduction or device of the F-measure, I might not be 
the best person to explain this but I hope this note would be a little 
help for those who are wondering what the F-measure really is. This 
introduction is devoted to provide brief but suﬃcient information on the
 F-measure.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>22/09/2023 à 17:00:11</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:54:17</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>fscore</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_GEYNFWLW">Sasaki - 2007 - The truth of the F-measure.pdf					</li>
				</ul>
			</li>


			<li id="item_C68AVPHK" class="item book">
			<h2>Thinking, fast and slow.</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Livre</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Daniel Kahneman</td>
					</tr>
					<tr>
					<th>Collection</th>
						<td>Thinking, fast and slow.</td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>New York,  NY,  US</td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>Farrar, Straus and Giroux</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>0-374-27563-7 (Hardcover); 1-4299-6935-0 (PDF); 978-0-374-27563-1 (Hardcover); 978-1-4299-6935-2 (PDF)</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2011</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: kahneman:2011:thinking-fast-slow</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>In the highly anticipated Thinking, Fast and Slow, Kahneman 
takes us on a groundbreaking tour of the mind and explains the two 
systems that drive the way we think. System 1 is fast, intuitive, and 
emotional; System 2 is slower, more deliberative, and more logical. 
Kahneman exposes the extraordinary capabilities—and also the faults and 
biases—of fast thinking, and reveals the pervasive influence of 
intuitive impressions on our thoughts and behavior. The impact of loss 
aversion and overconfidence on corporate strategies, the difficulties of
 predicting what will make us happy in the future, the challenges of 
properly framing risks at work and at home, the profound effect of 
cognitive biases on everything from playing the stock market to planning
 the next vacation—each of these can be understood only by knowing how 
the two systems shape our judgments and decisions. Engaging the reader 
in a lively conversation about how we think, Kahneman reveals where we 
can and cannot trust our intuitions and how we can tap into the benefits
 of slow thinking. He offers practical and enlightening insights into 
how choices are made in both our business and our personal lives—and how
 we can use different techniques to guard against the mental glitches 
that often get us into trouble. Thinking, Fast and Slow will transform 
the way you think about thinking. (PsycINFO Database Record (c) 2016 
APA, all rights reserved)</td>
					</tr>
					<tr>
					<th>Nb de pages</th>
						<td>499</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>07/06/2023 à 15:34:12</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:12:19</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Choice Behavior</li>
					<li>Decision Making</li>
					<li>Intuition</li>
					<li>Judgment</li>
					<li>Cognitive Processes</li>
					<li>Thinking</li>
					<li>Mind</li>
				</ul>
				<h3 class="notes">Notes :</h3>
				<ul class="notes">
					<li id="item_6PNEKDJC">
<div><div data-schema-version="8"><p>NOTE ERWAN</p>
<blockquote>
<ul>
<li>
System 1 = Rapide, Réaction
</li>
<li>
System 2 = Lent, Réflexion
</li>
</ul>
</blockquote>
</div></div>
					</li>
				</ul>
			</li>


			<li id="item_QLLVDGRK" class="item conferencePaper">
			<h2>Towards User-Adaptive Annotation Guidelines</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Stefanie Dipper</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Michael Gotze</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Stavros Skopeteas</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://aclanthology.org/W04-1904">https://aclanthology.org/W04-1904</a></td>
					</tr>
					<tr>
					<th>Maison d’édition</th>
						<td>COLING</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>23–30</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2004-08-28</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: dipper-etal:2004:useradaptive-annotation-guidelines</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>In this paper we address the issue of useradaptivity for 
annotation guidelines. We show that different user groups have different
 needs towards these documents, a fact neglected by most of current 
annotation guidelines. We propose a formal speciﬁcation of the structure
 of annotation guidelines, thus suggesting a minimum set of requirements
 that guidelines should fulﬁll. Finally, we sketch the use of these 
speciﬁcations by exemplary applications, resulting in user-speciﬁc 
guideline representations.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Proceedings of the 5th international workshop on linguistically interpreted corpora</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>05/09/2023 à 13:20:55</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:51:41</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_MUFUET4M">Dipper et al. - Towards User-Adaptive Annotation Guidelines.pdf					</li>
				</ul>
			</li>


			<li id="item_GWY589RW" class="item blogPost">
			<h2>Transformer: A Novel Neural Network Architecture for Language Understanding</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Billet de blog</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Jakob Uszkoreit</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">http://ai.googleblog.com/2017/08/transformer-novel-neural-network.html</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-08-31</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: uszkoreit:2017:transformer-novel-neural</td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>10/06/2020 à 11:11:03</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Posted by Jakob Uszkoreit, Software Engineer, Natural Language
 Understanding   Neural networks, in particular recurrent neural 
networks  (RN...</td>
					</tr>
					<tr>
					<th>Titre du blog</th>
						<td>Google AI Blog</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>Transformer</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>10/06/2020 à 11:11:03</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:09:30</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Computation and Language</li>
					<li>Transformers</li>
					<li>Attention</li>
					<li>Encoder</li>
					<li>Decoder</li>
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_ZY5F5X6A">Uszkoreit - 2017 - Transformer A Novel Neural Network Architecture f.html					</li>
				</ul>
				<h3 class="related">Connexe</h3>
				<ul class="related">
					<li id="item_IJGCWIVB">Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing</li>
				</ul>
			</li>


			<li id="item_CQU6FCPC" class="item conferencePaper">
			<h2>Un turc mécanique pour les ressources linguistiques : critique de la myriadisation du travail parcellisé</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Benoît Sagot</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Karen Fort</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gilles Adda</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Joseph Mariani</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Bernard Lang</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://inria.hal.science/inria-00617067">https://inria.hal.science/inria-00617067</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Montpellier, France</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2011-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: sagot-etal:2011:turc-mecanique-pour</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Cet article est une prise de position concernant les 
plate-formes de type Amazon Mechanical Turk, dont l'utilisation est en 
plein essor depuis quelques années dans le traitement automatique des 
langues. Ces plateformes de travail en ligne permettent, selon le 
discours qui prévaut dans les articles du domaine, de faire développer 
toutes sortes de ressources linguistiques de qualité, pour un prix 
imbattable et en un temps très réduit, par des gens pour qui il s'agit 
d'un passe-temps. Nous allons ici démontrer que la situation est loin 
d'être aussi idéale, que ce soit sur le plan de la qualité, du prix, du 
statut des travailleurs ou de l'éthique. Nous rappellerons ensuite les 
solutions alternatives déjà existantes ou proposées. Notre but est ici 
double : informer les chercheurs, aﬁn qu'ils fassent leur choix en toute
 connaissance de cause, et proposer des solutions pratiques et 
organisationnelles pour améliorer le développement de nouvelles 
ressources linguistiques en limitant les risques de dérives éthiques et 
légales, sans que cela se fasse au prix de leur coût ou de leur qualité.</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>TALN'2011 - traitement automatique des langues naturelles</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>29/09/2023 à 15:08:29</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>29/10/2023 à 09:45:07</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Amazon Mechanical Turk</li>
					<li>Language resources</li>
					<li>Ressources linguistiques</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_X5MRGBD3">Sagot et al. - 2011 - Un turc mécanique pour les ressources linguistique.pdf					</li>
				</ul>
			</li>


			<li id="item_Z67494BL" class="item journalArticle">
			<h2>Using TF-IDF to Determine Word Relevance in Document Queries</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Juan Ramos</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Proceedings of the first instructional conference on machine learning</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2003</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: ramos:2003:using-tfidf-determine</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>In this paper, we examine the results of applying Term 
Frequency Inverse Document Frequency (TF-IDF) to determine what words in
 a corpus of documents might be more favorable to use in a query. As the
 term implies, TF-IDF calculates values for each word in a document 
through an inverse proportion of the frequency of the word in a 
particular document to the percentage of documents the word appears in. 
Words with high TF-IDF numbers imply a strong relationship with the 
document they appear in, suggesting that if that word were to appear in a
 query, the document could be of interest to the user. We provide 
evidence that this simple algorithm efficiently categorizes relevant 
words that can enhance query retrieval.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>26/07/2023 à 13:41:44</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>26/07/2023 à 13:46:31</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_Q7PCWF7S">Ramos - Using TF-IDF to Determine Word Relevance in Docume.pdf					</li>
				</ul>
			</li>


			<li id="item_897RMT9M" class="item journalArticle">
			<h2>V-Measure: A Conditional Entropy-Based External Cluster Evaluation Measure</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Andrew Rosenberg</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Julia Hirschberg</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2007</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: rosenberg-hirschberg:2007:vmeasure-conditional-entropybased</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>We present V-measure, an external entropybased cluster 
evaluation measure. Vmeasure provides an elegant solution to many 
problems that affect previously deﬁned cluster evaluation measures 
including 1) dependence on clustering algorithm or data set, 2) the 
“problem of matching”, where the clustering of only a portion of data 
points are evaluated and 3) accurate evaluation and combination of two 
desirable aspects of clustering, homogeneity and completeness. We 
compare V-measure to a number of popular cluster evaluation measures and
 demonstrate that it satisﬁes several desirable properties of clustering
 solutions, using simulated clustering results. Finally, we use 
V-measure to evaluate two clustering tasks: document clustering and 
pitch accent type clustering.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>16/02/2023 à 09:53:02</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/07/2023 à 19:11:47</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*LU/IMPLÉMENTÉ</li>
					<li>*CITATION</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_HK8LKIDM">Rosenberg et Hirschberg - V-Measure A Conditional Entropy-Based External Cl.pdf					</li>
				</ul>
			</li>


			<li id="item_78BGK7C3" class="item conferencePaper">
			<h2>Vers une méthodologie d'annotation des entités nommées en corpus ?</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de colloque</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Karen Fort</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Maud Ehrmann</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Adeline Nazarenko</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.science/hal-00402321">https://hal.science/hal-00402321</a></td>
					</tr>
					<tr>
					<th>Lieu</th>
						<td>Senlis, France</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2009-06</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: fort-etal:2009:vers-methodologie-annotation</td>
					</tr>
					<tr>
					<th>Titre des actes</th>
						<td>Traitement automatique des langues naturelles 2009</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 17:32:21</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:55:34</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Annotation</li>
					<li>Named entities extraction</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_UAD26IZX">Fort et al. - 2009 - Vers une méthodologie d'annotation des entités nom.pdf					</li>
				</ul>
			</li>


			<li id="item_PRXW89RG" class="item journalArticle">
			<h2>What Determines Inter-Coder Agreement in Manual Annotations? A Meta-Analytic Investigation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Petra Saskia Bayerl</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Karsten Ingmar Paul</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://direct.mit.edu/coli/article/37/4/699-725/2129">https://direct.mit.edu/coli/article/37/4/699-725/2129</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>37</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>699-725</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Computational Linguistics</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0891-2017, 1530-9312</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2011-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: bayerl-paul:2011:what-determines-intercoder</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Computational Linguistics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1162/COLI_a_00074">10.1162/COLI_a_00074</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>31/08/2023 à 15:32:26</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Recent discussions of annotator agreement have mostly centered
 around its calculation and interpretation, and the correct choice of 
indices. Although these discussions are important, they only consider 
the “back-end” of the story, namely, what to do once the data are 
collected. Just as important in our opinion is to know how agreement is 
reached in the first place and what factors influence coder agreement as
 part of the annotation process or setting, as this knowledge can 
provide concrete guidelines for the planning and set-up of annotation 
projects. To investigate whether there are factors that consistently 
impact annotator agreement we conducted a meta-analytic investigation of
 annotation studies reporting agreement percentages. Our meta-analysis 
synthesized factors reported in 96 annotation studies from three domains
 (word-sense disambiguation, prosodic transcriptions, and phonetic 
transcriptions) and was based on a total of 346 agreement indices. Our 
analysis identified seven factors that influence reported agreement 
values: annotation domain, number of categories in a coding scheme, 
number of annotators in a project, whether annotators received training,
 the intensity of annotator training, the annotation purpose, and the 
method used for the calculation of percentage agreements. Based on our 
results we develop practical recommendations for the assessment, 
interpretation, calculation, and reporting of coder agreement. We also 
briefly discuss theoretical implications for the concept of annotation 
quality.</td>
					</tr>
					<tr>
					<th>Titre abrégé</th>
						<td>What Determines Inter-Coder Agreement in Manual Annotations?</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>31/08/2023 à 15:32:26</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 09:05:20</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Biais</li>
					<li>Différences</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_VF72XVM7">Bayerl et Paul - 2011 - What Determines Inter-Coder Agreement in Manual An.pdf					</li>
				</ul>
			</li>


			<li id="item_2PI7HRU3" class="item journalArticle">
			<h2>Who belongs in the family?</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Robert L. Thorndike</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/BF02289263">http://link.springer.com/10.1007/BF02289263</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>18</td>
					</tr>
					<tr>
					<th>Numéro</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>267-276</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Psychometrika</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0033-3123, 1860-0980</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>1953-12</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: thorndike:1953:who-belongs-family</td>
					</tr>
					<tr>
					<th>Abrév. de revue</th>
						<td>Psychometrika</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/BF02289263">10.1007/BF02289263</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>06/07/2023 à 16:32:10</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>06/07/2023 à 16:32:10</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 08:48:40</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>Elbow</li>
				</ul>
			</li>


			<li id="item_9PZGV3VY" class="item dataset">
			<h2>Zenodo</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Dataset</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Re3data.Org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.re3data.org/repository/r3d100010468">https://www.re3data.org/repository/r3d100010468</a></td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2013</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: re3data.org:2013:zenodo</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.17616/R3QP53">10.17616/R3QP53</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>04/10/2023 à 19:28:06</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Langue</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>ZENODO builds and operates a simple and innovative service 
that enables researchers, scientists, EU projects and institutions to 
share and showcase multidisciplinary research results (data and 
publications) that are not part of the existing institutional or 
subject-based repositories of the research communities. ZENODO enables 
researchers, scientists, EU projects and institutions to: easily share 
the long tail of small research results in a wide variety of formats 
including text, spreadsheets, audio, video, and images across all fields
 of science. display their research results and get credited by making 
the research results citable and integrate them into existing reporting 
lines to funding agencies like the European Commission. easily access 
and reuse shared research results.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>04/10/2023 à 19:28:06</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>05/10/2023 à 09:23:07</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>*CITATION</li>
					<li>1 Humanities and Social Sciences</li>
					<li>2 Life Sciences</li>
					<li>3 Natural Sciences</li>
					<li>4 Engineering Sciences</li>
				</ul>
			</li>


			<li id="item_8FYS7KVJ" class="item journalArticle">
			<h2>Zero-Shot Text-to-Image Generation</h2>
				<table>
					<tbody><tr>
						<th>Type de document</th>
						<td>Article de revue</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Aditya Ramesh</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mikhail Pavlov</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Gabriel Goh</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Scott Gray</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Chelsea Voss</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Alec Radford</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Mark Chen</td>
					</tr>
					<tr>
						<th class="author">Auteur</th>
						<td>Ilya Sutskever</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://arxiv.org/abs/2102.12092">https://arxiv.org/abs/2102.12092</a></td>
					</tr>
					<tr>
					<th>Autorisations</th>
						<td>Creative Commons Attribution 4.0 International</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ArXiv preprint</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>Citation Key: ramesh-etal:2021:zeroshot-texttoimage-generation</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/ARXIV.2102.12092">10.48550/ARXIV.2102.12092</a></td>
					</tr>
					<tr>
					<th>Consulté le</th>
						<td>25/07/2023 à 10:54:02</td>
					</tr>
					<tr>
					<th>Catalogue de bibl.</th>
						<td>DOI.org (Datacite)</td>
					</tr>
					<tr>
					<th>Résumé</th>
						<td>Text-to-image generation has traditionally focused on finding 
better modeling assumptions for training on a fixed dataset. These 
assumptions might involve complex architectures, auxiliary losses, or 
side information such as object part labels or segmentation masks 
supplied during training. We describe a simple approach for this task 
based on a transformer that autoregressively models the text and image 
tokens as a single stream of data. With sufficient data and scale, our 
approach is competitive with previous domain-specific models when 
evaluated in a zero-shot fashion.</td>
					</tr>
					<tr>
					<th>Date d'ajout</th>
						<td>25/07/2023 à 10:54:02</td>
					</tr>
					<tr>
					<th>Modifié le</th>
						<td>06/10/2023 à 15:33:02</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Marqueurs :</h3>
				<ul class="tags">
					<li>Machine learning</li>
					<li>*CITATION</li>
					<li>FOS: Computer and information sciences</li>
					<li>Computer Vision and Pattern Recognition</li>
				</ul>
				<h3 class="attachments">Pièces jointes</h3>
				<ul class="attachments">
					<li id="item_BAFHIAGD">Ramesh et al. - 2021 - Zero-Shot Text-to-Image Generation.pdf					</li>
				</ul>
			</li>

		</ul>
	
</body></html>