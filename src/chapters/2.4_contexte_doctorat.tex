\section[
	Contexte du doctorat: comment assister la conception d'une base d'apprentissage ?
]{
	Contexte du doctorat: comment assister la conception d'une base d'apprentissage pour un agent conversationnel bancaire en français ?
}
\label{section:2.4-CONTEXTE-DOCTORAT}

	% Introduction: Domaine d'application au NLP / chatbot.
	Durant ce doctorat, nous nous sommes intéressé à la \textbf{conception d'assistants conversationnels} (\textit{chatbot}).
	En effet, leur utilisation en entreprise est de plus en plus courante (\cite{goasduff:2019:chatbots-will-appeal}, \cite{costello-lodolce:2022:gartner-predicts-chatbots}), notamment pour l'automatisation de certaines tâches simples et l'accès aux informations de bases documentaires.
	La popularité de ces assistants vient entre autres de la possibilité de dialoguer directement avec la machine grâce à des requêtes exprimées en langage naturel, offrant ainsi un gain de confort, de disponibilité et de performance.
	
	% Comment créer un chatbot ?
	Par expérience, nous avons constaté que plusieurs critères sont nécessaires pour déployer un assistant conversationnel dans un contexte industriel :
	\begin{itemize}
		\item Il faut être capable de gérer le dialogue entre l'utilisateur et l'assistant (\textit{comprendre la requête initiale, demander ou confirmer des informations complémentaires, ...}) ;
		\item Il faut être capable de contrôler le contenu des réponses de l'assistant et de s'assurer de ses performances (\textit{répondre ou agir de manière adaptée, ne pas fournir de réponses contenant des informations confidentielles, ne pas répondre de manière indécente, ...}) ;
		\item Il est possible de donner à l'assistant l'accès à certaines ressources (\textit{lire et écrire en base de données, exécuter des programmes tiers, ...}) mais il faut alors en garantir un certain niveau de sécurité (\textit{se prémunir contre les requêtes malveillantes et les erreurs de manipulations}).
	\end{itemize}
	
	Pour toute ces raisons, \textbf{l'architecture traditionnelle des \textit{chatbot} est plutôt orientée par tâches} (\textit{task-oriented}), c'est-à-dire qu'elle manipule une abstraction du dialogue en intentions \footnote{
		Intention de dialogue : en traitement automatique du langage naturel, une intention représente la compréhension de la demande formulée par un utilisateur au cours de la conversation.
		Elle est généralement définie par le verbe d'action de la demande, et est représentée par une étiquette.
		Par exemple, les requêtes \textguillemets{\textit{joue moi du jazz s'il te plaît !}} ou \textguillemets{\textit{peux-tu lancer une playlist de Noël sur l'enceinte du salon !}} peut être modélisées par l'intention \texttt{jouer\_musique}.
		Pour plus d'information, consulter l'\textsc{Annexe~\ref{annex:B-ANNEXE-CHATBOTS}}.
	} et gère un paramétrage des réponses dépendant des intentions détectées (voir \cite{chen-etal:2017:survey-dialogue-systems} et \cite{brabra-etal:2022:dialogue-management-conversational}).
	
	\begin{leftBarInformation}
		L'\textsc{Annexe~\ref{annex:B-ANNEXE-CHATBOTS}} détaille plus amplement les différences entre les assistants \textit{task-oriented} (approches symboliques) et les assistants \textit{chat-oriented} (approches numériques ou génératives).
		Cette annexe se base notamment sur une revue des architectures de conceptions publiée par \cite{chen-etal:2017:survey-dialogue-systems}.
	\end{leftBarInformation}
	
	
	% Conception difficile, besoin d'experts !
	Néanmoins, l'élaboration de tels assistants reste un \textbf{défi difficile à relever dans le monde industriel} :
	\begin{itemize}
		\item Le traitement du langage en tant que tel est un problème complexe : il faut traiter une grande variété de bruits et d'ambiguïtés de dialogue en plus d'un vocabulaire souvent spécifique au domaine de l'assistant (voir les problèmes de bruits et de représentativité en \textsc{Section~\ref{section:2.3.1-DEFIS-ANNOTATION-ASPECT-DONNEES}}) ;
		\item La base d'apprentissage ainsi que les réponses de l'assistant peuvent contenir des données privées ou confidentielles : ainsi, il y a peu de données réutilisables à partir de sources publiques, et de fortes pressions sont exercées sur le contrôle du comportement du \textit{chatbot} (voir les problèmes de droits d'utilisation et de confidentialité en \textsc{Section~\ref{section:2.3.1-DEFIS-ANNOTATION-ASPECT-DONNEES}}) ;
		\item L'assistant doit parfois pouvoir manipuler un grand nombre de cas d'usages : sa modélisation peut alors représenter des dizaines d'intentions pour lesquelles des centaines de branches de dialogues peuvent être paramétrées, introduisant ainsi une grande complexité aux tâches de modélisation et d'annotation de sa base d'apprentissage (voir \textsc{Section~\ref{section:2.3.2-DEFIS-ANNOTATION-ASPECT-COMPLEXITE}}) ;
	\end{itemize}
	
	Pour surmonter ces difficultés, les entreprises font alors intervenir des experts aux compétences diverses (voir \textsc{Section~\ref{section:2.2.2-ORGANISATION-ANNOTATION-ACTEURS}}), notamment des experts analytiques pour concevoir une modélisation stable des textes en intentions, puis des experts métiers pour valider la pertinence de la modélisation proposée et annoter les données suivant cette modélisation.
	
	
	% Ces experts doivent résoudre les différences de comportement dus à la complexité de tâche.
	Or au vu de la complexité d'un tel projet, des différences de comportements entre opérateurs, telles que des erreurs d'annotation ou des divergences d'opinion, sont inévitables (voir \textsc{Section~\ref{section:2.3.3-DEFIS-ANNOTATION-ASPECT-HUMAIN}}).
	Il est alors nécessaire de former les experts métiers aux tâches d'annotation et à certaines tâches d'analyse afin d'encadrer les discussions autour de certaines différences de comportements pouvant mener à des remises en cause de la modélisation abstraite de textes en intentions (voir étape \textit{Revise} du cyle \texttt{MATTER}, \textsc{Section~\ref{section:2.2.1.A-ORGANISATION-ANNOTATION-ETAPES-CLES-MODELIZE-ANNOTATE}}).
	Au final, \textbf{cette organisation devient très coûteuse} car elle demande des formations analytiques à des experts métiers, nécessite l'organisation d'ateliers de modélisation en mode essai-erreur pour trouver une base d'apprentissage stable et pertinente, et fait intervenir des experts métiers sur une abstraction de leurs connaissances du quotidien.
	
	% Exemples.
	\begin{leftBarExamples}
		Au cours de ce doctorat, nous avons entre autres travaillé sur des assistants conversationnels à destination de conseillers bancaires et de leur clients.
		Ces assistants doivent traiter une large variété de sujets (banque, assurance, finance, ...) et peuvent donc rapidement contenir une centaine d'intentions pour plus d'un millier de branches de dialogue.
		La conception de la base d'apprentissage de tels assistants représente ainsi un réel défi d'organisation, sur plusieurs semaines, notamment pour faire intervenir des experts de la banque-assurance dans un projet d'intelligence artificielle, domaine dans lequel ils n'ont pas ou peu de connaissances...
	\end{leftBarExamples}
	
	
	% Objectif de ce doctorat : assister la phase de modélisation d'une base d'apprentissage.
	Cependant, il pourrait être intéressant de remettre en question cette organisation des projets d'annotation où les experts métiers sont interrogés sur des compétences qui ne sont pas les leurs.
	Ainsi, dans le but de trouver une solution à cette problématique, \textbf{nous nous sommes alors posé la question suivante} :
	\begin{leftBarImportantGreen}
		\begin{center}
		\textbf{
			Comment assister la phase de modélisation de textes en intentions \\
			pour concevoir la base d'apprentissage d'un assistant conversationnel \\
			en impliquant des experts métiers pour leurs vraies compétences \\
			et en leur demandant un minimum de bagages analytiques ou techniques ?
		}
		\end{center}
	\end{leftBarImportantGreen}
	
	
	% Transition : idée d'un \texttt{clustering interactif} !
	\begin{leftBarIdea}
		Pour répondre à cette problématique, nous nous sommes intéressé à trois concepts intéressants de la littérature :
		\begin{itemize}
			\item aux techniques de \textit{clustering}, permettant de déléguer à la machine la tâche de modélisation grâce à une segmentation des données sur la base de leurs similarités (\cite{xu-tian:2015:comprehensive-survey-clustering}) ;
			\item à l'annotation de contraintes binaires sur les données, permettant de corriger le fonctionnement d'un algorithme de \textit{clustering} en y introduisant de la connaissance métier (\cite{lampert-etal:2018:constrained-distance-based}) ;
			\item aux techniques d'apprentissage actif, favorisant les interactions entre l'Homme et la Machine pour atteindre un objectif (\cite{settles:2010:active-learning-literature}).
		\end{itemize}
		Ces trois concepts seront détaillés au début du chapitre suivant, et seront assemblés dans le but de concevoir une nouvelle méthode d'annotation basée sur un \texttt{Clustering Interactif}.
	\end{leftBarIdea}