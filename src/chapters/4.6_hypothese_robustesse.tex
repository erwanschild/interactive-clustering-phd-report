\section{Évaluation de l'hypothèse de robustesse}
\label{section:4.6-HYPOTHESE-ROBUSTESSE}


	%%% Introduction / Transition.
	Dans les précédentes études, nous avons presque toujours analysé le \textit{clustering} interactif en supposant que l'annotateur connaît parfaitement le domaine traité par le jeu de données et qu'il est capable de caractériser sans ambiguïté la similitude entre deux données issues de cet ensemble.
	Bien entendu, cette hypothèse forte n'est pas toujours vérifiée en situation réelle : l'interprétation du langage peut contenir certaines ambiguïtés, l'opérateur peut faire des erreurs d’inattention, et deux annotateurs peuvent avoir des avis contraire sur un même sujet.
	Dans cette section, nous nous intéresserons ainsi à la robustesse de notre méthode en présence d'erreurs d’annotation et d'incohérence dans les contraintes.
	Pour cela, nous aimerions donc vérifier l'hypothèse suivante :
	
	%%% Formulation des hypothèses:
	\begin{tcolorbox}[
		title=\faVial~\textbf{Hypothèse de robustesse}~\faVial,
		colback=colorTcolorboxHypothesis!15,
		colframe=colorTcolorboxHypothesis!75,
		width=\linewidth
	]
		% Hypothèse.
		« \textbf{
			Il est possible d'\textbf{estimer l'influence d'une différence d'annotation} lors d'une méthodologie d'annotation basée sur le \textit{clustering} interactif.
		} » \\
		
		% Figure.
		La \textsc{Figure~\ref{figure:4.6-HYPOTHESE-ROBUSTESSE}} illustre cette hypothèse et l'espoir de estimer l'impact d'erreurs ou de différences d'annotations sur le nombre d'itérations de la méthode.
		%
		\begin{figure}[H]  % keep [H] to be in the tcolorbox.
			\centering
			\includegraphics[width=0.95\textwidth]{figures/hypotheses-06-robustesse}
			\caption{Illustration des études réalisées sur le \textit{clustering} interactif (\textit{étape 6/6}) en schématisant l'évolution de la pertinence (\textit{valeur métier évaluée par l'expert et exprimé en nombre de clusters}) d'une base d'apprentissage en cours de construction en fonction du coût temporel de la méthode (\textit{temps nécessaire à l'expert métier et à la machine}), ainsi que les marges d'erreurs représentant l'impact de différences d'annotation sur le nombre d'itérations nécessaire à la méthode.}
			\label{figure:4.6-HYPOTHESE-ROBUSTESSE}
		\end{figure}

	\end{tcolorbox}
		
	% Résumé de l'étude.
	Afin de vérifier cette hypothèse, nous analysons l'impact d'une différence d'annotation sur les performances en simulant l'ajout de contraintes erronées, et nous discuterons de l'intérêt de prédire ou corriger les conflits d'annotation (cf. \textsc{Section~\ref{section:4.6.1-ETUDE-ROBUSTESSE-SIMULATION-ERREURS-ANNOTATION}}).
	Nous présenterons aussi les résultats de scores inter-annotateurs obtenus lors d'une expériences d'annotations de contraintes avec plusieurs annotateurs (cf. \textsc{Section~\ref{table:4.6.2-ETUDE-ROBUSTESSE-CALCUL-SCORE-INTER-ANNOTATEURS}}).
	
	
	%%%
	%%% Subsection 4.6.1: Étude de simulation d'erreurs d'annotations
	%%%
	\subsection{Étude de simulation d'erreurs d'annotations}
	\label{section:4.6.1-ETUDE-ROBUSTESSE-SIMULATION-ERREURS-ANNOTATION}
		
		% Objectif de l'expérience.
		\todo[inline]{A REDIGER: objectif de l'expérience}
	
		%%% Protocole expérimental.
		\subsubsection{Protocole expérimental}
			\todo[inline]{A REDIGER}
			% Axiome.
			% Pseudo-code.
			% Détails de l'expérience.
			
			
			% Référence scripts.
			\begin{leftBarInformation}
				Les scripts de l'expérience, réalisés avec des \textit{notebooks} Python (\cite{van-rossum-drake:2009:python-reference-manual}), sont disponibles dans un dossier dédié de~\cite{schild:2021:cognitivefactory-interactiveclusteringcomparativestudy}.
			\end{leftBarInformation}

		%%% Résultats
		\subsubsection{Résultats obtenus}
			\todo[inline]{A REDIGER}
		
			% Description statistiques.
			\todo[inline]{A REDIGER: Avec et sans corrections, avec sans sans closest.}
			
			% Figure.
			%
			\begin{figure}[!htb]
				\centering
				\includegraphics[width=0.95\textwidth]{figures/etude-erreur-simulation-impact}
				\caption{Évolutions de la moyenne de la \texttt{v-measure} entre un résultat obtenu et la vérité terrain en fonction du nombre d'itération de la méthode de \textit{clustering} interactif, moyenne prenant en compte différents taux d'erreurs d'annotations entre $0$ et $50$\%.}
				\label{figure:4.6.1-ETUDE-ROBUSTESSE-SIMULATION-ERREURS-ANNOTATION}
			\end{figure}

		%%% Discussion
		\subsubsection{Discussion}
			\todo[inline]{A REDIGER}
		
			% Remaques expérience utilisateur.
			\todo[inline]{A REDIGER: Super important de corriger}
			
			% Conclusions et suggestion.
	
	
	%%%
	%%% Subsection 4.6.2: Étude du score inter-annotateurs pour annoter des contraintes en situation réelle
	%%%
	\subsection{Étude du score inter-annotateurs pour annoter des contraintes en situation réelle}
	\label{section:4.6.2-ETUDE-ROBUSTESSE-CALCUL-SCORE-INTER-ANNOTATEURS}
		
		% Objectif de l'expérience.
		\todo[inline]{A REDIGER: objectif de l'expérience}
	
		%%% Protocole expérimental.
		\subsubsection{Protocole expérimental}
			\todo[inline]{A REDIGER}
			% Axiome.
			% Pseudo-code.
			% Détails de l'expérience.
			% Référence scripts.
	
		%%% Résultats
		\subsubsection{Résultats obtenus}
			\todo[inline]{A REDIGER}
		
			% Description statistiques.
			La \textsc{Table~\ref{table:4.6.2-ETUDE-ROBUSTESSE-CALCUL-SCORE-INTER-ANNOTATEURS}} expose les scores inter-annotateurs sur les $3$ opérateurs et le réviseur de cette expérience, ainsi que l'accord avec la vérité terrain.
			Le score d'accord moyen avec la vérité terrain est de $0.86$ (écart-type: $0.01$), et le score inter-annotateurs moyen (sans le réviseur) est de $0.84$ (écart-type: $0.02$).
			
			\begin{table}[!htb]
				\begin{center}
				\begin{tabular}{|c|r|r|r|r|}
				
					\hline
					% ENTETE DU TABLEAU
					
						& \multicolumn{1}{c|}{\shortstack[c]{
							1 (Relecteur)
						}}
						& \multicolumn{1}{c|}{\shortstack[c]{
							7 (Annotateur)
						}}
						& \multicolumn{1}{c|}{\shortstack[c]{
							9 (Annotateur)
						}}
						& \multicolumn{1}{c|}{\shortstack[c]{
							12 (Annotateur)
						}}
						\tabularnewline
						\hline

					% Vérité terrain
					\multicolumn{1}{|c|}{\shortstack[c]{
						Vérité terrain
					}}
						& $0.95$
						& $0.86$
						& $0.84$
						& $0.87$
						\tabularnewline
						\hline

					% Vérité terrain
					\multicolumn{1}{|c|}{\shortstack[c]{
						1 (Relecteur)
					}}
						&
						& $0.91$
						& $0.86$
						& $0.89$
						\tabularnewline
						\hline

					% Vérité terrain
					\multicolumn{1}{|c|}{\shortstack[c]{
						7 (Annotateur)
					}}
						&
						&
						& $0.86$
						& $0.85$
						\tabularnewline
						\hline

					% Vérité terrain
					\multicolumn{1}{|c|}{\shortstack[c]{
						9 (Annotateur)
					}}
						&
						&
						&
						& $0.80$
						\tabularnewline
						\hline
					
				\end{tabular}
				\end{center}
				\caption{Score d'accord inter-annotateurs.
				}
				\label{table:4.6.2-ETUDE-ROBUSTESSE-CALCUL-SCORE-INTER-ANNOTATEURS}
			\end{table}
			
			% Note.
			\begin{leftBarInformation}
				Dans une autres expérience, où $14$ opérateurs devaient annoter une base de $1~000$ contraintes aléatoires, nous obtenons un accord moyen avec la vérité terrain de $0.93$ (écart-type: $0.02$) et un score inter-annotateurs moyen de $0.91$ (écart-type: $0.03$).
				Toutefois, nous ne mettons pas en avant ces résultats car le lot de contraintes à annoté est déséquilibré à cause de l'utilisation de l'échantillonnage aléatoire ($932$ \texttt{CANNOT-LINK}, $68$ \texttt{MUST-LINK}).
			\end{leftBarInformation}
	
		%%% Discussion
		\subsubsection{Discussion}
			\todo[inline]{A REDIGER}
		
			% Remaques expérience utilisateur.
			
			% Conclusions et suggestion.