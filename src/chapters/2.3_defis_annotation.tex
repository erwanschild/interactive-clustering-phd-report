\section{Aperçu des nombreux défis de l'annotation}
\label{section:2.3-DEFIS-ANNOTATION}

	%%%
	%%% Introduction: annoncer la complexité due (1) aux données (2) à la tâche et (3) aux humains.
	%%%
	
	Comme nous avons pu l'apercevoir dans les sections précédentes, le cycle d'annotation recèle de nombreuses zones d'ombres pouvant introduire des complications dans la conception d'une base d'apprentissage (\cite{baledent:2022:complexite-annotation-manuelle}).
	Pour aborder cette partie, nous verrons :
	\begin{itemize}
		\item qu'il y a une forte pression sur la \textbf{qualité des données} devant constituer le corpus d'entraînement (cf. \textsc{Section~\ref{section:2.3.1-DEFIS-ANNOTATION-ASPECT-DONNEES}}) ;
		\item que ce standard de qualité entretient une \textbf{complexité inhérente} aux étapes de modélisation et d'annotation (cf. \textsc{Section~\ref{section:2.3.2-DEFIS-ANNOTATION-ASPECT-COMPLEXITE}}) ; et
		\item que cette complexité provoque des \textbf{différences de comportements} chez les annotateurs (cf. \textsc{Section~\ref{section:2.3.3-DEFIS-ANNOTATION-ASPECT-HUMAIN}}).
	\end{itemize}
	En détaillant chacun de ces trois points, nous discuterons d'un ensemble de techniques et bonnes pratiques mises en avant dans la littérature pour limiter les désagréments d'un projet d'annotation.
	Nous identifierons aussi les freins récurrents pouvant intervenir dans les mises en application industrielles.
	
	
	%%%
	%%% Subsection 2.3.1: Défis concernant le besoin de qualité des données.
	%%%
	\subsection{Défis concernant le besoin de qualité des données}
	\label{section:2.3.1-DEFIS-ANNOTATION-ASPECT-DONNEES}
	
		% Introduction: Machine Learning = reproduire par l'exemple.
		Comme nous l'avons défini en \textsc{Section~\ref{section:2.1.1.A-PRESENTATION-ANNOTATION-DEFINITION-MACHINE-LEARNING}}, l'\textguillemets{\texttt{apprentissage automatique}} regroupe un ensemble de techniques dont l'objectif est de reproduire une tâche \textbf{par l'exemple} : il est donc normal de porter une attention particulière aux données utilisées, car la qualité du modèle de \textit{Machine Learning} va fortement dépendre de la qualité de sa base d'apprentissage.
		Nous allons ici détailler trois défis actuels concernant cette création d'un jeu de données.
		
		
		%%% 2.3.1.A. Problèmes de représentativité.
		\subsubsection{Problèmes de représentativité}
		\label{section:2.3.1.A-DEFIS-ANNOTATION-ASPECT-DONNEES-REPRESENTATIVITE}
			
			% Introduction : Une collecte doit être "représentative" du problème.
			La phase de collecte de données est une étape importante du projet d'annotation.
			Malheureusement, la littérature scientifique associée à cette tâche est assez légère alors que c'est précisément à ce moment que ce joue une caractéristique cruciale de la future base d'apprentissage : la \textbf{représentativité} du phénomène à modéliser.
			
			% Définir la représentativité à partir de la méthode de l'échantillon.
			Cette notion est assez ambiguë, notamment car le terme technique \textguillemets{représentatif}fait écho à un mot de la vie courante qui peut avoir plusieurs sens.
			Dans \cite{kruskal-mosteller:1979:representative-sampling-nonscientific} et \cite{clemmensen-kjaersgaard:2022:data-representativity-machine}, plusieurs usages communs de ce terme sont recensés :
			\begin{itemize}
				\item \textguillemets{\textit{assertive claim}} :
				l'opérateur déclare que ses données sont représentatives du problème sans apporter d'arguments. Bien entendu, cette option est à bannir car elle n'apporte aucune information et peut cacher des vices de conception du modèle ;
				\item \textguillemets{\textit{absence or presence of selective force}} :
				la représentativité du phénomène est supposée en sélectionnant des données de \textbf{manière aléatoire} et en limitant le nombre de critères de sélection à ceux nécessaires pour l'étude réalisée ; 
				\item \textguillemets{\textit{miniature}} :
				aussi appelée \textbf{sélection stratifiée}, cette approche consiste à dire qu'un échantillon est représentatif d'un phénomène si la proportion de chacune de ses parties y est respectée
				(\textit{par exemple, un sondage peut respecter la répartition des tranches d'âge d'une population}) ;
				\item \textguillemets{\textit{typical/ideal case}} :
				cette définition consiste à représenter chaque partie du phénomène par un \textbf{exemple emblématique} ou un \textbf{exemple moyen}
				(\textit{par exemple, nous pouvons illustrer l'univers de la bande dessinée française par un numéro de la saga \texttt{Astérix \& Obélix}}) ;
				\item \textguillemets{\textit{population coverage}} :
				ici, la représentativité est associée à la présence \textbf{exhaustive} de l'ensemble des caractéristiques importantes du phénomène avec au moins un exemple par caractéristique
				(\textit{par exemple, dans l'arche de Noé, il devait y avoir au moins un couple d'animaux de chaque espèce}).
			\end{itemize}
			
			% Définir la représentativité à partir de la méthode d'échantillonnage.
			Pour compléter ces définitions, \cite{kruskal-mosteller:1979:representative-sampling-ii} insistent sur le besoin de \textbf{définir avec précision la méthode d'\textit{échantillonnage}} plutôt que l'\textit{échantillon} lui-même : en effet, il est important de caractériser le phénomène à modéliser, de définir l'objectif de la collecte de données et de détailler comment cette collecte va être réalisée.
			\cite{clemmensen-kjaersgaard:2022:data-representativity-machine} introduisent à leur tour trois mesures pour aider à caractériser une collecte : la \textit{réflexion} (est-ce l'échantillon respecte la distribution de la population ?), la \textit{couverture} (est-ce que l'échantillon illustre la diversité de la population ?) et la \textit{présence de représentants} (est-ce que l'échantillon contient les exemples emblématiques de la population ?).
			De telles informations sont essentielles pour pouvoir juger la valeur d'un échantillon par rapport à un cas d'usage et déterminer s'il est réutilisable pour une autre application.
			%
			\begin{leftBarExamples}
				% Cas d'usage : classification d'état.
				Illustrons nos propos avec la classification de l'état d'une bande dessinée à partir d'une photo (voir \textsc{Section~\ref{section:2.1.2.B-PRESENTATION-ANNOTATION-EXEMPLES-CLASSIFICATION}}).
				Afin de représenter correctement le cas d'usage, nous pourrions collecter des exemples de \texttt{BD} couvrant l'ensemble des dégradations fréquemment identifiées par les libraires (couvertures froissées, pages déchirées, couleurs délavées, ...) et les intégrer de manière proportionnelle dans la base d'apprentissage.
				Nous pourrions aussi nous assurer de la présence de cas emblématiques permettant de catégoriser les \texttt{BD} en "\texttt{Mauvais état}", "\texttt{Bon état}", "\texttt{Très bon état}", "\texttt{Neuf}".
				
				% Autre cas d'usage : pas représentatif.
				Toutefois, cette base d'apprentissage ne serait peut-être plus représentative si nous voulions détecter la langue de la bande dessinée : il conviendrait alors de vérifier la répartition par langue en revoyant les trois mesures précédemment mentionnées.
			\end{leftBarExamples}
			
			% Besoin de beaucoup d'exemples.
			La description d'un phénomène reste cependant une \textbf{tâche difficile}, notamment lorsque que celui-ci possède un ensemble vaste et abstrait de caractéristiques à décrire.
			Nous comptons généralement sur la loi des grands nombres pour espérer dresser un portrait fidèle du phénomène, mais cela impose parfois de traiter d'\textbf{immenses quantités de données}.
			%
			\begin{leftBarExamples}
				% Exemple de la variabilité du langage.
				Considérons le traitement du langage : le vocabulaire employé peut concerner des dizaines de milliers de mots ; il existe des variantes régionales et divers jargons techniques ; certains termes peuvent avoir plusieurs sens et des expressions peuvent dépendre de leur contexte (comme l'humour ou les critiques).
				Pour représenter ces spécificités (listées de manière non exhaustive), une base d'apprentissage devra contenir de nombreux exemples afin de capturer les différents aspects du langage à traiter.
				Nous pouvons citer par exemple \texttt{MLSUM: The Multilingual Summarization Corpus} (\cite{scialom-etal:2020:mlsum-multilingual-summarization}), une base de $1.5$ millions d'articles de journaux en $5$ langues pour entraîner un modèle de résumé automatique, ou encore \texttt{The Multilingual Amazon Reviews Corpus} (\cite{keung-etal:2020:multilingual-amazon-reviewsa}), une base de $1.26$ millions de commentaires de produits en $6$ langues pour entraîner un modèle de classification de la note d'un commentaire sur $5$ étoiles.
			\end{leftBarExamples}
			
			% Discussion sur les biais de sur-représentativités ou sous-représentativités.
			Toutefois, la masse de données ne résout pas toujours tous les problèmes de représentativité.
			Une des difficultés récurrentes concerne les aspects peu fréquents d'un phénomène qui se retrouvent ainsi \textbf{sous-représentés} : si l'enjeu du modèle à concevoir consiste justement à détecter ou reproduire ces aspects, il peut être intéressant de volontairement biaiser les proportions du corpus d'entraînement pour mieux les illustrer.
			À l'inverse, des cas communs ou fréquents peuvent être \textbf{sur-représentés} : il est parfois nécessaire de limiter leur occurrence dans le corpus d'apprentissage pour ne pas concevoir un modèle véhiculant des généralités ou des stéréotypes.
			Dans les deux cas, \textbf{toute intervention va introduire un biais} : l'opération doit donc être réfléchie et judicieusement réalisée pour contribuer à la finalité du modèle, d'où l'intérêt de bien la documenter pour faire entendre ce que vous voulez signifier par \textguillemets{échantillon représentatif}.
			%
			\begin{leftBarExamples}
				% Problème de sous-représentation: Détecter la langue latine ou la langue corse.
				D'une part, considérons le besoin de détecter la langue d'une bande dessinée (voir \textsc{Section~\ref{section:2.1.2.B-PRESENTATION-ANNOTATION-EXEMPLES-CLASSIFICATION}}).
				Il est fort probable que la base d'apprentissage contienne peu de données sur les parutions en langues régionales (en Corse, en Wallon, en Alsacien, ...).
				Nous pouvons donc être amenés à ajouter des exemples supplémentaires pour espérer mieux les détecter et ainsi augmenter la \textit{couverture} de notre jeu de données.
				
				% Problème d'équilibrage: Stéréotypes de Stable Diffusion.
				D'autre part, regardons l'analyse du modèle de \texttt{Stable Diffusion}, réalisée par \cite{nicoletti-bass:2023:generative-ai-takes} sur la génération de portraits de personnes fictives à partir d'une description textuelle de leur métier.
				L'étude montre que le modèle tend générer des portraits d'hommes à la peau blanche pour le métier d'architecte ou d'ingénieur, des femmes pour le rôle de concierge ou encore des personnes à la peau noire pour illustrer la classe ouvrière (voir la \textsc{Figure~\ref{figure:2.3.1.A-DEFIS-ANNOTATION-ASPECT-DONNEES-REPRESENTATIVITE-STEREOTYPES}}).
				\begin{figure}[H]
					\centering
					\includegraphics[width=0.75\textwidth]{figures/etatdelart-nicoletti-bass-2023}
					\caption{
						Répartition des couleurs de peau \textbf{(1)} et des genres \textbf{(2)} par métier lors de génération de portraits avec \texttt{Stable Diffusion} (étude menée par \cite{nicoletti-bass:2023:generative-ai-takes}).
					}
					\label{figure:2.3.1.A-DEFIS-ANNOTATION-ASPECT-DONNEES-REPRESENTATIVITE-STEREOTYPES}
				\end{figure}
				
				%%\begin{figure}[H]
				%%	\centering
				%%	\includegraphics[width=0.75\textwidth]{figures/etatdelart-nicoletti-bass-2023-skins}
				%%	\caption{
				%%		Répartitions des teintes de peaux par métier lors de génération de portrait avec \texttt{Stable Diffusion} (étude menée par \cite{nicoletti-bass:2023:generative-ai-takes}).
				%%	}
				%%	\label{figure:2.3.1.A-DEFIS-ANNOTATION-ASPECT-DONNEES-REPRESENTATIVITE-STEREOTYPES-SKINS}
				%%\end{figure}
				%%\begin{figure}[H]
				%%	\centering
				%%	\includegraphics[width=0.75\textwidth]{figures/etatdelart-nicoletti-bass-2023-genders}
				%%	\caption{
				%%		Répartitions des genres par métier lors de génération de portrait avec \texttt{Stable Diffusion} (étude menée par \cite{nicoletti-bass:2023:generative-ai-takes}).
				%%	}
				%%	\label{figure:2.3.1.A-DEFIS-ANNOTATION-ASPECT-DONNEES-REPRESENTATIVITE-STEREOTYPES-GENDERS}
				%%\end{figure}
				
				Ici, ce modèle dépeint les inégalités de notre société en perpétuant des stéréotypes, et cela ouvre la question suivante : veut-on vraiment reproduire à l'identique cette représentation ?
				(\textit{Pour grossir le trait : si nous voulions générer le scénario d'une nouvelle \texttt{BD} \texttt{Lucky Luke} à partir des \texttt{BD} déjà existantes, accepte-t-on que tous les personnages d'origine asiatique soient à la blanchisserie, et que par conséquent le prochain le soit aussi ?})
			\end{leftBarExamples}
			%
			\begin{leftBarIdea}
				% Solution: Équilibrage par la génération de données.
				Une piste pour équilibrer efficacement les corpus d'entraînement et permettre de corriger leurs biais consiste à utiliser des \textbf{données synthétiques} (\cite{jaipuria-etal:2020:deflating-dataset-bias}).
				Ces données peuvent être créées manuellement ou être générées automatiquement (voir \cite{shorten-etal:2021:text-data-augmentation} pour une revue de génération de textes et \cite{shorten-khoshgoftaar:2019:survey-image-data} pour la génération d'image).
				Bien entendu, une telle approche doit rester réfléchie pour ne pas introduire davantage de biais et pour répondre à un objectif précis d'équilibrage du jeu de données.
			\end{leftBarIdea}
			
			% Problème d'obsolescence des données.
			Une dernière difficulté concerne l'\textbf{obsolescence} des données au cours du temps.
			En effet, peu de phénomènes sont immuables, et il est courant de devoir questionner la représentativité d'un problème pour prendre en compte de nouveaux aspects ou corriger des caractéristiques devenues inexactes.
			%
			\begin{leftBarExamples}
				% Exemple de l'estimation du prix d'une BD.
				Ce problème est particulièrement impactant si nous voulons estimer le prix d'une bande dessinée (voir \textsc{Section~\ref{section:2.1.2.A-PRESENTATION-ANNOTATION-EXEMPLES-REGRESSION}}) car les oeuvres vont gagner ou perdre de la valeur avec le temps.
				Par exemple, en $1949$, le premier album de \texttt{Lucky Luke} devait s'acheter pour quelques francs, alors qu'aujourd'hui, cette édition est estimée à plusieurs milliers d'euros.
				
				% Exemple de l'évolution du langage.
				De manière similaire, le traitement du langage constate aussi des évolutions au cours du temps (\textit{nouveaux mots de vocabulaire, nouvelles expressions, influence de langues étrangères, ...}), imposant ainsi la mise à jour des jeux de données.
			\end{leftBarExamples}
		
		
		%%% 2.3.1.B. Problèmes de bruits.
		\subsubsection{Problèmes de bruits}
		\label{section:2.3.1.B-DEFIS-ANNOTATION-ASPECT-DONNEES-BRUITS}
		
			% Introduction : données bruités.
			La qualité d'une base d'apprentissage dépend fortement du bruit qu'elle contient.
			Ce bruit est inévitablement inséré lors de la collecte :
			d'une part, la méthode de collecte elle-même peut en introduire (\textit{instrument de mesure faillible, erreur humaine, ...}) ;
			d'autre part, par souci de représentativité, le bruit intrinsèque du phénomène va être capturé (\textit{forte variabilité, présence d'irrégularités, ...}).
			Un échantillon de données va donc forcément devoir se confronter à des étapes de prétraitements et de curation de données.

			% Classification des types de bruits.
			Nous nous inspirons de \cite{maharana-etal:2022:review-data-preprocessing} et de \cite{alasadi-bhaya:2017:review-data-preprocessing} pour dresser une liste de problèmes récurrents sur les données suite à une collecte :
			\begin{itemize}
				% Bruit: 1. Données non pertinentes.
				\item présence de \textbf{données non pertinentes} par rapport au cas d'usage :
				une collecte automatique ou aléatoire peut sélectionner des données n'ayant pas ou peu de rapport avec le phénomène à modéliser.
				Garder de telles données peut introduire de la confusion dans le modèle à entraîner ;
				% Bruit: 2. Variations parasites.
				\item dégradation des données par des \textbf{variations parasites} :
				comme décrit en introduction de cette partie, les bruits peuvent être intrinsèques au phénomène ou être introduits par la méthode de collecte.
				Il convient de lisser ou limiter ces bruits pour ne pas perturber le modèle ;
				% Bruit: 3. Absence de valeurs.
				\item \textbf{absence de valeurs} descriptives essentielles :
				cette absence peut venir d'une erreur de mesure, d'une méconnaissance du phénomène à caractériser, ou simplement d'un oubli.
				Cependant, un trou de description peut rendre inutile une donnée si cela concerne une caractéristique importante du phénomène ;
				% Bruit: 4. Incohérences et ambiguïtés.
				\item présence d'\textbf{incohérences} ou d'\textbf{ambiguïté} entre les données :
				les données sont rarement catégoriques et plusieurs interprétations sont parfois possibles (voir la discussion sur la subjectivité en \textsc{Section~\ref{section:2.3.3.A-DEFIS-ANNOTATION-ASPECT-HUMAIN-INTER-ANNOTATEURS}}).
				Toutefois, des contradictions entre les données peuvent pénaliser le modèle à entraîner.
			\end{itemize}
			%
			\begin{leftBarExamples}
				% Problèmes: estimation du prix d'une BD.
				Pour illustrer ces problèmes, considérons la tâche d'estimation du prix d'une bande dessinée (voir \textsc{Section~\ref{section:2.1.2.A-PRESENTATION-ANNOTATION-EXEMPLES-REGRESSION}}) :
				\begin{itemize}
					% Exemple: 1. Données non pertinentes.
					\item une donnée concernant le prix d'un roman ou d'une encyclopédie peut avoir été insérée par mégarde et pourrait être considérée comme donnée non pertinente pour ce cas d'usage ;
					% Exemple: 2. Variations parasites.
					\item un changement de typographie (\textit{majuscules, minuscules, accents, ponctuation}) dans l'écriture d'un titre pourrait mal identifier une bande dessinée ;
					% Exemple: 3. Absence de valeurs.
					\item une information peut ne pas avoir été renseignée lors d'une transaction (l'année d'édition par exemple), alors que c'est une caractéristique importante de la prise de décision ;
					% Exemple: 4. Incohérences et ambiguïtés.
					\item une même bande dessinée (avec les mêmes caractéristiques) peut avoir été vendue à deux prix radicalement différents, introduisant ainsi une légère ambiguïté dans les données.
				\end{itemize}
				
				% Autres problèmes.
				Des problèmes similaires peuvent impacter le traitement du texte (\textit{fautes grammaticales, fautes syntaxiques, erreurs sémantiques, ambiguïtés, omissions, ...}), des images (\textit{flous, mauvais cadrages, colorimétries gênantes, ...}) et de l'audio (\textit{bruits en arrière plan, saturations, coupures inopportunes, mots mâchés, ...}).
				Quelques exemples sont présentés ci-dessous dans la \textsc{Figure~\ref{figure:2.3.1.B-DEFIS-ANNOTATION-ASPECT-DONNEES-BRUITS}}.
				%
				\begin{figure}[H]
					\centering
					\includegraphics[width=0.80\textwidth]{figures/etatdelart-morris-1958-lucky-luke-12-bruits}
					\caption{
						Exemples de bruits courants perturbant l'analyse d'une image :
						\textbf{(1)} le flou,
						\textbf{(2)} un doigt sur le capteur,
						\textbf{(3)} un problème de cadrage
						et \textbf{(4)} un problème d'angle de vue.
					}
					\label{figure:2.3.1.B-DEFIS-ANNOTATION-ASPECT-DONNEES-BRUITS}
				\end{figure}
			\end{leftBarExamples}
			
			% Correction des données par le prétraitements et le nettoyage.
			Pour limiter l'impact du bruit dans les données, \cite{alasadi-bhaya:2017:review-data-preprocessing} structurent les étapes de prétraitements de données entre quatre catégories :
			\begin{itemize}
				% Approche: Data cleaning.
				\item le \textbf{nettoyage des données} : cette étape consiste à compléter les données manquantes (\textit{en prenant la valeur moyenne par exemple}), à filtrer les données aberrantes ou inintéressantes, et surtout à lisser le bruit dans les données en gommant les variations parasites ;
				% Approche: Data integration.
				\item l'\textbf{intégration des données} : dans certains cas, plusieurs sources de données sont disponibles, il peut donc être intéressant de croiser ces sources de données pour augmenter la consistance de la base d'apprentissage et identifier les incohérences ;
				% Approche: Data transformation.
				\item le \textbf{formatage des données} : pour exploiter facilement les données, certaines transformations sont parfois nécessaires pour limiter les ambiguïtés dues au leur format (\textit{par exemple: normaliser une valeur entre $0$ et $1$, limiter les caractères spéciaux dans un texte});
				% Approche: Data reduction.
				\item la \textbf{réduction des données} : en réalisant une analyse approfondie des données, nous pouvons quelquefois constater que certaines caractéristiques présentes sur les données sont peu utiles et peuvent être supprimées pour réduire la complexité de la base d'apprentissage.
			\end{itemize}
			\cite{baledent:2022:complexite-annotation-manuelle} rappelle néanmoins que le document source (ou ici : la donnée brute) doit rester accessible pour la phase d'annotation afin de ne pas manquer une information potentiellement intéressante.
			%
			\begin{leftBarExamples}
				% Correction: estimation du prix d'une BD.
				Reprenons les problèmes évoqués précédemment sur la tâche d'estimation du prix d'une bande dessinée :
				\begin{itemize}
					% Correction: 1. Données non pertinentes.
					\item une donnée inintéressante peut simplement être supprimée ;
					% Correction: 2. Variations parasites.
					\item normaliser les champs décrivant une bande dessinée en passant tout en minuscules limiterait les chances de mal l'identifier ;
					% Correction: 3. Absence de valeurs.
					\item une année d'édition manquante pourrait être identifiée par l'étiquette \texttt{inconnue} et un prix manquant pourrait être complété par la moyenne du prix des \texttt{BD} ayant les mêmes caractéristiques ;
					% Correction: 4. Incohérences et ambiguïtés
					\item un prix faussé pourrait être identifié comme incohérent en analysant les prix des \texttt{BD} ayant les mêmes caractéristiques ;
				\end{itemize}
			\end{leftBarExamples}
		
		
		%%% 2.3.1.C. Problèmes d'exploitation et de diffusion.
		\subsubsection{Problèmes d'exploitation et de diffusion}
		\label{section:2.3.1.C-DEFIS-ANNOTATION-ASPECT-DONNEES-DROITS}
		
			% Introduction: toutes les données ne sont pas disponibles.
			En plus des difficultés techniques sur la réalisation d'une collecte de données, il y a aussi des contraintes législatives et stratégiques à prendre en compte.
			
			% Contraintes sur la propriété intellectuelle des données.
			D'une part, il faut considérer le fait que certaines données sont protégées et ne peuvent pas être collectées ou exploitées librement.
			C'est le cas de données soumises aux droits des \textbf{propriétés intellectuelles} qui empêchent cet usage : nous pouvons citer par exemple \cite{loignon:2023:ia-medias-francais} qui évoque une levée de boucliers des médias français contre l'utilisation de leurs articles pour entraîner des modèles de langues, mais aussi le journal \cite{les-echos:2023:ia-auteur-game} qui questionne la violation des \textbf{droits d'auteur} lorsque qu'un modèle est entraîné sur l'oeuvre d'un artiste et qu'il est capable de la reproduire.
			
			% Contraintes sur le consentement.
			Ces limites concernent aussi la Réglementation Générale européenne sur la Protection des Données (\cite{european-commission:2016:regulation-eu-2016}) restreignant les \textbf{collectes et usages non consentis} de données personnelles.
			Ainsi, il n'est pas possible d'entraîner n'importe quel modèle sur n'importe quelles données, et une telle contrainte impose de manipuler les données en garantissant l'anonymat et la confidentialité des personnes consentantes.
			
			% Exemple 1 : propriété intellectuelle et consentement.
			\begin{leftBarExamples}
				Considérons la conception d'un modèle de synthèse vocale pour réaliser une \texttt{BD} audio (voir \textsc{Section~\ref{section:2.1.2.D-PRESENTATION-ANNOTATION-EXEMPLES-TRANSCRIPTION}}).
				D'une part, un tel projet nécessiterait déjà de demander les droits d'adaptation pour entraîner un modèle de synthèse vocale avec les doublage de l'adaptation télévisée de \texttt{Lucky Luke}.
				D'autre part, l'utilisation de la voix d'une personne se confrontera probablement à plusieurs restrictions pour éviter que ce modèle ne soit détourné pour des usages non consentis par le doubleur.
			\end{leftBarExamples}
			
			% Contraintes stratégiques.
			Pour aller plus loin, cette notion de confidentialité touche les données personnelles, mais aussi le \textbf{caractère stratégique} d'une organisation.
			En effet, dans le monde académique, les données manipulées sont le plus souvent publiques et peuvent être employées pour contribuer à la recherche scientifique.
			Mais dans le secteur industriel, les jeux de données sont liés au domaine d'activité de l'entreprise : ils ont généralement requis un investissement conséquent en temps et en moyens, et ils représentent donc son avantage concurrentiel (\textit{par leur spécificité, leur caractère secret ou novateur, leur qualité compétitive, ...}).
			Il est donc rare de voir une entreprise partager ses jeux de données car elle pourrait perdre un de ses atouts stratégiques.
			
			% Exemple OpenSource, mais limitation commerciale.
			Une solution est de trouver des jeux de données \textbf{accessibles en \textit{Open Source}}.
			Plusieurs plateformes mettent en effet à disposition des données ou des modèles, comme \textit{Hugging Face} (\cite{hugging-face:2016:hugging-face-ai}) ou \texttt{Zenodo} (\cite{re3data.org:2013:zenodo}).
			Toutefois, deux limites subsistent à l'utilisation de ces données :
			\begin{itemize}
				\item les données mises à disposition publiquement sont souvent assez générales et ne reflètent pas la spécificité des cas d'usage de l'entreprise, limitant ainsi leur intérêt ;
				\item les données publiques ne sont pas forcément ouvertes à un usage commercial (\textit{elles peuvent par exemple employer la licence \texttt{CC BY-NC 4.0}, \cite{creative-commons:2013:cc-bync-legal}}), restreignant ainsi les seules applications aux domaines de la recherche et de la veille scientifique.
			\end{itemize}
			Pour ne pas faire de faux pas juridique, \cite{rajbahadur-etal:2022:can-use-this} proposent une approche pour vérifier si une licence permet d'exploiter un jeu de données.
			
			% Besoin de tracabilité.
			\begin{leftBarInformation}
				Pour terminer, nous mentionnons aussi une proposition de législation européenne concernant la future réglementation des modèles d'intelligence artificielle (\cite{european-commission:2021:proposal-regulation-european}).
				Cette loi concerne les quatre objectifs suivants :
				\begin{itemize}
					\item \textguillemets{\textit{veiller à ce que les systèmes d'\texttt{IA} mis sur le marché de l'Union et utilisés soient sûrs et respectent la législation en vigueur en matière de droits fondamentaux et les valeurs de l'Union}} ;
					\item \textguillemets{\textit{garantir la sécurité juridique pour faciliter les investissements et l'innovation dans le domaine de l'\texttt{IA}}} ;
					\item \textguillemets{\textit{renforcer la gouvernance et l'application effective de la législation existante en matière de droits fondamentaux et des exigences de sécurité applicables aux systèmes d'\texttt{IA}}} ;
					\item \textguillemets{\textit{faciliter le développement d'un marché unique pour des applications d'\texttt{IA} légales, sûres et dignes de confiance, et empêcher la fragmentation du marché}}.
				\end{itemize}
				Un besoin de traçabilité des données et des modèles se fait donc sentir, renforçant les recommandations à documenter et détailler les traitements et choix pour garantir la représentativité et la qualité des données des bases d'apprentissage.
			\end{leftBarInformation}
		
		
	%%%
	%%% Subsection 2.3.2: Défis concernant la complexité inhérente à la tâche d'annotation.
	%%%
	\subsection{Défis concernant la complexité inhérente à la tâche d'annotation}
	\label{section:2.3.2-DEFIS-ANNOTATION-ASPECT-COMPLEXITE}
	
		% Introduction: Se rendre compte de la complexité.
		Selon \cite{baledent:2022:complexite-annotation-manuelle}, deux types de complexités sont à différencier :
		\begin{itemize}
			% Complexité propre aux données.
			\item la \textbf{complexité propre au phénomène} que l'on veut modéliser :
			nous avons pu apercevoir celle-ci dans la \textsc{Section~\ref{section:2.3.1.A-DEFIS-ANNOTATION-ASPECT-DONNEES-REPRESENTATIVITE}}, notamment en considérant la nécessité de collecter une grande quantité de données pour représenter la diversité du phénomène et le besoin de contrôler les bruits pour en assurer la qualité ; et
			% Complexité propre à la procédure d'annotation.
			\item la \textbf{complexité propre à la procédure d'annotation} mise en place :
			cet aspect est abordé brièvement dans la \textsc{Section~\ref{section:2.2-ORGANISATION-ANNOTATION}} en exposant le besoin d'établir une modélisation du problème avec son guide d'annotation, de recourir à un processus itératif pour affiner les problèmes de conception et différences d'interprétation (cycles \texttt{MATTER} et \texttt{MAMA}), ou encore d'employer des opérateurs ayant différentes compétences.
		\end{itemize}
		Dans cette section, nous allons voir comment analyser et mesurer cette complexité, puis nous nous intéresserons aux coûts qu'elle peut engendrer lors de la conception du jeu de données.
		
		
		%%% 2.3.2.A. Modélisation difficile du phénomène.
		\subsubsection{Modélisation difficile du phénomène}
		\label{section:2.3.2.A-DEFIS-ANNOTATION-ASPECT-COMPLEXITE-MODELISATION}
		
			% Introduction : Modélisation importante, mais compliquée !
			Comme nous l'avons énoncé lors de la présentation au cours du cycle \texttt{MATTER} en \textsc{Section~\ref{section:2.2.1.A-ORGANISATION-ANNOTATION-ETAPES-CLES-MODELIZE-ANNOTATE}}, la modélisation est une étape importante du processus de conception car elle permet de clarifier ce qu'il faut annoter et avec quel(s) objectif(s).
			Toutefois, plusieurs aspects rendent cette tâche difficile à réaliser.
			
			% Complexité due à l'intervention d'experts métiers.
			Tout d'abord, le projet d'annotation concerne généralement un cas d'usage précis dont la spécificité requiert l'intervention d'experts ayant des \textbf{connaissances métiers}.
			Cependant, de tels experts n'ont pas forcément les compétences analytiques requises pour établir une représentation abstraite de leurs connaissances.
			En effet, diverses questions sont à discuter concernant la modélisation à choisir :
			\begin{itemize}
				\item peut-elle réutiliser un standard existant ?
				\item sera-t-elle stable et explicite à l'annotation ?
				\item sera-t-elle traduite en un seul ou en plusieurs modèle(s) de \textit{Machine Learning} ?
				\item sera-t-elle maintenable avec de grands volumes de données ?
			\end{itemize}
			Pour y répondre, des ateliers de conception sont généralement organisés avec les experts, permettant ainsi d'identifier les notions pertinentes à intégrer dans la modélisation finale du problème.
			Si le phénomène est intrinsèquement complexe, il est possible néanmoins que ces ateliers se réalisent en mode essai-erreur (à l'image du mini-cycle \texttt{MAMA}) jusqu'à trouver une modélisation qui puisse convenir, rendant cette tâche particulièrement pénible.
			%
			\begin{leftBarExamples}
				Pour se rendre compte de cette difficulté, il suffit d'essayer de détailler l'ensemble des actions que peut entreprendre un robot conversationnel en domotique (comme \texttt{Alexa}, \cite{alexa-internet:2018:keyword-research-competitor}), puis de modéliser les diverses instructions verbales pouvant déclencher ces actions.
				Nous pouvons vite tomber sur des débats d'opinion, notamment autour de la gestion des formulations ambigües ou d'actions différentes provenant d'instructions similaires (\textit{voir l'exemple précédemment utilisé : est-ce que l'énoncé \textguillemets{peux-tu allumer...} demande à l'assistant d'effectuer une action, ou demande-t-il simplement exprimer s'il en est capable ?})
			\end{leftBarExamples}
			
			% Solution pour limiter la complexité de modélisation.
			\begin{leftBarIdea}
				Quelques approches peuvent être mises en place pour assister la modélisation d'un problème :
				\begin{itemize}
					% Solution: Modélisation non supervisées (clustering ou topic modelling).
					\item les approches \textbf{non supervisées} :
					elles consistent à laisser la machine extraire et structurer automatiquement la connaissance contenue dans les données collectées.
					Par exemple pour le traitement du texte, nous pouvons citer les méthodes d'exploration utilisant le regroupement automatique (\textit{clustering}) comme \texttt{KMeans} (\cite{macqueen:1967:methods-classification-analysis}), ou la modélisation thématique (\textit{topic modeling}) comme \texttt{LDA} (\cite{blei-etal:2003:latent-dirichlet-allocation}) ;
					% Solution: Modélisation semi-supervisées (active learning)
					\item les approches \textbf{semi-supervisées} :
					elles consistent à travailler main dans la main avec la machine pour explorer les données collectées.
					Nous pouvons citer par exemple les méthodes d'apprentissage actif (\textit{active learning}) dont une revue est proposée par \cite{settles:2010:active-learning-literature} ;
					% Solution: Modélisation itératives.
					\item les approches \textbf{itératives} :
					elles consistent à concevoir d'abord un petit modèle dont le périmètre est limité, puis d'étendre pas à pas son périmètre suite aux retours de son utilisation.
					Une telle organisation fait bien entendu écho à la philosophie du cycle \texttt{MATTER}.
				\end{itemize}
				Toutefois, plusieurs handicaps pénalisent ces approches, notamment lors de déséquilibrage ou de bruits dans les données, ou lorsque l'interprétation nécessite une forte connaissance métier.
			\end{leftBarIdea}
			
			% Avis de l'auteur : pas d'assistance à la modélisation !
			\begin{leftBarAuthorOpinion}
				% Constat: conception généralement manuelle et peu assister.
				Par expérience, nous constatons que peu d'approches non supervisées ou semi-supervisées sont utilisées, notamment parce que leurs résultats sont jugés peu pertinents sur des phénomènes complexes.
				Les experts métiers réalisent alors cette étape de modélisation manuellement, absorbant la complexité de cette tâche en organisant de nombreux ateliers de conception en mode essai-erreur.
				
				% Exemple des chatbots.
				C'est particulièrement le cas lors de la conception de la base d'apprentissage d'un assistant conversationnel (\textit{task-oriented}) : la tâche de modélisation consiste généralement à identifier l'intention formulée dans une demande d'un utilisateur en fonction du verbe d'action (\textguillemets{\textit{je veux \textbf{réserver} un billet}}, \textguillemets{\textit{\textbf{joue} moi du jazz !}}, \textguillemets{\textit{comment \textbf{éditer} une attestation ?}}).
				Cependant, la vaste diversité du langage permet rarement d'identifier les thématiques présentes dans une collecte de données.
				L'étape de modélisation est alors réalisée manuellement par les experts du domaine couvert par l'assistant conversationnel.
			\end{leftBarAuthorOpinion}
			
			% Complexité due à la rigueur requise pour la conception.
			Lorsqu'une modélisation acceptable du phénomène a été définie, il est nécessaire de la structurer dans le but de \textbf{rédiger le guide d'annotation} associé (voir \textsc{Section~\ref{section:2.2.1.A-ORGANISATION-ANNOTATION-ETAPES-CLES-MODELIZE-ANNOTATE}}).
			\cite{nedellec-etal:2006:annotation-guidelines-machine} ont pu montrer que la clarté de ce guide impacte directement la qualité des annotations : il est donc important de rédiger celui-ci avec soin pour donner à l'annotateur une vision de son objectif (\cite{fort-etal:2009:vers-methodologie-annotation}).
			Cela requiert toutefois de solides compétences analytiques et pédagogiques, notamment pour définir, organiser et transmettre ce vaste ensemble de règles sans introduire de biais ni de confusion.
			%
			\begin{leftBarReminder}
				\cite{dipper-etal:2004:useradaptive-annotation-guidelines} ont dressé une liste de recommandations pour rédiger un guide d'annotation fiable.
			\end{leftBarReminder}
			
			% Complexité due à la subjectivité de la tâche.
			Malgré tout, \cite{baledent:2022:complexite-annotation-manuelle} rappelle que l'établissement d'une modélisation d'un phénomène \textbf{relève d'un choix}, et que celui-ci est par conséquent subjectif.
			En effet, plusieurs représentations peuvent convenir à un même cas d'usage, et celle retenue devra être la représentation qui correspondra le mieux à la finalité du modèle.
			Ce choix, aussi avisé soit-il, entrera inévitablement en friction avec certaines données collectées qui s'inséreront difficilement au sein de la modélisation choisie.
			Lors de la rédaction du guide d'annotation, il faut donc trouver l'équilibre entre entre la rigueur (\textit{pour fiabiliser la qualité de la labellisation}) et la flexibilité (\textit{pour pouvoir s'adapter aux données contrariantes}).
			%
			\begin{leftBarExamples}
				Dans la tâche de transcription d'un audio pour réaliser un modèle de synthèse vocale (\textsc{Section~\ref{section:2.1.2.D-PRESENTATION-ANNOTATION-EXEMPLES-TRANSCRIPTION}}), nous constatons que \texttt{Lucky Luke} mâche certains de ses mots (\textguillemets{[...] \texttt{j'vous s'rai reconnaissant} [...]}) : préférez-vous annoter strictement ce qu'il dit (\textit{au risque de complexifier le modèle}) ou corriger la transcription (\textit{au risque de ne pas reproduire la prononciation exacte du personnage}) ?
			\end{leftBarExamples}
		
		%%% 2.3.2.B. Estimation de la complexité.
		\subsubsection{Estimation de la complexité}
		\label{section:2.3.2.B-DEFIS-ANNOTATION-ASPECT-COMPLEXITE-ESTIMATION}
			
			% Estimation par une approche analytique.
			Dans \cite{fort-etal:2012:modeling-complexity-manual}, une approche analytique est proposée pour mesurer la complexité des tâches de modélisation et d'annotation.
			Six dimensions sont détaillées, réparties en trois axes :
			\begin{itemize}
				% Aspect localisation.
				\item la complexité de \textbf{localisation} de l'annotation (\textit{discrimination}, \textit{délimitation}) :
				y a-t-il plusieurs parties à annoter dans une donnée ?
				quel est le ratio entre les parties à annoter et les parties potentiellement annotables ?
				est-ce que ces parties sont clairement délimitées ou ont-elles des bornes floues ?
				% Aspect caractérisation.
				\item la complexité de \textbf{caractérisation} de l'annotation (\textit{expressivité}, \textit{dimensionnalité}, \textit{ambiguïté}) :
				doit-on annoter une variable catégorielle ou numérique ?
				s'il y a plusieurs variables, y a-t-il des relations entre elles ?
				leur cardinalité est-elle finie ou infinie ?
				quelle est la proportion de confusion ou de désaccord d'interprétation de cette modélisation ?
				% Aspect contexte.
				\item la complexité de \textbf{situation} de l'annotation (\textit{poids du contexte}) :
				a-t-on besoin d'informations complémentaires pour être capable d'interpréter la donnée ?
			\end{itemize}
			
			% Estimation par une approche statistique.
			Une autre manière de mesurer la complexité d'une tâche d'annotation consiste à \textbf{évaluer les différences entre annotateurs}.
			En effet, \cite{gut-bayerl:2004:measuring-reliability-manual} ont notamment montré qu'un nombre élevé de désaccords de labellisation peut mettre en avant une ambiguïté de modélisation, une différence d'interprétation entre annotateurs, ou encore une difficulté à saisir pleinement la subtilité des données manipulées : dans tous les cas, ces désaccords témoignent de la complexité de la tâche.
			Pour mesurer cet accord, différents scores ont été développés comme peut en témoigner la revue de \cite{artstein-poesio:2008:intercoder-agreement-computational}.
			Nous reviendrons plus en détails sur ces différences de comportement dans la \textsc{Section~\ref{section:2.3.3-DEFIS-ANNOTATION-ASPECT-HUMAIN}}.
			\begin{leftBarInformation}
				L'un des plus scores les plus utilisés est $\alpha$ de \textit{Krippendorff} (\cite{krippendorff:2004:content-analysis-introduction}).
				Le score est normalisé entre $0$ (\textit{aucun accord}) et $1$ (\textit{accord parfait}).
				Il est d'usage de considérer un accord fort lorsque le score est supérieur à $0.8$,
				et l'accord reste acceptable si la valeur est supérieure à $0.667$.
			\end{leftBarInformation}
			
			% Exemples
			\begin{leftBarExamples}
				% Exemple: Identification d'une bande dessinée à partir de sa couverture.
				Considérons l'identification d'une bande dessinée à partir de sa couverture, pour laquelle l'annotation de textes présents sur une image sont nécessaires pour entraîner un modèle de reconnaissance optique de caractères (voir \textsc{Section~\ref{section:2.1.2.C-PRESENTATION-ANNOTATION-EXEMPLES-EXTRACTION}}).
				Nous pouvons voir que :
				\begin{itemize}
					% Aspect localisation.
					\item la localisation des annotations est assez évidente car l'information est visuelle : 
					(1) En général, il y a peu de texte sur une couverture de \texttt{BD}, l'information est donc facilement identifiable (\textit{bonne discrimination}) ;
					(2) Cependant, il peut y avoir de légères différences sur la position exacte des encadrés identifiant les textes (\textit{délimitation délicate}) ;
					% Aspect caractérisation.
					\item la caractérisation concerne du texte mais son annotation est explicite :
					(1) L'annotation concerne du texte et des nombres, il y a donc une grande variabilité parmi les valeurs possibles (\textit{forte expressivité}).
					(2) Plusieurs informations sont attendues, comme le nom de la collection, l'auteur, le titre, ou la date de parution (\textit{dimensionnalité modérée}) ;
					(3) Toutefois, il y a assez peu de doute sur les valeurs à indiquer car ces dernières sont explicitement liées aux inscriptions sur l'image (\textit{peu d'ambiguïté}) ;
					% Aspect contexte.
					\item la situation de l'annotation n'a pas d'impact :
					en effet, peu d'informations complémentaires sont requises pour interpréter les textes de l'image (\textit{poids du contexte faible}).
				\end{itemize}
				Au final, l'analyse révèle que cette tâche est relativement peu complexe.
				Le calcul d'un score d'accord entre annotateurs permettrait de confirmer cette hypothèse et d'en déduire la confiance que nous pouvons accorder à la qualité des données labellisées.
			\end{leftBarExamples}
			%% NOTE (Thierry P.): Compléter par un exemple plus complexe ?
			
			
		%%% 2.3.2.C. Problèmes de coûts.
		\subsubsection{Problèmes de coûts}
		\label{section:2.3.2.C-DEFIS-ANNOTATION-ASPECT-COMPLEXITE-COUTS}
		
			% Introduction : Une conséquence de la complexité est le coût de l'annotation.
			Toute cette complexité a un impact non négligeable sur les coûts à engager dans un projet de conception de jeu de données.
			Nous allons ici détailler certains de ces coûts et donner quelques exemples notoires.
			
			% Coût du recrutement, de la formation, du tarif horaire.
			Tout d'abord, il y a des \textbf{charges de main d'oeuvre}.
			En effet, de nombreuses personnes aux compétences diverses vont s'investir dans un tel projet (voir \textsc{Section~\ref{section:2.2.2-ORGANISATION-ANNOTATION-ACTEURS}}), à la fois pour modéliser le phénomène mais aussi pour labelliser les données le représentant.
			Cependant, les experts qualifiés pour ces tâches sont souvent très demandés : ainsi, ces profils sont rares à l'embauche, souvent difficiles à mobiliser sur de longues durées, et ont généralement des tarifs horaires élevés.
			Une alternative consiste à former le personnel nécessaire, mais cette montée en compétence prend du temps et représente aussi un investissement important (\textit{formations professionnelles, veille technologique, appréhension du phénomène à modéliser, ...}).
			
			% Coût temporel.
			Ensuite, il faut considérer les \textbf{facteurs temporels} qui impactent le délai de mise en production du modèle de \textit{Machine Learning}.
			En plus des délais de montée en compétences des experts, nous pouvons ajouter :
			\begin{itemize}
				\item le temps nécessaire à la \textit{collecte de données}, pouvant prendre plusieurs semaines (\textit{diffusion d'un sondage, temps de mesure d'un phénomène s'étalant sur la durée, ...}) ;
				\item le temps imposé par les \textit{ateliers de conception} de la modélisation, pouvant prendre entre quelques heures et quelques semaines en fonction de sa complexité et des différences d'opinions entre experts ;
				\item le temps dédié à l'\textit{annotation des données}, dépendant entre autres de la complexité de la modélisation et de la quantité à labelliser ; et
				\item le temps requis pour entraîner le modèle de \textit{Machine Learning}.
			\end{itemize}
			À cela s'ajoute aussi la perspective de révision de la modélisation, et donc à la multiplication des coûts en appliquant plusieurs itérations du cycle \texttt{MATTER} pour obtenir un modèle convenable.
			Il est possible de réduire certains de ces coûts temporels en ajoutant davantage de personnes dans le projet, mais cela augmentera évidemment les charges de main d'oeuvre, et quelques aspects demeureront toutefois incompressibles (\textit{les débats lors de la phase de modélisation par exemple}).
			
			% Coût financiers.
			Enfin, il y a divers \textbf{coûts financiers à engager} en plus des recrutements et des conséquences des délais de réalisation.
			Nous pouvons notamment considérer l'achat ou le développement de l'infrastructure technique telle que de l'outil d'annotation et de stockage des données, les potentiels instruments de mesure du phénomène (\textit{micros, caméras, sondes, ...}) ou encore les acquisitions de droits d'utilisation de données ou de modèles sous licence.
			
			% Exemple de coûts.
			\begin{leftBarExamples}
				Détaillons ici deux projets d'annotation dont le chiffrage est disponible :
				\begin{itemize}
					% Prague Dependency Treebank.
					\item \texttt{Prague Dependency Treebank} (\cite{bohmova-etal:2003:prague-dependency-treebank}) :
					l'annotation de $180~000$ phrases tchèques (environ $1.8$ million de \textit{tokens}) pour l'analyse morpho-syntaxique a duré $5$ ans (entre 1996 et 2003), impliquant $22$ personnes.
					La somme totale engagée est estimée à $600~000$ dollars ;
					% MS COCO.
					\item \texttt{MS COCO} (\cite{lin-etal:2014:microsoft-coco-common}) :
					l'annotation d'objets présents dans $328~000$ images (environ $2.5$ millions d'objets répartis en $91$ types différents) a nécessité environ $70~000$ heures d'annotation.
				\end{itemize}
			\end{leftBarExamples}
			
			% Solutions pour limiter les coûts
			\begin{leftBarIdea}
				Pour limiter les coûts, diverses solutions ont déjà été proposées :
				\begin{itemize}
					% Solution: Pré-annotation pour préparer le travail de l'annotateur.
					\item la \textbf{pré-annotation} :
						cette approche consiste à employer un petit modèle pour suggérer une annotation à l'annotateur, celui-ci pouvant alors l'approuver ou corriger.
						\cite{fort-sagot:2010:influence-preannotation-postagged} démontre le gain de temps et de qualité d'une telle approche.
						toutefois, certains biais peuvent influencer négativement l'annotateur : \cite{dandapat-etal:2009:complex-linguistic-annotation} souligne par exemple le risque de biais de confirmation (\textit{influence de la machine et tendance de l'annotateur à être en accord avec celle-ci, notamment sur des données ambiguës}) ;
					% Solution: Apprentissage actif pour cibler le travail de l'annotateur.
					\item l'\textbf{apprentissage actif} (\textit{active learning}) :
						cette approche consiste à interagir avec la machine pour sélectionner les données les plus intéressantes à annoter (\cite{settles:2010:active-learning-literature}).
						Nous pouvons par exemple entraîner un modèle avec les données déjà disponibles, le tester sur les données non annotées et sélectionner les données sur lesquelles ses prédictions sont le moins confiantes ;
					% Solution: Transfert d'apprentissage pour demander moins de données annotées.
					\item le \textbf{transfert d'apprentissage} (\textit{transfert learning}) :
						cette approche consiste à réutiliser la connaissance contenue dans un modèle déjà existant dans le but d'exploiter certaines de ses fonctionnalités (\cite{zhuang-etal:2021:comprehensive-survey-transfer}, \cite{iman-etal:2023:review-deep-transfer}).
						Il a été montré qu'adapter un modèle pour un nouveau cas d'usage similaire peut se faire avec peu de données, réduisant ainsi drastiquement la charge d'annotation (\cite{parnami-lee:2022:learning-few-examples}) ;
					% Solution: Myriadisation.
					\item la \textbf{myriadisation} (\textit{crowdsourcing}) :
						cette approche consiste à déléguer l'annotation à des plateformes collaboratives en ligne comme \texttt{Amazon Mechanical Turk} (\cite{callison-burch-dredze:2010:creating-speech-language}) ou \texttt{Language ARC} (\cite{fiumara-etal:2020:languagearc-developing-language}).
						N'importe quel internaute peut alors contribuer à la tâche d'annotation, permettant ainsi de labelliser de grands volumes de données rapidement et à moindres coûts.
						Cette technique comporte toutefois un inconvénient majeur : les opérateurs ne sont généralement pas des experts et cer derniers sont rémunérés au volume labellisé.
						La qualité des annotations risque donc d'être délaissée au profit de la quantité (\cite{sagot-etal:2011:turc-mecanique-pour}).
				\end{itemize}
			\end{leftBarIdea}
		
		
	%%%
	%%% Subsection 2.3.3: Défis concernant les différences de comportements d'annotation.
	%%%
	\subsection{Défis concernant les différences de comportements d'annotation}
	\label{section:2.3.3-DEFIS-ANNOTATION-ASPECT-HUMAIN}
		
		% Introduction: Considérer les différences de comportements.
		Nous pouvons constater deux divergences de comportements :
		\begin{itemize}
			\item ceux entre deux annotateurs (voir \textsc{Section~\ref{section:2.3.3.A-DEFIS-ANNOTATION-ASPECT-HUMAIN-INTER-ANNOTATEURS}}) ;
			\item ceux d'un annotateur avec lui-même (voir \textsc{Section~\ref{section:2.3.3.B-DEFIS-ANNOTATION-ASPECT-HUMAIN-INTRA-ANNOTATEUR}}).
		\end{itemize}
		
		
		%%% 2.3.3.A. Différences inter-annotateurs.
		\subsubsection{Différences inter-annotateurs}
		\label{section:2.3.3.A-DEFIS-ANNOTATION-ASPECT-HUMAIN-INTER-ANNOTATEURS}
		
			% Introduction : l'annotation est subjective.
			Comme nous avons pu le voir dans la \textsc{Section~\ref{section:2.3.2.A-DEFIS-ANNOTATION-ASPECT-COMPLEXITE-MODELISATION}}, la modélisation d'un phénomène relève d'un choix subjectif.
			Il est donc normal de constater que cette subjectivité entraîne des différences de comportement d'annotation.
			Celles-ci se manifestent particulièrement sur des données ambiguës ou bruitées car les limites de la modélisation sont exposées.
			D'autres éléments comme le caractère abstrait d'une modélisation ou la présence de règles de labellisation trop floues peuvent aussi mener à des divergences d'interprétation entre opérateurs.
			
			% Facteur de désaccords.
			\cite{bayerl-paul:2011:what-determines-intercoder} ont pu étudier un ensemble de \textbf{facteurs à l'origine de désaccords}.
			Nous en dressons une liste résumée ci-dessous :
			\begin{itemize}
				% Complexité.
				\item la \textit{complexité} du problème :
				que celle-ci vienne intrinsèquement du phénomène à annoter ou du cas d'usage reflété dans la modélisation, nous observons que si l'annotation est difficile, alors les chances d'interpréter différemment les données sont plus élevées ;
				% Nombre.
				\item le \textit{nombre} d'annotateurs :
				il est normal de constater que plus y a de personnes donnant leurs avis, plus les avis peuvent diverger ;
				% Expertise.
				\item le \textit{niveau d'expertise} du phénomène :
				nous remarquons des divergences d'opinion entre les opérateurs n'étant pas spécialistes du phénomène et ceux détenant des connaissances sur celui-ci (un linguiste pour des données textuelles, un libraire pour des \texttt{BD}, ...) ;
				% Formation.
				\item le \textit{niveau de formation} à la tâche de labellisation :
				nous constatons des divergences entre les opérateurs habitués à l'outil et au guide d'annotation, et ceux découvrant la tâche de labellisation et sa mise en oeuvre pour la première fois.
			\end{itemize}
			%
			\begin{leftBarInformation}
				\cite{bayerl-paul:2011:what-determines-intercoder} montrent aussi qu'il peut y avoir des différences entre deux annotateurs experts non formés à la tâche de labellisation, alors qu'il y a moins de divergences entre des annotateurs experts et non expert s'ils ont été formés tous les deux.
				Cela souligne bien l'\textbf{importance de la formation à la tâche d'annotation} et la nécessité de rédiger un guide d'annotation qui détaille l'objectif et les règles de labellisation dans le but d'en limiter la subjectivité.
			\end{leftBarInformation}
			%
			\begin{leftBarIdea}
				% Adjudication.
				Pour aller plus loin, il est recommandé d'organiser des sessions d'\textbf{adjudication} durant laquelle les opérateurs peuvent confronter leurs visions en annotant les mêmes données.
				Cela permet de mesurer un score d'accord entre annotateurs mais aussi de discuter des points de désaccords dans l'application du guide de labellisation.
				Une règle de bon sens consiste à confronter $2$ annotateurs pour être capable d'identifier les points de désaccords, mais il faut être au moins $3$ annotateurs pour en discuter et les résoudre.
				\cite{bayerl-paul:2011:what-determines-intercoder} conseille même d'être au moins $5$ annotateurs si le cas d'usage est critique.
			\end{leftBarIdea}
		
		%%% 2.3.3.B. Différences intra-annotateur.
		\subsubsection{Différences intra-annotateur}
		\label{section:2.3.3.B-DEFIS-ANNOTATION-ASPECT-HUMAIN-INTRA-ANNOTATEUR}
		
			% Introduction à la régulation charge de travail.
			Malgré la conception d'un guide et la rédaction de règles, malgré les sessions de revues dédiées à affiner ce guide et malgré les diverses pistes mises en oeuvre pour rendre l'annotation moins complexe, nous pouvons tout de même constater qu'un annotateur peut manifester des variations de comportement.
			Ces différences peuvent s'apparenter à des erreurs d'inattention, à des oublis de consignes, ou à d'autres fluctuations similaires.
			
			% Modèle de Sperandio sur la régulation de la charge de travail.
			Pour expliquer cela, nous pouvons nous baser sur la théorie de la \textbf{régulation de la charge de travail} (\cite{sperandio:1978:regulation-working-methods}, \cite{sperandio:1987:ergonomie-travail-mental}).
			Celle-ci s'exprime de la manière suivante :
			\begin{itemize}
				% Estime la charge de travail.
				\item D'une part, l'opérateur \textbf{estime la charge de travail} à accomplir (\textit{la quantité, la difficulté, les délais, ...}).
				Concernant la tâche d'annotation, elle sera perçue comme \textbf{très élevée} (\textit{complexité intrinsèque, volume conséquent à traiter, règles strictes de labellisation , ...}) ;
				% Estime les ressources.
				\item D'autre part, l'opérateur \textbf{estime les ressources} à sa disposition (\textit{ses capacités, ses connaissances, ses outils, ...}).
				Celles-ci seront plutôt perçues comme \textbf{minimes} face à cette montagne (\textit{peu de compétences techniques, manque de formation, méconnaissance de la modélisation utilisée, ...}) ;
				;
				% Régulatiuon.
				\item Enfin, l'opérateur compare les deux estimations (\textit{est-ce que la charge de travail et mes ressources sont à l'équilibre ?}) et \textbf{ajuste sa charge de travail} pour la proportionner aux ressources qu'il va engager.
				Dans notre cas, l'opérateur va probablement \textbf{essayer de réduire} (intentionnellement ou non) sa charge de travail pour qu'elle soit perçue comme acceptable vis-à-vis de ses ressources.
			\end{itemize}
			Ce principe explique alors certaines variations, notamment lorsque la modélisation est particulièrement complexe ou que l'annotateur est sous pression ou fatigué.
			%
			% Exemple.
			\begin{leftBarExamples}
				Nous pouvons appliquer cette théorie lorsque l'opérateur n'a pas eu de congés depuis plusieurs semaines ou que la fin de semaine approche : ses capacités sont perçues comme plus faibles à cause de la fatigue, nous pouvons alors constater des erreurs d'annotation même si la complexité de la tâche n'a pas changé.
			\end{leftBarExamples}
			%
			% Solutions.
			\begin{leftBarIdea}
				% Solution méthodologique.
				Une première approche consiste à \textbf{essayer de simplifier la tâche} de labellisation (recommandation de \cite{bayerl-paul:2011:what-determines-intercoder}), permettant ainsi d'avoir une meilleure qualité avec une modélisation moins sophistiquée.
				\cite{fort-etal:2012:modeling-complexity-manual} rappellent que le contexte autour de la donnée semble aussi introduire un surplus d'information à gérer : diminuer ce contexte peut parfois alléger l'annotation mais risque en échange introduire plus d'ambiguïté.
				\cite{baledent:2022:complexite-annotation-manuelle} expose le dilemme entre annoter un phénomène complexe en un seul jet et le découper en plusieurs tâches unitaires distinctes : si la première permet d'avoir une meilleure vue d'ensemble, la seconde peut alléger la charge de travail.
				
				% Solution gamification.
				Il est aussi possible d'essayer de \textbf{rendre la tâche ludique} (\textit{gamification}, \cite{von-ahn:2006:games-purpose}) : plusieurs outils tentent en effet de faire oublier à l'opérateur qu'il est en train de travailler en déguisant sa mission sous la forme d'un jeu (par exemple : \cite{guillaume-etal:2016:crowdsourcing-complex-language} propose \texttt{ZombiLingo} pour l'annotation morpho-syntaxique de textes).
				Cette approche requiert toutefois une grande créativité pour réussir à produire cette illusion (\cite{fort:2017:experts-ou-foule}).
			\end{leftBarIdea}
		
		
		%%% 2.3.3.C. Faible valorisation du rôle d'annotateur.
		\subsubsection{Faible valorisation du rôle d'annotateur}
		\label{section:2.3.3.C-DEFIS-ANNOTATION-ASPECT-HUMAIN-ESCLAVAGE}
			
			% Introduction: nous avons besoin d'experts.
			Comme vu en \textsc{Section~\ref{section:2.2.2-ORGANISATION-ANNOTATION-ACTEURS}}, l'annotation repose principalement sur des opérateurs ayant une connaissance \textbf{métier} du phénomène à modéliser, ou des opérateurs formés spécifiquement à la tâche de labellisation.
			Ces personnes sont donc essentielles à la conception d'une base d'apprentissage.
			
			% Dérive: Myriadisation.
			Cependant, nous constatons que de plus en plus d'entreprises décident de sous-traiter ces tâches d'annotation à des plateformes de myriadisation (\textit{crowdsourcing}, \cite{howe:2008:crowdsourcing-how-power}) \footnote{
				Myriadisation : Pour rappel, ces plateformes collaboratives permettent à n'importe quel internaute de contribuer à une tâche d'annotation, permettant ainsi de labelliser de grands volumes de données rapidement et à moindre coûts.
			} comme \texttt{Amazon Mechanical Turk} (\cite{callison-burch-dredze:2010:creating-speech-language}) ou \texttt{Language ARC} (\cite{fiumara-etal:2020:languagearc-developing-language}).
			Plusieurs études montrent en effet l'intérêt de faire participer une foule d'opérateurs non-experts (\cite{snow-etal:2008:cheap-fast-it}, \cite{fort:2017:experts-ou-foule}), mais de \textbf{sérieuses questions éthiques} sont néanmoins soulevées par l'utilisation de ces plateformes.
			
			% Problème 1: Salaires faibles.
			Tout d'abord, nous pouvons remarquer que ces opérateurs sont souvent payés un salaire dérisoire proportionnel à la quantité de données qu'ils labellisent.
			Cela ouvre la porte à des dérives, comme la polémique autour de \texttt{ChatGPT} (\cite{openai:2023:chatgpt}) où \cite{perrigo-zorthian:2023:exclusive-openai-used} avaient dénoncé l'emploi de Kényans pour moins de $2$\$ de l'heure dans le but de corriger ce modèle.
			Nous pouvons aussi citer \cite{dzieza:2023:ai-lot-work} qui alerte sur l'apparition cette nouvelle classe de travail sous-payée, n'ayant pas de place claire dans le droit du travail, et généralement dévalorisée dans l'organisation des projets d'annotation.
			
			% Problème 2: Troubles psychologiques.
			D'autres part, \cite{rowe:2023:it-destroyed-me} reporte aussi les impacts émotionnels et psychologiques causés par certaines tâches d'annotation.
			En effet, une mission récurrente consiste à modérer des contenus à caractères offensants (\textit{insultes, violence, drogue, sexe, armes, ...}) : de nombreux annotateurs sombrent ainsi dans la dépression après avoir labellisé de telles données pendant des jours voire des semaines...
			
			% Pour information: Critique franche du TALN.
			\begin{leftBarInformation}
				Pour conclure concernant ces dérives éthiques, \cite{valette:2016:analyse-statistique-donnees} rédige une critique franche des stratégies d'annotation dans le domaine du traitement automatique du langage naturel.
				Celle-ci dénonce l'organisation actuelle où les experts linguistes sont devenus de simples sous-traitants n'ayant plus leur mot à dire dans la conception d'une modélisation : ils sont généralement traités avec mépris, ne récoltent pas les lauriers des projets à succès mais sont tenus pour responsables des projets en échec.
			\end{leftBarInformation}
	
	
	%%%
	%%% Subsection 2.3.4: Bilan concernant les nombreux défis de l'annotation.
	%%%
	\subsection{Bilan concernant les nombreux défis de l'annotation}
	\label{section:2.3.4-DEFIS-ANNOTATION-BILAN}
	
	%%%
	%%% Conclusion.
	%%%
	\begin{leftBarSummary}
		En dressant la liste des défis autour de la tâche d'annotation, nous avons pu voir que :
		\begin{todolist}
			% Pression sur la qualité.
			\item[\itemok] L'enjeu d'un projet d'annotation consiste à \textbf{avoir des données de qualité} :
			celles-ci doivent être représentatives du problème à traiter, en quantité suffisante, avec un minimum de bruit, et leurs droits d'usage doivent être disponibles ;
			% Complexité élevée.
			\item[\itemok] Cependant, la tâche de labellisation et son exigence de qualité \textbf{engendre de la complexité} :
			celle-ci peut venir de la difficulté à modéliser le phénomène ou de l'annotation elle-même, ce qui engendre un certains nombre de coûts ;
			% Différence de comportement.
			\item[\itemok] Ainsi, cette complexité \textbf{créé des différences de comportements} : ces divergences s'expliquent notamment par la subjectivité de l'annotation et par la régulation de la charge de travail effectuée par l'opérateur lorsque cette charge est trop élevée.
		\end{todolist}
	\end{leftBarSummary}